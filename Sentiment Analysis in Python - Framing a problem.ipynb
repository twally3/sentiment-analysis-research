{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in Python - Framing a problem\n",
    "By Max Taylor\n",
    "\n",
    "This is an overview of the full process of developing a Neural Network for sentiment analysis. We will address: How to develop and impement a predictive theory, prepare data, build the network, reduce noise and optimise. This will involve how to attack and solve the problem; Which can be applied throughout future networks.\n",
    "\n",
    "### Contents\n",
    "- Loading the dataset\n",
    "- predictive theory\n",
    "- Theory Validation\n",
    "- Preparing input and output data\n",
    "- Building the network\n",
    "- Identifying Neural Noise\n",
    "- Reducing Neural Noise\n",
    "- Analysing inefficiencies in the network\n",
    "- Optimising inefficiencies in the network\n",
    "- Further noise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = open('reviews.txt','r')\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r')\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a predictive theory\n",
    "\n",
    "Look over the data and consider the best way to use the input information to effectively get the output information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt \t : \t reviews.txt\n",
      "\n",
      "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
      "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
      "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
      "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
      "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
      "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
     ]
    }
   ],
   "source": [
    "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
    "pretty_print_review_and_label(2137)\n",
    "pretty_print_review_and_label(12816)\n",
    "pretty_print_review_and_label(6267)\n",
    "pretty_print_review_and_label(21934)\n",
    "pretty_print_review_and_label(5297)\n",
    "pretty_print_review_and_label(4998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the data should be split into words as they convey the most meaning. For example, single characters do not contain any form of context and whole sentences are too large and general for the network to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory validation\n",
    "\n",
    "Having produced a predictive theory it can be helpful to validate the theory. In this case it was decided that words were the most helpful to us, so this is what we will test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if labels[i] == 'POSITIVE':\n",
    "        for word in reviews[i].split(' '):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(' '):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 550468),\n",
       " ('the', 173324),\n",
       " ('.', 159654),\n",
       " ('and', 89722),\n",
       " ('a', 83688),\n",
       " ('of', 76855),\n",
       " ('to', 66746),\n",
       " ('is', 57245),\n",
       " ('in', 50215),\n",
       " ('br', 49235),\n",
       " ('it', 48025),\n",
       " ('i', 40743),\n",
       " ('that', 35630),\n",
       " ('this', 35080),\n",
       " ('s', 33815),\n",
       " ('as', 26308),\n",
       " ('with', 23247),\n",
       " ('for', 22416),\n",
       " ('was', 21917),\n",
       " ('film', 20937),\n",
       " ('but', 20822),\n",
       " ('movie', 19074),\n",
       " ('his', 17227),\n",
       " ('on', 17008),\n",
       " ('you', 16681),\n",
       " ('he', 16282),\n",
       " ('are', 14807),\n",
       " ('not', 14272),\n",
       " ('t', 13720),\n",
       " ('one', 13655),\n",
       " ('have', 12587),\n",
       " ('be', 12416),\n",
       " ('by', 11997),\n",
       " ('all', 11942),\n",
       " ('who', 11464),\n",
       " ('an', 11294),\n",
       " ('at', 11234),\n",
       " ('from', 10767),\n",
       " ('her', 10474),\n",
       " ('they', 9895),\n",
       " ('has', 9186),\n",
       " ('so', 9154),\n",
       " ('like', 9038),\n",
       " ('about', 8313),\n",
       " ('very', 8305),\n",
       " ('out', 8134),\n",
       " ('there', 8057),\n",
       " ('she', 7779),\n",
       " ('what', 7737),\n",
       " ('or', 7732)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_counts.most_common()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has produces a collection of the positive and negarive words and their number of occurances. Scrolling through the data clearly shows that there is a difference between positive and negative word occurances. However straight away we can see the data is cluttered with useless words. \n",
    "\n",
    "A good step to resolve this is to find the ratio between the words occurance in the positive set and the negative set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "for term, cnt in list(total_counts.most_common()):\n",
    "    if cnt > 100:\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term] + 1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "        \n",
    "for word, ratio in pos_neg_ratios.most_common():\n",
    "    if ratio > 1:\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1 / (ratio + 0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each word in the total count where term is the word and cnt is the number of occurances. If the number of occurances is greater than 100 calculate the ratio between the occurances of that word in the positive list and the negative list and add it to the counter.\n",
    "\n",
    "Then, loop through all the new ratios where word is the word and ratio is the ratio calculated in the last step. If the ratio is greater than 1 it will occur more in the positive set than the negative set. Calculate the natural log to normalise. Otherwise calculate 1 / the natrural log and make it negative. the 0.01 is added so there are no divde by 0 errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 4.6913478822291435),\n",
       " ('paulie', 4.0775374439057197),\n",
       " ('felix', 3.1527360223636558),\n",
       " ('polanski', 2.8233610476132043),\n",
       " ('matthau', 2.8067217286092401),\n",
       " ('victoria', 2.6810215287142909),\n",
       " ('mildred', 2.6026896854443837),\n",
       " ('gandhi', 2.5389738710582761),\n",
       " ('flawless', 2.451005098112319),\n",
       " ('superbly', 2.2600254785752498),\n",
       " ('perfection', 2.1594842493533721),\n",
       " ('astaire', 2.1400661634962708),\n",
       " ('captures', 2.0386195471595809),\n",
       " ('voight', 2.0301704926730531),\n",
       " ('wonderfully', 2.0218960560332353),\n",
       " ('powell', 1.9783454248084671),\n",
       " ('brosnan', 1.9547990964725592),\n",
       " ('lily', 1.9203768470501485),\n",
       " ('bakshi', 1.9029851043382795),\n",
       " ('lincoln', 1.9014583864844796),\n",
       " ('refreshing', 1.8551812956655511),\n",
       " ('breathtaking', 1.8481124057791867),\n",
       " ('bourne', 1.8478489358790986),\n",
       " ('lemmon', 1.8458266904983307),\n",
       " ('delightful', 1.8002701588959635),\n",
       " ('flynn', 1.7996646487351682),\n",
       " ('andrews', 1.7764919970972666),\n",
       " ('homer', 1.7692866133759964),\n",
       " ('beautifully', 1.7626953362841438),\n",
       " ('soccer', 1.7578579175523736),\n",
       " ('elvira', 1.7397031072720019),\n",
       " ('underrated', 1.7197859696029656),\n",
       " ('gripping', 1.7165360479904674),\n",
       " ('superb', 1.7091514458966952),\n",
       " ('delight', 1.6714733033535532),\n",
       " ('welles', 1.6677068205580761),\n",
       " ('sadness', 1.663505133704376),\n",
       " ('sinatra', 1.6389967146756448),\n",
       " ('touching', 1.637217476541176),\n",
       " ('timeless', 1.62924053973028),\n",
       " ('macy', 1.6211339521972916),\n",
       " ('unforgettable', 1.6177367152487956),\n",
       " ('favorites', 1.6158688027643908),\n",
       " ('stewart', 1.6119987332957739),\n",
       " ('sullivan', 1.6094379124341003),\n",
       " ('extraordinary', 1.6094379124341003),\n",
       " ('hartley', 1.6094379124341003),\n",
       " ('brilliantly', 1.5950491749820008),\n",
       " ('friendship', 1.5677652160335325),\n",
       " ('wonderful', 1.5645425925262093)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words most frequently seen in the postive reviews\n",
    "pos_neg_ratios.most_common()[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boll', -4.0778152602708904),\n",
       " ('uwe', -3.9218753018711578),\n",
       " ('seagal', -3.3202501058581921),\n",
       " ('unwatchable', -3.0269848170580955),\n",
       " ('stinker', -2.9876839403711624),\n",
       " ('mst', -2.7753833211707968),\n",
       " ('incoherent', -2.7641396677532537),\n",
       " ('unfunny', -2.5545257844967644),\n",
       " ('waste', -2.4907515123361046),\n",
       " ('blah', -2.4475792789485005),\n",
       " ('horrid', -2.3715779644809971),\n",
       " ('pointless', -2.3451073877136341),\n",
       " ('atrocious', -2.3187369339642556),\n",
       " ('redeeming', -2.2667790015910296),\n",
       " ('prom', -2.2601040980178784),\n",
       " ('drivel', -2.2476029585766928),\n",
       " ('lousy', -2.2118080125207054),\n",
       " ('worst', -2.1930856334332267),\n",
       " ('laughable', -2.172468615469592),\n",
       " ('awful', -2.1385076866397488),\n",
       " ('poorly', -2.1326133844207011),\n",
       " ('wasting', -2.1178155545614512),\n",
       " ('remotely', -2.111046881095167),\n",
       " ('existent', -2.0024805005437076),\n",
       " ('boredom', -1.9241486572738005),\n",
       " ('miserably', -1.9216610938019989),\n",
       " ('sucks', -1.9166645809588516),\n",
       " ('uninspired', -1.9131499212248517),\n",
       " ('lame', -1.9117232884159072),\n",
       " ('insult', -1.9085323769376259)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words most frequently seen in the negative reviews\n",
    "list(reversed(pos_neg_ratios.most_common()))[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming text into numbers\n",
    "\n",
    "The current information is usefull to those of us who can already read but not very usefull to a neural network!\n",
    "Before we train the neural network we must convert the data into a format that can be used for in the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of different words in the data:  74074\n"
     ]
    }
   ],
   "source": [
    "vocab = set(total_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "print ('The number of different words in the data: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'spaghettis',\n",
       " 'ballplayers',\n",
       " 'progrmmer',\n",
       " 'rouges',\n",
       " 'fondas',\n",
       " 'acmetropolis',\n",
       " 'pulsates',\n",
       " 'memorise',\n",
       " 'tambien',\n",
       " 'jonatha',\n",
       " 'piquantly',\n",
       " 'craptitude',\n",
       " 'misjudge',\n",
       " 'classic',\n",
       " 'felichy',\n",
       " 'somegoro',\n",
       " 'expunged',\n",
       " 'egalitarianism',\n",
       " 'maruschka',\n",
       " 'conklin',\n",
       " 'gunfire',\n",
       " 'civic',\n",
       " 'pucky',\n",
       " 'vaulted',\n",
       " 'traumatise',\n",
       " 'blades',\n",
       " 'voogdt',\n",
       " 'constipated',\n",
       " 'emblem',\n",
       " 'recertified',\n",
       " 'screw',\n",
       " 'carnaevon',\n",
       " 'dramatisation',\n",
       " 'anddd',\n",
       " 'dystrophic',\n",
       " 'mope',\n",
       " 'tentacle',\n",
       " 'ridgement',\n",
       " 'kidman',\n",
       " 'gainey',\n",
       " 'fawlty',\n",
       " 'declared',\n",
       " 'crybaby',\n",
       " 'rascism',\n",
       " 'entomologist',\n",
       " 'astronishing',\n",
       " 'racecar',\n",
       " 'rang',\n",
       " 'ottoman']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab)[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab is a list of all the different words found in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer_0 = np.zeros((1, vocab_size))\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create the input layer with a length of the number of different words. We fill it with zeros to save memory which can improve comutiational efficiency.\n",
    "\n",
    "Next, take each word and give it a unique index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'spaghettis': 1,\n",
       " 'ballplayers': 2,\n",
       " 'progrmmer': 3,\n",
       " 'rouges': 4,\n",
       " 'fondas': 5,\n",
       " 'acmetropolis': 6,\n",
       " 'pulsates': 7,\n",
       " 'memorise': 8,\n",
       " 'tambien': 9,\n",
       " 'jonatha': 10,\n",
       " 'piquantly': 11,\n",
       " 'craptitude': 12,\n",
       " 'misjudge': 13,\n",
       " 'classic': 14,\n",
       " 'felichy': 15,\n",
       " 'somegoro': 16,\n",
       " 'expunged': 17,\n",
       " 'egalitarianism': 18,\n",
       " 'maruschka': 19,\n",
       " 'conklin': 20,\n",
       " 'gunfire': 21,\n",
       " 'civic': 22,\n",
       " 'pucky': 23,\n",
       " 'vaulted': 24,\n",
       " 'traumatise': 25,\n",
       " 'blades': 26,\n",
       " 'voogdt': 27,\n",
       " 'constipated': 28,\n",
       " 'emblem': 29,\n",
       " 'recertified': 30,\n",
       " 'screw': 31,\n",
       " 'carnaevon': 32,\n",
       " 'dramatisation': 33,\n",
       " 'anddd': 34,\n",
       " 'dystrophic': 35,\n",
       " 'mope': 36,\n",
       " 'tentacle': 37,\n",
       " 'ridgement': 38,\n",
       " 'kidman': 39,\n",
       " 'gainey': 40,\n",
       " 'fawlty': 41,\n",
       " 'declared': 42,\n",
       " 'crybaby': 43,\n",
       " 'rascism': 44,\n",
       " 'entomologist': 45,\n",
       " 'astronishing': 46,\n",
       " 'racecar': 47,\n",
       " 'rang': 48,\n",
       " 'ottoman': 49,\n",
       " 'reaffirming': 50,\n",
       " 'veer': 51,\n",
       " 'slevin': 52,\n",
       " 'crashed': 53,\n",
       " 'pambies': 54,\n",
       " 'westernized': 55,\n",
       " 'eldard': 56,\n",
       " 'presentable': 57,\n",
       " 'popcorncoke': 58,\n",
       " 'fathoms': 59,\n",
       " 'sabriye': 60,\n",
       " 'rozzi': 61,\n",
       " 'baxtor': 62,\n",
       " 'elaborately': 63,\n",
       " 'picturing': 64,\n",
       " 'curve': 65,\n",
       " 'boeing': 66,\n",
       " 'archaeology': 67,\n",
       " 'bai': 68,\n",
       " 'romcoms': 69,\n",
       " 'oppositions': 70,\n",
       " 'vancamp': 71,\n",
       " 'reaping': 72,\n",
       " 'heels': 73,\n",
       " 'diarrhoeic': 74,\n",
       " 'fisher': 75,\n",
       " 'implores': 76,\n",
       " 'naista': 77,\n",
       " 'colera': 78,\n",
       " 'mormons': 79,\n",
       " 'markov': 80,\n",
       " 'subjugates': 81,\n",
       " 'cratey': 82,\n",
       " 'skaters': 83,\n",
       " 'hhe': 84,\n",
       " 'roeg': 85,\n",
       " 'tighter': 86,\n",
       " 'ducommun': 87,\n",
       " 'suble': 88,\n",
       " 'lovableness': 89,\n",
       " 'freckles': 90,\n",
       " 'soundtracks': 91,\n",
       " 'satrapi': 92,\n",
       " 'novelties': 93,\n",
       " 'kerr': 94,\n",
       " 'gainsbourg': 95,\n",
       " 'dhavan': 96,\n",
       " 'swathed': 97,\n",
       " 'tmc': 98,\n",
       " 'neglecting': 99,\n",
       " 'lindseys': 100,\n",
       " 'orphanages': 101,\n",
       " 'prunes': 102,\n",
       " 'immoderate': 103,\n",
       " 'sindhoor': 104,\n",
       " 'classify': 105,\n",
       " 'eccentricity': 106,\n",
       " 'broon': 107,\n",
       " 'beatnik': 108,\n",
       " 'squeaky': 109,\n",
       " 'cribs': 110,\n",
       " 'cossey': 111,\n",
       " 'vxzptdtphwdm': 112,\n",
       " 'sword': 113,\n",
       " 'fotp': 114,\n",
       " 'congrats': 115,\n",
       " 'gifford': 116,\n",
       " 'wildcard': 117,\n",
       " 'endectomy': 118,\n",
       " 'guinea': 119,\n",
       " 'streetwalker': 120,\n",
       " 'thickness': 121,\n",
       " 'valkyries': 122,\n",
       " 'blush': 123,\n",
       " 'sulu': 124,\n",
       " 'joycey': 125,\n",
       " 'potholes': 126,\n",
       " 'escapees': 127,\n",
       " 'irrelevancy': 128,\n",
       " 'trespasses': 129,\n",
       " 'crims': 130,\n",
       " 'dourif': 131,\n",
       " 'interstitials': 132,\n",
       " 'extrovert': 133,\n",
       " 'trashes': 134,\n",
       " 'valhalla': 135,\n",
       " 'immediate': 136,\n",
       " 'borek': 137,\n",
       " 'jun': 138,\n",
       " 'sufficient': 139,\n",
       " 'coordinated': 140,\n",
       " 'abner': 141,\n",
       " 'betting': 142,\n",
       " 'nieztsche': 143,\n",
       " 'rosario': 144,\n",
       " 'one': 145,\n",
       " 'grasping': 146,\n",
       " 'submariner': 147,\n",
       " 'unfurls': 148,\n",
       " 'bishoff': 149,\n",
       " 'rebecca': 150,\n",
       " 'hooey': 151,\n",
       " 'phillis': 152,\n",
       " 'ruined': 153,\n",
       " 'associates': 154,\n",
       " 'ravings': 155,\n",
       " 'suchet': 156,\n",
       " 'manhunter': 157,\n",
       " 'thrust': 158,\n",
       " 'paxton': 159,\n",
       " 'chutki': 160,\n",
       " 'divorcee': 161,\n",
       " 'showpiece': 162,\n",
       " 'adjunct': 163,\n",
       " 'cetniks': 164,\n",
       " 'hatcher': 165,\n",
       " 'ennia': 166,\n",
       " 'conundrum': 167,\n",
       " 'boogey': 168,\n",
       " 'photograpy': 169,\n",
       " 'phoormola': 170,\n",
       " 'defence': 171,\n",
       " 'ronda': 172,\n",
       " 'wt': 173,\n",
       " 'tandon': 174,\n",
       " 'liquidators': 175,\n",
       " 'geddy': 176,\n",
       " 'criticises': 177,\n",
       " 'macy': 178,\n",
       " 'lovebirds': 179,\n",
       " 'antonioni': 180,\n",
       " 'seized': 181,\n",
       " 'huhuhuhuhu': 182,\n",
       " 'yoshi': 183,\n",
       " 'lengthen': 184,\n",
       " 'invaders': 185,\n",
       " 'badiel': 186,\n",
       " 'saarsgard': 187,\n",
       " 'minnie': 188,\n",
       " 'whirry': 189,\n",
       " 'charlsten': 190,\n",
       " 'nookie': 191,\n",
       " 'subjectively': 192,\n",
       " 'adherents': 193,\n",
       " 'battleships': 194,\n",
       " 'pollute': 195,\n",
       " 'calito': 196,\n",
       " 'holender': 197,\n",
       " 'extort': 198,\n",
       " 'tyron': 199,\n",
       " 'samoan': 200,\n",
       " 'giger': 201,\n",
       " 'annabella': 202,\n",
       " 'sagacity': 203,\n",
       " 'denominations': 204,\n",
       " 'cruiserweight': 205,\n",
       " 'customers': 206,\n",
       " 'satirized': 207,\n",
       " 'unexpressed': 208,\n",
       " 'pallio': 209,\n",
       " 'ment': 210,\n",
       " 'whisked': 211,\n",
       " 'cohesive': 212,\n",
       " 'rishtaa': 213,\n",
       " 'dukesofhazzard': 214,\n",
       " 'iiascension': 215,\n",
       " 'tenfold': 216,\n",
       " 'klemper': 217,\n",
       " 'rifted': 218,\n",
       " 'myra': 219,\n",
       " 'manr': 220,\n",
       " 'taing': 221,\n",
       " 'emancipator': 222,\n",
       " 'neglectful': 223,\n",
       " 'innit': 224,\n",
       " 'hyser': 225,\n",
       " 'explicated': 226,\n",
       " 'bodied': 227,\n",
       " 'experiments': 228,\n",
       " 'phlox': 229,\n",
       " 'upanishad': 230,\n",
       " 'runaways': 231,\n",
       " 'productively': 232,\n",
       " 'embellishes': 233,\n",
       " 'zipper': 234,\n",
       " 'musican': 235,\n",
       " 'emblazered': 236,\n",
       " 'premiere': 237,\n",
       " 'cyanide': 238,\n",
       " 'babs': 239,\n",
       " 'dialectics': 240,\n",
       " 'carousing': 241,\n",
       " 'zigfield': 242,\n",
       " 'allotted': 243,\n",
       " 'psychlogical': 244,\n",
       " 'pause': 245,\n",
       " 'siberian': 246,\n",
       " 'malevolence': 247,\n",
       " 'distant': 248,\n",
       " 'choker': 249,\n",
       " 'felon': 250,\n",
       " 'hedaya': 251,\n",
       " 'keneth': 252,\n",
       " 'stewarts': 253,\n",
       " 'yugonostalgic': 254,\n",
       " 'bolts': 255,\n",
       " 'prowled': 256,\n",
       " 'misfire': 257,\n",
       " 'bratt': 258,\n",
       " 'firearms': 259,\n",
       " 'ladyslipper': 260,\n",
       " 'spang': 261,\n",
       " 'attractions': 262,\n",
       " 'continued': 263,\n",
       " 'audaciousness': 264,\n",
       " 'fancifully': 265,\n",
       " 'nauseated': 266,\n",
       " 'scrawled': 267,\n",
       " 'humanities': 268,\n",
       " 'maia': 269,\n",
       " 'climate': 270,\n",
       " 'beren': 271,\n",
       " 'substitute': 272,\n",
       " 'mongolian': 273,\n",
       " 'authentic': 274,\n",
       " 'kuchler': 275,\n",
       " 'cuddly': 276,\n",
       " 'manckiewitz': 277,\n",
       " 'pensylvannia': 278,\n",
       " 'consumerism': 279,\n",
       " 'nsa': 280,\n",
       " 'rajni': 281,\n",
       " 'routs': 282,\n",
       " 'barabarian': 283,\n",
       " 'flinty': 284,\n",
       " 'motor': 285,\n",
       " 'tentatives': 286,\n",
       " 'startrek': 287,\n",
       " 'benighted': 288,\n",
       " 'reichskanzler': 289,\n",
       " 'nominating': 290,\n",
       " 'telly': 291,\n",
       " 'observe': 292,\n",
       " 'pedophilia': 293,\n",
       " 'hear': 294,\n",
       " 'troubling': 295,\n",
       " 'stadium': 296,\n",
       " 'foxworth': 297,\n",
       " 'peep': 298,\n",
       " 'suggested': 299,\n",
       " 'herb': 300,\n",
       " 'gogo': 301,\n",
       " 'archrival': 302,\n",
       " 'bigfoot': 303,\n",
       " 'meaningless': 304,\n",
       " 'betterment': 305,\n",
       " 'facials': 306,\n",
       " 'bodycount': 307,\n",
       " 'familiarity': 308,\n",
       " 'shares': 309,\n",
       " 'shingo': 310,\n",
       " 'luminescence': 311,\n",
       " 'exploration': 312,\n",
       " 'kilmer': 313,\n",
       " 'ry': 314,\n",
       " 'greenlights': 315,\n",
       " 'nger': 316,\n",
       " 'revolutionairies': 317,\n",
       " 'unbefitting': 318,\n",
       " 'gahannah': 319,\n",
       " 'hope': 320,\n",
       " 'resisting': 321,\n",
       " 'maldonado': 322,\n",
       " 'alexio': 323,\n",
       " 'nightwatch': 324,\n",
       " 'arrogants': 325,\n",
       " 'protagonist': 326,\n",
       " 'discipline': 327,\n",
       " 'domains': 328,\n",
       " 'meddings': 329,\n",
       " 'conforms': 330,\n",
       " 'tlc': 331,\n",
       " 'trashed': 332,\n",
       " 'concoction': 333,\n",
       " 'chans': 334,\n",
       " 'city': 335,\n",
       " 'gawdawful': 336,\n",
       " 'dragonball': 337,\n",
       " 'overlooks': 338,\n",
       " 'doucette': 339,\n",
       " 'rahm': 340,\n",
       " 'lament': 341,\n",
       " 'mehta': 342,\n",
       " 'ttkk': 343,\n",
       " 'briggitta': 344,\n",
       " 'predetermined': 345,\n",
       " 'embarassingly': 346,\n",
       " 'dusenberry': 347,\n",
       " 'leachman': 348,\n",
       " 'neuromuscular': 349,\n",
       " 'starchaser': 350,\n",
       " 'inchworms': 351,\n",
       " 'trotted': 352,\n",
       " 'subsidy': 353,\n",
       " 'vilarasau': 354,\n",
       " 'spouses': 355,\n",
       " 'kaif': 356,\n",
       " 'rutledge': 357,\n",
       " 'blankets': 358,\n",
       " 'mazurszky': 359,\n",
       " 'panic': 360,\n",
       " 'settlement': 361,\n",
       " 'repugnancy': 362,\n",
       " 'erroll': 363,\n",
       " 'dethroning': 364,\n",
       " 'trotters': 365,\n",
       " 'maltreat': 366,\n",
       " 'penn': 367,\n",
       " 'filmable': 368,\n",
       " 'gitai': 369,\n",
       " 'viewability': 370,\n",
       " 'ticked': 371,\n",
       " 'arousers': 372,\n",
       " 'alothugh': 373,\n",
       " 'ummm': 374,\n",
       " 'suspiciously': 375,\n",
       " 'bleeth': 376,\n",
       " 'gaga': 377,\n",
       " 'menephta': 378,\n",
       " 'defrocked': 379,\n",
       " 'blaise': 380,\n",
       " 'incoherence': 381,\n",
       " 'puberty': 382,\n",
       " 'loyalist': 383,\n",
       " 'skittles': 384,\n",
       " 'taktarov': 385,\n",
       " 'mou': 386,\n",
       " 'travelogues': 387,\n",
       " 'positioned': 388,\n",
       " 'ponto': 389,\n",
       " 'synopsizing': 390,\n",
       " 'tamper': 391,\n",
       " 'undestand': 392,\n",
       " 'prototypical': 393,\n",
       " 'reconstituirea': 394,\n",
       " 'landen': 395,\n",
       " 'moldy': 396,\n",
       " 'allusion': 397,\n",
       " 'org': 398,\n",
       " 'booklets': 399,\n",
       " 'carmelo': 400,\n",
       " 'cool': 401,\n",
       " 'coverings': 402,\n",
       " 'deities': 403,\n",
       " 'combusts': 404,\n",
       " 'starr': 405,\n",
       " 'puede': 406,\n",
       " 'prologic': 407,\n",
       " 'yous': 408,\n",
       " 'betta': 409,\n",
       " 'ferrara': 410,\n",
       " 'wendt': 411,\n",
       " 'ooverall': 412,\n",
       " 'graveyard': 413,\n",
       " 'fuckwood': 414,\n",
       " 'roundabout': 415,\n",
       " 'unschooled': 416,\n",
       " 'reshot': 417,\n",
       " 'summerslam': 418,\n",
       " 'cutsey': 419,\n",
       " 'loudest': 420,\n",
       " 'castulo': 421,\n",
       " 'boxes': 422,\n",
       " 'burty': 423,\n",
       " 'tablespoon': 424,\n",
       " 'saggy': 425,\n",
       " 'lauter': 426,\n",
       " 'naschy': 427,\n",
       " 'rhonda': 428,\n",
       " 'phyllida': 429,\n",
       " 'geologists': 430,\n",
       " 'authorlittlehammer': 431,\n",
       " 'unfaltering': 432,\n",
       " 'langa': 433,\n",
       " 'plotty': 434,\n",
       " 'zanjeer': 435,\n",
       " 'plantage': 436,\n",
       " 'polluted': 437,\n",
       " 'lumpiest': 438,\n",
       " 'mps': 439,\n",
       " 'highlighting': 440,\n",
       " 'grouping': 441,\n",
       " 'cannibalized': 442,\n",
       " 'insured': 443,\n",
       " 'mcallister': 444,\n",
       " 'innocous': 445,\n",
       " 'brittannica': 446,\n",
       " 'entrusts': 447,\n",
       " 'boomtown': 448,\n",
       " 'masti': 449,\n",
       " 'bucket': 450,\n",
       " 'edit': 451,\n",
       " 'frazer': 452,\n",
       " 'panzer': 453,\n",
       " 'auguste': 454,\n",
       " 'braveness': 455,\n",
       " 'samuraisploitation': 456,\n",
       " 'unsurvivable': 457,\n",
       " 'patrick': 458,\n",
       " 'mulrooney': 459,\n",
       " 'readies': 460,\n",
       " 'wasbut': 461,\n",
       " 'colour': 462,\n",
       " 'thereafter': 463,\n",
       " 'grated': 464,\n",
       " 'subtitling': 465,\n",
       " 'had': 466,\n",
       " 'phillippe': 467,\n",
       " 'wells': 468,\n",
       " 'toothbrush': 469,\n",
       " 'acadmey': 470,\n",
       " 'hallier': 471,\n",
       " 'spoiles': 472,\n",
       " 'urbanization': 473,\n",
       " 'horne': 474,\n",
       " 'clemens': 475,\n",
       " 'persevere': 476,\n",
       " 'commitments': 477,\n",
       " 'taft': 478,\n",
       " 'purchassed': 479,\n",
       " 'denholm': 480,\n",
       " 'bloodymonday': 481,\n",
       " 'leyner': 482,\n",
       " 'runny': 483,\n",
       " 'compositely': 484,\n",
       " 'vulcan': 485,\n",
       " 'reassembles': 486,\n",
       " 'heartthrobs': 487,\n",
       " 'restrained': 488,\n",
       " 'combustible': 489,\n",
       " 'durokov': 490,\n",
       " 'wanderd': 491,\n",
       " 'heartbreaks': 492,\n",
       " 'suckers': 493,\n",
       " 'frequencies': 494,\n",
       " 'kroual': 495,\n",
       " 'chronologies': 496,\n",
       " 'erath': 497,\n",
       " 'fiddling': 498,\n",
       " 'swishy': 499,\n",
       " 'midge': 500,\n",
       " 'theodor': 501,\n",
       " 'lobsters': 502,\n",
       " 'definitively': 503,\n",
       " 'preachiest': 504,\n",
       " 'apporting': 505,\n",
       " 'cultivated': 506,\n",
       " 'carre': 507,\n",
       " 'rednecks': 508,\n",
       " 'audrey': 509,\n",
       " 'goldoni': 510,\n",
       " 'dance': 511,\n",
       " 'strictures': 512,\n",
       " 'slates': 513,\n",
       " 'charlus': 514,\n",
       " 'substantiate': 515,\n",
       " 'sumatra': 516,\n",
       " 'rigshospitalet': 517,\n",
       " 'devious': 518,\n",
       " 'rober': 519,\n",
       " 'provoking': 520,\n",
       " 'disguised': 521,\n",
       " 'lifeguards': 522,\n",
       " 'mouthy': 523,\n",
       " 'reoccurring': 524,\n",
       " 'mistreated': 525,\n",
       " 'lawler': 526,\n",
       " 'cognoscenti': 527,\n",
       " 'loni': 528,\n",
       " 'standa': 529,\n",
       " 'migenes': 530,\n",
       " 'mackendrick': 531,\n",
       " 'macadam': 532,\n",
       " 'wang': 533,\n",
       " 'sienna': 534,\n",
       " 'fogie': 535,\n",
       " 'arsonist': 536,\n",
       " 'yipee': 537,\n",
       " 'psychological': 538,\n",
       " 'nerdbomber': 539,\n",
       " 'insturmental': 540,\n",
       " 'eye': 541,\n",
       " 'abadi': 542,\n",
       " 'standstill': 543,\n",
       " 'prigs': 544,\n",
       " 'reeeeeaally': 545,\n",
       " 'penpusher': 546,\n",
       " 'kuno': 547,\n",
       " 'necessity': 548,\n",
       " 'miscarriages': 549,\n",
       " 'robbins': 550,\n",
       " 'industrialize': 551,\n",
       " 'drooling': 552,\n",
       " 'toola': 553,\n",
       " 'rupturing': 554,\n",
       " 'prinal': 555,\n",
       " 'libidos': 556,\n",
       " 'unsatisfying': 557,\n",
       " 'devotions': 558,\n",
       " 'templars': 559,\n",
       " 'blains': 560,\n",
       " 'mcdemorant': 561,\n",
       " 'plagiarised': 562,\n",
       " 'murmurs': 563,\n",
       " 'cities': 564,\n",
       " 'fluffiness': 565,\n",
       " 'finest': 566,\n",
       " 'astronuat': 567,\n",
       " 'dragonfly': 568,\n",
       " 'toss': 569,\n",
       " 'eoes': 570,\n",
       " 'protractor': 571,\n",
       " 'madden': 572,\n",
       " 'lr': 573,\n",
       " 'ae': 574,\n",
       " 'tenku': 575,\n",
       " 'frith': 576,\n",
       " 'houselessness': 577,\n",
       " 'latke': 578,\n",
       " 'petra': 579,\n",
       " 'snipe': 580,\n",
       " 'gordano': 581,\n",
       " 'viy': 582,\n",
       " 'gossebumps': 583,\n",
       " 'bloggers': 584,\n",
       " 'bludgeoning': 585,\n",
       " 'disseminating': 586,\n",
       " 'supporters': 587,\n",
       " 'whacky': 588,\n",
       " 'goeres': 589,\n",
       " 'powdered': 590,\n",
       " 'ii': 591,\n",
       " 'rancour': 592,\n",
       " 'undershorts': 593,\n",
       " 'prolo': 594,\n",
       " 'ferries': 595,\n",
       " 'chintz': 596,\n",
       " 'retrace': 597,\n",
       " 'jars': 598,\n",
       " 'dar': 599,\n",
       " 'prominant': 600,\n",
       " 'storyteling': 601,\n",
       " 'gangmembers': 602,\n",
       " 'dribbles': 603,\n",
       " 'deray': 604,\n",
       " 'traversed': 605,\n",
       " 'souvenirs': 606,\n",
       " 'throttle': 607,\n",
       " 'holsters': 608,\n",
       " 'interspecies': 609,\n",
       " 'briny': 610,\n",
       " 'beauty': 611,\n",
       " 'brighter': 612,\n",
       " 'vivement': 613,\n",
       " 'lafia': 614,\n",
       " 'caf': 615,\n",
       " 'entrailing': 616,\n",
       " 'bobbins': 617,\n",
       " 'mcelwee': 618,\n",
       " 'helmuth': 619,\n",
       " 'pressuring': 620,\n",
       " 'accelerated': 621,\n",
       " 'tonino': 622,\n",
       " 'caretaker': 623,\n",
       " 'darnell': 624,\n",
       " 'aunties': 625,\n",
       " 'thespian': 626,\n",
       " 'imbred': 627,\n",
       " 'diy': 628,\n",
       " 'augers': 629,\n",
       " 'lumbly': 630,\n",
       " 'dissecting': 631,\n",
       " 'compactor': 632,\n",
       " 'cinema': 633,\n",
       " 'freud': 634,\n",
       " 'ni': 635,\n",
       " 'hirschbiegel': 636,\n",
       " 'imperialflags': 637,\n",
       " 'kumai': 638,\n",
       " 'whateverian': 639,\n",
       " 'ealings': 640,\n",
       " 'baccalaurat': 641,\n",
       " 'painting': 642,\n",
       " 'metasonix': 643,\n",
       " 'michelangelo': 644,\n",
       " 'kiley': 645,\n",
       " 'maricarmen': 646,\n",
       " 'average': 647,\n",
       " 'brattiness': 648,\n",
       " 'nortons': 649,\n",
       " 'laetitia': 650,\n",
       " 'futuramafan': 651,\n",
       " 'artiste': 652,\n",
       " 'thumper': 653,\n",
       " 'correlli': 654,\n",
       " 'ecuador': 655,\n",
       " 'altar': 656,\n",
       " 'belafonte': 657,\n",
       " 'jangles': 658,\n",
       " 'waaay': 659,\n",
       " 'renderings': 660,\n",
       " 'befouled': 661,\n",
       " 'aan': 662,\n",
       " 'buchinsky': 663,\n",
       " 'librarians': 664,\n",
       " 'asininity': 665,\n",
       " 'interface': 666,\n",
       " 'gale': 667,\n",
       " 'cheerfully': 668,\n",
       " 'donger': 669,\n",
       " 'nilo': 670,\n",
       " 'executive': 671,\n",
       " 'preordered': 672,\n",
       " 'endorses': 673,\n",
       " 'alotta': 674,\n",
       " 'beds': 675,\n",
       " 'feitshans': 676,\n",
       " 'nekromantiks': 677,\n",
       " 'bankability': 678,\n",
       " 'unload': 679,\n",
       " 'impede': 680,\n",
       " 'bumblebee': 681,\n",
       " 'ospenskya': 682,\n",
       " 'aaaaaaah': 683,\n",
       " 'forlornly': 684,\n",
       " 'fai': 685,\n",
       " 'undying': 686,\n",
       " 'byington': 687,\n",
       " 'freshmen': 688,\n",
       " 'viktor': 689,\n",
       " 'polluting': 690,\n",
       " 'discussion': 691,\n",
       " 'baptiste': 692,\n",
       " 'specially': 693,\n",
       " 'speechless': 694,\n",
       " 'hothead': 695,\n",
       " 'taboo': 696,\n",
       " 'kraft': 697,\n",
       " 'surprises': 698,\n",
       " 'elicit': 699,\n",
       " 'relic': 700,\n",
       " 'asssociated': 701,\n",
       " 'twaddle': 702,\n",
       " 'excoriated': 703,\n",
       " 'elton': 704,\n",
       " 'hubbie': 705,\n",
       " 'ranks': 706,\n",
       " 'robed': 707,\n",
       " 'downed': 708,\n",
       " 'bender': 709,\n",
       " 'mained': 710,\n",
       " 'tiananmen': 711,\n",
       " 'torrie': 712,\n",
       " 'lennie': 713,\n",
       " 'elegant': 714,\n",
       " 'deathit': 715,\n",
       " 'dureyea': 716,\n",
       " 'misstakes': 717,\n",
       " 'infusion': 718,\n",
       " 'oppressions': 719,\n",
       " 'pugs': 720,\n",
       " 'herringbone': 721,\n",
       " 'lidia': 722,\n",
       " 'viz': 723,\n",
       " 'meditations': 724,\n",
       " 'nickerson': 725,\n",
       " 'winchester': 726,\n",
       " 'psycho': 727,\n",
       " 'group': 728,\n",
       " 'antirust': 729,\n",
       " 'depalmas': 730,\n",
       " 'benji': 731,\n",
       " 'whirlwind': 732,\n",
       " 'anticlimactic': 733,\n",
       " 'hankies': 734,\n",
       " 'sossamon': 735,\n",
       " 'wrestle': 736,\n",
       " 'ooof': 737,\n",
       " 'redid': 738,\n",
       " 'fatty': 739,\n",
       " 'colossal': 740,\n",
       " 'outlawed': 741,\n",
       " 'destins': 742,\n",
       " 'concieling': 743,\n",
       " 'odeon': 744,\n",
       " 'shying': 745,\n",
       " 'beatings': 746,\n",
       " 'squabbling': 747,\n",
       " 'rebelliously': 748,\n",
       " 'dashiel': 749,\n",
       " 'pygmalion': 750,\n",
       " 'gegen': 751,\n",
       " 'darshan': 752,\n",
       " 'indie': 753,\n",
       " 'goalkeeper': 754,\n",
       " 'hongos': 755,\n",
       " 'unlikened': 756,\n",
       " 'booth': 757,\n",
       " 'bowel': 758,\n",
       " 'preexisting': 759,\n",
       " 'mattering': 760,\n",
       " 'incalculable': 761,\n",
       " 'coxism': 762,\n",
       " 'stridently': 763,\n",
       " 'ebon': 764,\n",
       " 'housebound': 765,\n",
       " 'methinks': 766,\n",
       " 'yara': 767,\n",
       " 'dismissive': 768,\n",
       " 'zealousness': 769,\n",
       " 'weaves': 770,\n",
       " 'mol': 771,\n",
       " 'restaurant': 772,\n",
       " 'dolittle': 773,\n",
       " 'alphabetti': 774,\n",
       " 'battered': 775,\n",
       " 'krishnan': 776,\n",
       " 'groovie': 777,\n",
       " 'ditka': 778,\n",
       " 'baffle': 779,\n",
       " 'sylvia': 780,\n",
       " 'ethereal': 781,\n",
       " 'wails': 782,\n",
       " 'dutchess': 783,\n",
       " 'carapace': 784,\n",
       " 'aux': 785,\n",
       " 'mowing': 786,\n",
       " 'alamothirteen': 787,\n",
       " 'ekin': 788,\n",
       " 'rentalrack': 789,\n",
       " 'trampa': 790,\n",
       " 'crocket': 791,\n",
       " 'slashing': 792,\n",
       " 'placesyou': 793,\n",
       " 'definatly': 794,\n",
       " 'wsj': 795,\n",
       " 'carrillo': 796,\n",
       " 'racheal': 797,\n",
       " 'weatherly': 798,\n",
       " 'endures': 799,\n",
       " 'haack': 800,\n",
       " 'assan': 801,\n",
       " 'informality': 802,\n",
       " 'goodman': 803,\n",
       " 'presses': 804,\n",
       " 'bighouse': 805,\n",
       " 'kinetics': 806,\n",
       " 'objectors': 807,\n",
       " 'fling': 808,\n",
       " 'ridden': 809,\n",
       " 'zeppelins': 810,\n",
       " 'sequences': 811,\n",
       " 'miasma': 812,\n",
       " 'twadd': 813,\n",
       " 'unfun': 814,\n",
       " 'spontaneously': 815,\n",
       " 'statuette': 816,\n",
       " 'degenerating': 817,\n",
       " 'skew': 818,\n",
       " 'otherwise': 819,\n",
       " 'salesman': 820,\n",
       " 'wold': 821,\n",
       " 'manji': 822,\n",
       " 'bffs': 823,\n",
       " 'farthe': 824,\n",
       " 'runtime': 825,\n",
       " 'renowned': 826,\n",
       " 'nielsen': 827,\n",
       " 'relate': 828,\n",
       " 'perfection': 829,\n",
       " 'amen': 830,\n",
       " 'flimsy': 831,\n",
       " 'kinmont': 832,\n",
       " 'decays': 833,\n",
       " 'guerillas': 834,\n",
       " 'uncharted': 835,\n",
       " 'kraakman': 836,\n",
       " 'revolutionary': 837,\n",
       " 'louese': 838,\n",
       " 'streptomycin': 839,\n",
       " 'blazing': 840,\n",
       " 'schopenhauerian': 841,\n",
       " 'rosalyn': 842,\n",
       " 'appaerantly': 843,\n",
       " 'leporidae': 844,\n",
       " 'ru': 845,\n",
       " 'listened': 846,\n",
       " 'anna': 847,\n",
       " 'editor': 848,\n",
       " 'vanquished': 849,\n",
       " 'floorpan': 850,\n",
       " 'kruschen': 851,\n",
       " 'ne': 852,\n",
       " 'undressed': 853,\n",
       " 'lunch': 854,\n",
       " 'holding': 855,\n",
       " 'historia': 856,\n",
       " 'blasters': 857,\n",
       " 'burgi': 858,\n",
       " 'gershwin': 859,\n",
       " 'derris': 860,\n",
       " 'carrefour': 861,\n",
       " 'naaah': 862,\n",
       " 'rectum': 863,\n",
       " 'himalayas': 864,\n",
       " 'lorraine': 865,\n",
       " 'takahisa': 866,\n",
       " 'prissies': 867,\n",
       " 'mwuhahahaa': 868,\n",
       " 'projectionist': 869,\n",
       " 'pavillion': 870,\n",
       " 'dwelled': 871,\n",
       " 'vegeburger': 872,\n",
       " 'rosalba': 873,\n",
       " 'sabato': 874,\n",
       " 'spraining': 875,\n",
       " 'moldavia': 876,\n",
       " 'marky': 877,\n",
       " 'chicks': 878,\n",
       " 'robocop': 879,\n",
       " 'bedknobs': 880,\n",
       " 'pupi': 881,\n",
       " 'landscaped': 882,\n",
       " 'choise': 883,\n",
       " 'genital': 884,\n",
       " 'stringing': 885,\n",
       " 'grandiosely': 886,\n",
       " 'blissfully': 887,\n",
       " 'walloping': 888,\n",
       " 'prom': 889,\n",
       " 'portly': 890,\n",
       " 'rofl': 891,\n",
       " 'nibelungen': 892,\n",
       " 'je': 893,\n",
       " 'kabbalah': 894,\n",
       " 'amritlal': 895,\n",
       " 'anthropology': 896,\n",
       " 'bhabhi': 897,\n",
       " 'marthy': 898,\n",
       " 'burrowed': 899,\n",
       " 'coaltrain': 900,\n",
       " 'patel': 901,\n",
       " 'masturbates': 902,\n",
       " 'anachronism': 903,\n",
       " 'spry': 904,\n",
       " 'compromise': 905,\n",
       " 'swear': 906,\n",
       " 'doodle': 907,\n",
       " 'vama': 908,\n",
       " 'retakes': 909,\n",
       " 'aphasia': 910,\n",
       " 'unashamedly': 911,\n",
       " 'healed': 912,\n",
       " 'papich': 913,\n",
       " 'derange': 914,\n",
       " 'index': 915,\n",
       " 'rack': 916,\n",
       " 'apocalypto': 917,\n",
       " 'elijah': 918,\n",
       " 'milder': 919,\n",
       " 'scrolls': 920,\n",
       " 'hillsides': 921,\n",
       " 'unhelpful': 922,\n",
       " 'aloo': 923,\n",
       " 'titlesgreat': 924,\n",
       " 'deceiver': 925,\n",
       " 'sceneries': 926,\n",
       " 'cobs': 927,\n",
       " 'physicallity': 928,\n",
       " 'fidgeted': 929,\n",
       " 'describing': 930,\n",
       " 'honoured': 931,\n",
       " 'presidency': 932,\n",
       " 'newth': 933,\n",
       " 'dating': 934,\n",
       " 'nostalgic': 935,\n",
       " 'blabla': 936,\n",
       " 'redoing': 937,\n",
       " 'gilgamesh': 938,\n",
       " 'lyle': 939,\n",
       " 'someones': 940,\n",
       " 'af': 941,\n",
       " 'spinola': 942,\n",
       " 'yello': 943,\n",
       " 'paramore': 944,\n",
       " 'rounder': 945,\n",
       " 'cashiered': 946,\n",
       " 'hoops': 947,\n",
       " 'bazooka': 948,\n",
       " 'seasick': 949,\n",
       " 'warhol': 950,\n",
       " 'perilously': 951,\n",
       " 'knowns': 952,\n",
       " 'distressingly': 953,\n",
       " 'lethargy': 954,\n",
       " 'terra': 955,\n",
       " 'silent': 956,\n",
       " 'turret': 957,\n",
       " 'laconian': 958,\n",
       " 'influencing': 959,\n",
       " 'inhabits': 960,\n",
       " 'scriptures': 961,\n",
       " 'triads': 962,\n",
       " 'remixes': 963,\n",
       " 'obverse': 964,\n",
       " 'slipping': 965,\n",
       " 'thunk': 966,\n",
       " 'neath': 967,\n",
       " 'dde': 968,\n",
       " 'defames': 969,\n",
       " 'knot': 970,\n",
       " 'auf': 971,\n",
       " 'wheeled': 972,\n",
       " 'mopes': 973,\n",
       " 'fossey': 974,\n",
       " 'rashid': 975,\n",
       " 'hexing': 976,\n",
       " 'isolative': 977,\n",
       " 'chretien': 978,\n",
       " 'gabbar': 979,\n",
       " 'chichi': 980,\n",
       " 'dionna': 981,\n",
       " 'misshapenly': 982,\n",
       " 'mcconaughey': 983,\n",
       " 'dogville': 984,\n",
       " 'corpsethe': 985,\n",
       " 'pascual': 986,\n",
       " 'confessionals': 987,\n",
       " 'solos': 988,\n",
       " 'supervillain': 989,\n",
       " 'megatron': 990,\n",
       " 'pathologist': 991,\n",
       " 'disclamer': 992,\n",
       " 'crap': 993,\n",
       " 'vulturine': 994,\n",
       " 'emu': 995,\n",
       " 'reestablishing': 996,\n",
       " 'nothan': 997,\n",
       " 'obssession': 998,\n",
       " 'neville': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "\n",
    "word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to update the input layer to actually contain the information and not just zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    \n",
    "    global layer_0\n",
    "    \n",
    "    # Ensure all of layer 0 is set to 0\n",
    "    layer_0 *= 0\n",
    "    \n",
    "    for word in review.split(' '):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "        \n",
    "update_input_layer(reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes a review and loops through each word. It then adds 1 to the value at the index of the word2index number of the word. This will build a collection of the number of word occurances at the unique index of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to get the 'POSITIVE' and 'NEGATIVE' labels into a machine readable format. Here we will use a 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_for_label(label):\n",
    "    if label == 'POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target_for_label(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "For this I am going to use the NeuralNetwork class from Udacity Project 1 with some adjustments:\n",
    "- 3 Layer neural network\n",
    "- no non-linearity in the second layer (No sigmoid between layer 0 and 1)\n",
    "- use previous functions to create the training data\n",
    "- create a 'pre_process_data' function to create vocabulary for the training data and generating functions\n",
    "- modify train to train over the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class SentimentNetwork():\n",
    "    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \n",
    "        # Seed the random number generator for debugging\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(self.review_vocab_size, hidden_nodes, 1, learning_rate)\n",
    "    \n",
    "    # Process all the review and label data and form unique dictionarys\n",
    "    # Give each word a unique index for entry into the network\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        # Creates a dictionary that contains one of each different word\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(' '):\n",
    "                review_vocab.add(word)\n",
    "        \n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # Creates a dictionary that contains one of each label type [IN our case 'POSITIVE' or 'NEGATIVE']\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "                \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of each dictionary\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Give each word a uniquely identifying index\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Give each label an identifying index [in our case only 0 or 1]\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "    \n",
    "    # Initialize all the network parameters\n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set the number of nodes for all three layers\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # Initialise weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1, input_nodes))\n",
    "    \n",
    "    # Activation function\n",
    "    def sigmoid(self, x, deriv=False):\n",
    "        if deriv:\n",
    "            return x * (1 - x)\n",
    "        else:\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # Reset the layer for the next pass and add the new words from the review\n",
    "    def update_input_layer(self, review):\n",
    "        # Clear the previous state and set to 0\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(' '):\n",
    "            if (word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] += 1\n",
    "    \n",
    "    # Get the neumerical reprisentation of the output\n",
    "    def get_target_for_label(self, label):\n",
    "        if label == 'POSITIVE':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # Train the network\n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # Check that the inputs match the outputs\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        # Log the start time\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            ## Forward Pass ##\n",
    "            \n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "            \n",
    "            # Hidden Layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            ## Backwards Pass ##\n",
    "            \n",
    "            # Output Error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
    "            layer_2_delta = layer_2_error * self.sigmoid(layer_2, True)\n",
    "            \n",
    "            # Hidden Error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)\n",
    "            layer_1_delta = layer_1_error\n",
    "            \n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate\n",
    "            \n",
    "            if (np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    # Test the network\n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            \n",
    "            if pred == testing_labels[i]:\n",
    "                correct += 1\n",
    "                \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    # Forward propogate        \n",
    "    def run(self, review):\n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create an instance of the network and train it on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):682.6% #Correct:500 #Tested:1000 Testing Accuracy:50.0%"
     ]
    }
   ],
   "source": [
    "# evaluate our model before training (just to show how horrible it is)\n",
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):147.8 #Correct:1250 #Trained:2501 Training Accuracy:49.9%\n",
      "Progress:20.8% Speed(reviews/sec):169.2 #Correct:2500 #Trained:5001 Training Accuracy:49.9%\n",
      "Progress:31.2% Speed(reviews/sec):179.1 #Correct:3750 #Trained:7501 Training Accuracy:49.9%\n",
      "Progress:41.6% Speed(reviews/sec):182.8 #Correct:5000 #Trained:10001 Training Accuracy:49.9%\n",
      "Progress:52.0% Speed(reviews/sec):184.3 #Correct:6250 #Trained:12501 Training Accuracy:49.9%\n",
      "Progress:62.5% Speed(reviews/sec):178.9 #Correct:7500 #Trained:15001 Training Accuracy:49.9%\n",
      "Progress:72.9% Speed(reviews/sec):175.0 #Correct:8750 #Trained:17501 Training Accuracy:49.9%\n",
      "Progress:83.3% Speed(reviews/sec):170.0 #Correct:10000 #Trained:20001 Training Accuracy:49.9%\n",
      "Progress:93.7% Speed(reviews/sec):166.2 #Correct:11250 #Trained:22501 Training Accuracy:49.9%\n",
      "Progress:99.9% Speed(reviews/sec):164.5 #Correct:11999 #Trained:24000 Training Accuracy:49.9%"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of training was actually worse than predicting the outcome randomly. Adjustments to the learning rate had little affect and therefore there must be something wrong with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Noise\n",
    "\n",
    "Neural noise is when the important data is being drowned out by other pieces of unimportant data. \n",
    "\n",
    "An analagy would be:\n",
    ">the neural network is a spade and it helps you dig for gold. However no type of spade is going to help you get more gold if you are digging in the wrong place.\n",
    "\n",
    "To solve this we need to eliminate the noise in the data. First, lets check the data to see if there is anything that shouldn't be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function defined previously\n",
    "def update_input_layer(review):\n",
    "    \n",
    "    global layer_0\n",
    "    \n",
    "    # clear out previous state, reset the layer to be all 0s\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 27),\n",
       " ('', 18),\n",
       " ('the', 9),\n",
       " ('to', 6),\n",
       " ('high', 5),\n",
       " ('i', 5),\n",
       " ('bromwell', 4),\n",
       " ('is', 4),\n",
       " ('a', 4),\n",
       " ('teachers', 4),\n",
       " ('that', 4),\n",
       " ('of', 4),\n",
       " ('it', 2),\n",
       " ('at', 2),\n",
       " ('as', 2),\n",
       " ('school', 2),\n",
       " ('my', 2),\n",
       " ('in', 2),\n",
       " ('me', 2),\n",
       " ('students', 2),\n",
       " ('their', 2),\n",
       " ('student', 2),\n",
       " ('cartoon', 1),\n",
       " ('comedy', 1),\n",
       " ('ran', 1),\n",
       " ('same', 1),\n",
       " ('time', 1),\n",
       " ('some', 1),\n",
       " ('other', 1),\n",
       " ('programs', 1),\n",
       " ('about', 1),\n",
       " ('life', 1),\n",
       " ('such', 1),\n",
       " ('years', 1),\n",
       " ('teaching', 1),\n",
       " ('profession', 1),\n",
       " ('lead', 1),\n",
       " ('believe', 1),\n",
       " ('s', 1),\n",
       " ('satire', 1),\n",
       " ('much', 1),\n",
       " ('closer', 1),\n",
       " ('reality', 1),\n",
       " ('than', 1),\n",
       " ('scramble', 1),\n",
       " ('survive', 1),\n",
       " ('financially', 1),\n",
       " ('insightful', 1),\n",
       " ('who', 1),\n",
       " ('can', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_counter = Counter()\n",
    "\n",
    "for word in reviews[0].split(' '):\n",
    "    review_counter[word] += 1\n",
    "    \n",
    "review_counter.most_common()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we can see there are 18 instances of an empty space. As this does not convey the sentiment in any way it must be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing noise in the input data\n",
    "\n",
    "In this situation we can see that the data is being scewed by the large number of useless values. We can resolve this by changing the update_input_layer method to not incriment the word count but just log it as present!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class SentimentNetwork():\n",
    "    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \n",
    "        # Seed the random number generator for debugging\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(self.review_vocab_size, hidden_nodes, 1, learning_rate)\n",
    "    \n",
    "    # Process all the review and label data and form unique dictionarys\n",
    "    # Give each word a unique index for entry into the network\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        # Creates a dictionary that contains one of each different word\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(' '):\n",
    "                review_vocab.add(word)\n",
    "        \n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # Creates a dictionary that contains one of each label type [IN our case 'POSITIVE' or 'NEGATIVE']\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "                \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of each dictionary\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Give each word a uniquely identifying index\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Give each label an identifying index [in our case only 0 or 1]\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "    \n",
    "    # Initialize all the network parameters\n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set the number of nodes for all three layers\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # Initialise weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1, input_nodes))\n",
    "    \n",
    "    # Activation function\n",
    "    def sigmoid(self, x, deriv=False):\n",
    "        if deriv:\n",
    "            return x * (1 - x)\n",
    "        else:\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # Reset the layer for the next pass and add the new words from the review\n",
    "    def update_input_layer(self, review):\n",
    "        # Clear the previous state and set to 0\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(' '):\n",
    "            if (word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "    \n",
    "    # Get the neumerical reprisentation of the output\n",
    "    def get_target_for_label(self, label):\n",
    "        if label == 'POSITIVE':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # Train the network\n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # Check that the inputs match the outputs\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        # Log the start time\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            ## Forward Pass ##\n",
    "            \n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "            \n",
    "            # Hidden Layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            ## Backwards Pass ##\n",
    "            \n",
    "            # Output Error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
    "            layer_2_delta = layer_2_error * self.sigmoid(layer_2, True)\n",
    "            \n",
    "            # Hidden Error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)\n",
    "            layer_1_delta = layer_1_error\n",
    "            \n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate\n",
    "            \n",
    "            if (np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    # Test the network\n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            \n",
    "            if pred == testing_labels[i]:\n",
    "                correct += 1\n",
    "                \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    # Forward propogate        \n",
    "    def run(self, review):\n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):204.0 #Correct:1812 #Trained:2501 Training Accuracy:72.4%\n",
      "Progress:20.8% Speed(reviews/sec):204.2 #Correct:3800 #Trained:5001 Training Accuracy:75.9%\n",
      "Progress:31.2% Speed(reviews/sec):204.4 #Correct:5879 #Trained:7501 Training Accuracy:78.3%\n",
      "Progress:41.6% Speed(reviews/sec):204.8 #Correct:8015 #Trained:10001 Training Accuracy:80.1%\n",
      "Progress:52.0% Speed(reviews/sec):205.0 #Correct:10150 #Trained:12501 Training Accuracy:81.1%\n",
      "Progress:62.5% Speed(reviews/sec):204.7 #Correct:12298 #Trained:15001 Training Accuracy:81.9%\n",
      "Progress:72.9% Speed(reviews/sec):202.1 #Correct:14425 #Trained:17501 Training Accuracy:82.4%\n",
      "Progress:83.3% Speed(reviews/sec):201.0 #Correct:16596 #Trained:20001 Training Accuracy:82.9%\n",
      "Progress:93.7% Speed(reviews/sec):201.2 #Correct:18782 #Trained:22501 Training Accuracy:83.4%\n",
      "Progress:99.9% Speed(reviews/sec):200.3 #Correct:20105 #Trained:24000 Training Accuracy:83.7%"
     ]
    }
   ],
   "source": [
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantly we can see that the network is now training successfully; attaining an accuracy upwards of 83.5%!\n",
    "\n",
    "However the training process is still slow and we need to find remove inefficiencies from the code to make it run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):1000.% #Correct:851 #Tested:1000 Testing Accuracy:85.1%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing inefficiencies in the network\n",
    "\n",
    "Now we need to identify things that can slow down the network. Lets start by looking at layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that layer_0 is the length of the entire dictionary. However most of those inputs will simply be zero. Considering 0 * any number is always 0 it is a wasted calculation. Looking at a smaller example we can see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0 = np.zeros(10)\n",
    "\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0[4] = 1\n",
    "layer_0[9] = 1\n",
    "\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_0_1 = np.random.randn(10, 5)\n",
    "layer_0.dot(weights_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On its own this doesnt look like a problem but lets see how we can get the same results with much less computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [4,9]\n",
    "layer_1 = np.zeros(5)\n",
    "for index in indices:\n",
    "    layer_1 += (weights_0_1[index])\n",
    "    \n",
    "layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how this produces exactly the same results because 0 is a wasted value! It should also be noted that the input can only be a zero or a 1. 1 * x is always equal to x so the first layer computation can be significantly reduced!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing inefficiencies in the network\n",
    "\n",
    "Now that a serious inefficiency has been found in the network we need to actually adapt the network to handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "# Let's tweak the network from before to model these phenomena\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self,reviews):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            self.layer_0[0][self.word2index[word]] = 1\n",
    "\n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "        \n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "\n",
    "            # Hidden layer\n",
    "#             layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            \n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "        \n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "\n",
    "\n",
    "        # Hidden layer\n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):1857. #Correct:20108 #Trained:24000 Training Accuracy:83.7%"
     ]
    }
   ],
   "source": [
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):1995.% #Correct:857 #Tested:1000 Testing Accuracy:85.7%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further Noise Reduction\n",
    "\n",
    "Lets continue to reduce the amount of noise to make training even more accurate! Small changes can make a huge impact on how fast the network trains.\n",
    "\n",
    "Here we are going to look at how to seperate out the key words more effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 4.6913478822291435),\n",
       " ('paulie', 4.0775374439057197),\n",
       " ('felix', 3.1527360223636558),\n",
       " ('polanski', 2.8233610476132043),\n",
       " ('matthau', 2.8067217286092401),\n",
       " ('victoria', 2.6810215287142909),\n",
       " ('mildred', 2.6026896854443837),\n",
       " ('gandhi', 2.5389738710582761),\n",
       " ('flawless', 2.451005098112319),\n",
       " ('superbly', 2.2600254785752498),\n",
       " ('perfection', 2.1594842493533721),\n",
       " ('astaire', 2.1400661634962708),\n",
       " ('captures', 2.0386195471595809),\n",
       " ('voight', 2.0301704926730531),\n",
       " ('wonderfully', 2.0218960560332353),\n",
       " ('powell', 1.9783454248084671),\n",
       " ('brosnan', 1.9547990964725592),\n",
       " ('lily', 1.9203768470501485),\n",
       " ('bakshi', 1.9029851043382795),\n",
       " ('lincoln', 1.9014583864844796),\n",
       " ('refreshing', 1.8551812956655511),\n",
       " ('breathtaking', 1.8481124057791867),\n",
       " ('bourne', 1.8478489358790986),\n",
       " ('lemmon', 1.8458266904983307),\n",
       " ('delightful', 1.8002701588959635),\n",
       " ('flynn', 1.7996646487351682),\n",
       " ('andrews', 1.7764919970972666),\n",
       " ('homer', 1.7692866133759964),\n",
       " ('beautifully', 1.7626953362841438),\n",
       " ('soccer', 1.7578579175523736)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common()[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data being passed at the moment is full of words we can use for sentiment analysis. However it also contains many words that are not usefull to us. There are many names that occur commonly that don't really express sentiment. The next step is to remove those useless words.\n",
    "\n",
    "A good way to do this is to use bokeh; It is a data visualisation library, which will allow us to see what is going on with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"ea87c7e6-3e7c-49a7-a87d-7ba77d84a7a3\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"ea87c7e6-3e7c-49a7-a87d-7ba77d84a7a3\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"ea87c7e6-3e7c-49a7-a87d-7ba77d84a7a3\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ea87c7e6-3e7c-49a7-a87d-7ba77d84a7a3' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"ea87c7e6-3e7c-49a7-a87d-7ba77d84a7a3\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"ea87c7e6-3e7c-49a7-a87d-7ba77d84a7a3\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"bk-plotdiv\" id=\"9e083060-09b6-4862-9483-86230ae569ff\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = false;\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        document.getElementById(\"9e083060-09b6-4862-9483-86230ae569ff\").textContent = \"BokehJS successfully loaded.\";\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"9e083060-09b6-4862-9483-86230ae569ff\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid '9e083060-09b6-4862-9483-86230ae569ff' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        (function() {\n",
       "          var fn = function() {\n",
       "            var docs_json = {\"8aa54abe-d069-4dcf-9aaf-23f039396be1\":{\"roots\":{\"references\":[{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ec986694-4851-4e78-91bd-11e006d51533\",\"type\":\"BasicTicker\"}},\"id\":\"986a285c-6070-4637-bad6-b175b5839681\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"c2beca28-9329-4dc0-bf36-cac26b66d8d3\",\"type\":\"PanTool\"},{\"attributes\":{\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"a6484a78-61df-4a67-a4bd-121c3e1f31e7\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"below\":[{\"id\":\"07cee6b3-1506-4ebb-8b83-64d628d388b4\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"84e965cb-52ad-4cd0-8521-a3fcf6464d37\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"07cee6b3-1506-4ebb-8b83-64d628d388b4\",\"type\":\"LinearAxis\"},{\"id\":\"a50b1b47-2c5d-46b0-b201-3f384400ba09\",\"type\":\"Grid\"},{\"id\":\"84e965cb-52ad-4cd0-8521-a3fcf6464d37\",\"type\":\"LinearAxis\"},{\"id\":\"986a285c-6070-4637-bad6-b175b5839681\",\"type\":\"Grid\"},{\"id\":\"b3a71ec8-aa41-4f9e-a79e-1853f19f506c\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"3156a647-edea-459d-85bd-519b0fd5620e\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"037ae5ed-2f93-4b0b-9ec9-9d0d77e9429d\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"5911e532-8801-471c-b79d-d69998f85dc3\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"bb5d3585-3128-4a52-9a3d-a5874fb901d8\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"a8372a26-3ca6-4208-b841-c217a7a696ee\",\"type\":\"DataRange1d\"}},\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"250bc6f7-c344-4861-aad1-e79409d45b0a\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"96f1d6d1-3a0d-4b48-a177-4397b7a6ffb6\",\"type\":\"SaveTool\"},{\"attributes\":{\"plot\":null,\"text\":\"Word positive/negative Affinity Distribution\"},\"id\":\"3156a647-edea-459d-85bd-519b0fd5620e\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"8171f858-580b-421b-9b61-1b3cb6a7500f\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1e80afc3-75d3-456f-a945-565cb0388035\",\"type\":\"Quad\"},\"hover_glyph\":null,\"nonselection_glyph\":{\"id\":\"3c456129-cc2f-4567-8fc0-7ff3ba11fc47\",\"type\":\"Quad\"},\"selection_glyph\":null},\"id\":\"b3a71ec8-aa41-4f9e-a79e-1853f19f506c\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"left\",\"right\",\"top\"],\"data\":{\"left\":{\"__ndarray__\":\"Cvm3za5PEMCZHufvxesPwB5LXkQuOA/AonfVmJaEDsAnpEzt/tANwKzQw0FnHQ3AMf06ls9pDMC2KbLqN7YLwDpWKT+gAgvAv4KgkwhPCsBErxfocJsJwMnbjjzZ5wjATggGkUE0CMDSNH3lqYAHwFhh9DkSzQbA3I1rjnoZBsBhuuLi4mUFwObmWTdLsgTAahPRi7P+A8DwP0jgG0sDwHRsvzSElwLA+Zg2iezjAcB+xa3dVDABwAPyJDK9fADAED04DUuS/78Ylia2Gyv+vyLvFF/sw/y/LEgDCL1c+782ofGwjfX5v0D631lejvi/SFPOAi8n979SrLyr/7/1v1wFq1TQWPS/Zl6Z/aDx8r9wt4emcYrxv3gQdk9CI/C/BNPI8CV47b8YhaVCx6nqvyw3gpRo2+e/QOle5gkN5b9Qmzs4qz7iv8iaMBSZ4N6/8P7pt9tD2b8YY6NbHqfTv4COuf7BFMy/0FYsRkfbwL+AfHw2Moemv4BiuKu4XqY/QFB74yjRwD8AiAicowrMP+DfSioPotM/sHuRhsw+2T+QF9jiidveP7BZj58jPOI/oKeyTYIK5T+Q9dX74NjnP3hD+ak/p+o/aJEcWJ517T+o7x+D/iHwP6CWMdotifE/mD1DMV3w8j+M5FSIjFf0P4SLZt+7vvU/eDJ4Nusl9z9w2YmNGo34P2iAm+RJ9Pk/XCetO3lb+z9Uzr6SqML8P0h10OnXKf4/QBziQAeR/z+c4flLG3wAQBa1gveyLwFAkogLo0rjAUAMXJRO4pYCQIgvHfp5SgNABAOmpRH+A0B+1i5RqbEEQPqpt/xAZQVAdH1AqNgYBkDwUMlTcMwGQGwkUv8HgAdA5vfaqp8zCEBiy2NWN+cIQNye7AHPmglAWHJ1rWZOCkDSRf5Y/gELQE4ZhwSWtQtAyuwPsC1pDEBEwJhbxRwNQMCTIQdd0A1AOmeqsvSDDkC2OjNejDcPQDAOvAkk6w9A1nCi2l1PEECU2mawKakQQFJEK4b1AhFADq7vW8FcEUDMF7QxjbYRQIqBeAdZEBJASOs83SRqEkA=\",\"dtype\":\"float64\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"mR7n78XrD8AeS15ELjgPwKJ31ZiWhA7AJ6RM7f7QDcCs0MNBZx0NwDH9OpbPaQzAtimy6je2C8A6Vik/oAILwL+CoJMITwrARK8X6HCbCcDJ24482ecIwE4IBpFBNAjA0jR95amAB8BYYfQ5Es0GwNyNa456GQbAYbri4uJlBcDm5lk3S7IEwGoT0Yuz/gPA8D9I4BtLA8B0bL80hJcCwPmYNons4wHAfsWt3VQwAcAD8iQyvXwAwBA9OA1Lkv+/GJYmthsr/r8i7xRf7MP8vyxIAwi9XPu/NqHxsI31+b9A+t9ZXo74v0hTzgIvJ/e/Uqy8q/+/9b9cBatU0Fj0v2Zemf2g8fK/cLeHpnGK8b94EHZPQiPwvwTTyPAleO2/GIWlQsep6r8sN4KUaNvnv0DpXuYJDeW/UJs7OKs+4r/ImjAUmeDev/D+6bfbQ9m/GGOjWx6n07+Ajrn+wRTMv9BWLEZH28C/gHx8NjKHpr+AYriruF6mP0BQe+Mo0cA/AIgInKMKzD/g30oqD6LTP7B7kYbMPtk/kBfY4onb3j+wWY+fIzziP6Cnsk2CCuU/kPXV++DY5z94Q/mpP6fqP2iRHFiede0/qO8fg/4h8D+gljHaLYnxP5g9QzFd8PI/jORUiIxX9D+Ei2bfu771P3gyeDbrJfc/cNmJjRqN+D9ogJvkSfT5P1wnrTt5W/s/VM6+kqjC/D9IddDp1yn+P0Ac4kAHkf8/nOH5Sxt8AEAWtYL3si8BQJKIC6NK4wFADFyUTuKWAkCILx36eUoDQAQDpqUR/gNAftYuUamxBED6qbf8QGUFQHR9QKjYGAZA8FDJU3DMBkBsJFL/B4AHQOb32qqfMwhAYstjVjfnCEDcnuwBz5oJQFhyda1mTgpA0kX+WP4BC0BOGYcElrULQMrsD7AtaQxARMCYW8UcDUDAkyEHXdANQDpnqrL0gw5AtjozXow3D0AwDrwJJOsPQNZwotpdTxBAlNpmsCmpEEBSRCuG9QIRQA6u71vBXBFAzBe0MY22EUCKgXgHWRASQEjrPN0kahJABlUBs/DDEkA=\",\"dtype\":\"float64\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"s6auGMn1ZT+zpq4YyfVlPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALOmrhjJ9WU/AAAAAAAAAAAAAAAAAAAAALOmrhjJ9WU/k6auGMn1ZT8AAAAAAAAAAJOmrhjJ9XU/AAAAAAAAAAAAAAAAAAAAAJOmrhjJ9WU/0qauGMn1dT+Tpq4YyfV1P7OmrhjJ9YU/Bf2C0lZ4gD+zpq4YyfWFP7OmrhjJ9WU/wdGY9Q83kz9fUNpeO3ObPwX9gtJWeJA/s6auGMn1lT/d0Zj1DzeTP8HRmPUPN6M/9GVPzd4Tqj+Je8Q7grSoP/RlT83eE6o/O3JIGwUosT9zD3sTUZGvP/RlT83eE7o/9GVPzd4Tuj+ht+X2LdDAP+gbdGF3pcY/2lQY73k5zz+nXNOsYYfSP6wBwWKVPtQ/xJV3OmQb2z9Z/6EadlviPyTgAZkQXOU/7sBhF6tc6D9YgiEU4F3uP2El8IH0Me4/XSz8TJet6j/wnIMFB5fnP/EzCBg6Kec/9UZePr7m4z89itzRx6vhP+ED4Kq0IdY/9UZePr7m0z+XmrXKouHOP/nrS/TxncU/Zbwjh2yWxD+hOmXwl9K8P/VGXj6+5rM/mzHpzxpGtT/8kDmqJVWnP2W8I4dslqQ/wdGY9Q83oz8qvCOHbJakP/jRmPUPN5M/wdGY9Q83kz8d/YLSVniQP5OmrhjJ9YU/k6auGMn1hT/Spq4YyfVlP5OmrhjJ9WU/0qauGMn1ZT8AAAAAAAAAAJOmrhjJ9WU/0qauGMn1ZT+Tpq4YyfVlP9KmrhjJ9WU/k6auGMn1dT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADSpq4YyfVlPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAk6auGMn1ZT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAk6auGMn1ZT8=\",\"dtype\":\"float64\",\"shape\":[100]}}},\"id\":\"8171f858-580b-421b-9b61-1b3cb6a7500f\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"3c456129-cc2f-4567-8fc0-7ff3ba11fc47\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"db23dae3-c9ef-4041-85d3-0070225589e2\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"bb5d3585-3128-4a52-9a3d-a5874fb901d8\",\"type\":\"DataRange1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"c2beca28-9329-4dc0-bf36-cac26b66d8d3\",\"type\":\"PanTool\"},{\"id\":\"a6484a78-61df-4a67-a4bd-121c3e1f31e7\",\"type\":\"WheelZoomTool\"},{\"id\":\"250bc6f7-c344-4861-aad1-e79409d45b0a\",\"type\":\"ResetTool\"},{\"id\":\"96f1d6d1-3a0d-4b48-a177-4397b7a6ffb6\",\"type\":\"SaveTool\"}]},\"id\":\"5911e532-8801-471c-b79d-d69998f85dc3\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"ccb1bc94-e52c-437b-bbda-82aff57331f4\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"037ae5ed-2f93-4b0b-9ec9-9d0d77e9429d\",\"type\":\"ToolEvents\"},{\"attributes\":{\"formatter\":{\"id\":\"ccb1bc94-e52c-437b-bbda-82aff57331f4\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"f9f55fca-680d-4107-a90b-9487c4dac2f7\",\"type\":\"BasicTicker\"}},\"id\":\"07cee6b3-1506-4ebb-8b83-64d628d388b4\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null},\"id\":\"a8372a26-3ca6-4208-b841-c217a7a696ee\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"f9f55fca-680d-4107-a90b-9487c4dac2f7\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1e80afc3-75d3-456f-a945-565cb0388035\",\"type\":\"Quad\"},{\"attributes\":{\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"f9f55fca-680d-4107-a90b-9487c4dac2f7\",\"type\":\"BasicTicker\"}},\"id\":\"a50b1b47-2c5d-46b0-b201-3f384400ba09\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"db23dae3-c9ef-4041-85d3-0070225589e2\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ec986694-4851-4e78-91bd-11e006d51533\",\"type\":\"BasicTicker\"}},\"id\":\"84e965cb-52ad-4cd0-8521-a3fcf6464d37\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"ec986694-4851-4e78-91bd-11e006d51533\",\"type\":\"BasicTicker\"}],\"root_ids\":[\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.4\"}};\n",
       "            var render_items = [{\"docid\":\"8aa54abe-d069-4dcf-9aaf-23f039396be1\",\"elementid\":\"9e083060-09b6-4862-9483-86230ae569ff\",\"modelid\":\"b3626e9c-2646-4aa5-9361-b5f8288fcbf5\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "          };\n",
       "          if (document.readyState != \"loading\") fn();\n",
       "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "        })();\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === true) {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (force !== true) {\n",
       "        var cell = $(document.getElementById(\"9e083060-09b6-4862-9483-86230ae569ff\")).parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, edges = np.histogram(list(map(lambda x:x[1], pos_neg_ratios.most_common())), density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools='pan,wheel_zoom,reset,save', toolbar_location='above', title=\"Word positive/negative Affinity Distribution\")\n",
    "\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that there are a large number of words lying in the middle of the x axis. This shows that there are a large number of words that have little meaning and less words on the sides with meaning.\n",
    "\n",
    "This is good because we can add a cut-off point which will discount the useless words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data to remove the noise\n",
    "\n",
    "Now we can use what we have learned to increase the accuracy of the network by introducing a fequency cut-off. This will remove the useless words like '.' and ''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak the network from before to model these phenomena\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,min_count = 10,polarity_cutoff = 0.1,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, polarity_cutoff, min_count)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self,reviews, polarity_cutoff,min_count):\n",
    "        \n",
    "        positive_counts = Counter()\n",
    "        negative_counts = Counter()\n",
    "        total_counts = Counter()\n",
    "\n",
    "        for i in range(len(reviews)):\n",
    "            if(labels[i] == 'POSITIVE'):\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    positive_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "            else:\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    negative_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "\n",
    "        pos_neg_ratios = Counter()\n",
    "\n",
    "        for term,cnt in list(total_counts.most_common()):\n",
    "            if(cnt >= 50):\n",
    "                pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "                pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "        for word,ratio in pos_neg_ratios.most_common():\n",
    "            if(ratio > 1):\n",
    "                pos_neg_ratios[word] = np.log(ratio)\n",
    "            else:\n",
    "                pos_neg_ratios[word] = -np.log((1 / (ratio + 0.01)))\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                if(total_counts[word] > min_count):\n",
    "                    if(word in pos_neg_ratios.keys()):\n",
    "                        if((pos_neg_ratios[word] >= polarity_cutoff) or (pos_neg_ratios[word] <= -polarity_cutoff)):\n",
    "                            review_vocab.add(word)\n",
    "                    else:\n",
    "                        review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            self.layer_0[0][self.word2index[word]] = 1\n",
    "\n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "        \n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "\n",
    "            # Hidden layer\n",
    "#             layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            \n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
    "                correct_so_far += 1\n",
    "            if(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "        \n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "\n",
    "\n",
    "        # Hidden layer\n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_count_cutoff: In order to be included it must be more frequent than this value\n",
    "polarity_cutoff: Words must be left or right of the histogram by this much to be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=20,polarity_cutoff=0.05,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):2012. #Correct:20461 #Trained:24000 Training Accuracy:85.2%"
     ]
    }
   ],
   "source": [
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):2280.% #Correct:859 #Tested:1000 Testing Accuracy:85.9%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the useless data has clearly had a positive impact on the overall accuracy of the network during testing. It has also had a small increase in the speed because the dictionary is smaller. \n",
    "\n",
    "Increasing the polarity cutoff will speed up the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=20,polarity_cutoff=0.8,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):6837. #Correct:20552 #Trained:24000 Training Accuracy:85.6%"
     ]
    }
   ],
   "source": [
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0% #Correct:0 #Tested:1 Testing Accuracy:0.0%\r",
      "Progress:0.1% Speed(reviews/sec):1942.% #Correct:1 #Tested:2 Testing Accuracy:50.0%\r",
      "Progress:0.2% Speed(reviews/sec):2123.% #Correct:2 #Tested:3 Testing Accuracy:66.6%\r",
      "Progress:0.3% Speed(reviews/sec):2560.% #Correct:3 #Tested:4 Testing Accuracy:75.0%\r",
      "Progress:0.4% Speed(reviews/sec):3084.% #Correct:3 #Tested:5 Testing Accuracy:60.0%\r",
      "Progress:0.5% Speed(reviews/sec):3564.% #Correct:4 #Tested:6 Testing Accuracy:66.6%\r",
      "Progress:0.6% Speed(reviews/sec):3016.% #Correct:5 #Tested:7 Testing Accuracy:71.4%\r",
      "Progress:0.7% Speed(reviews/sec):3083.% #Correct:6 #Tested:8 Testing Accuracy:75.0%\r",
      "Progress:0.8% Speed(reviews/sec):3262.% #Correct:7 #Tested:9 Testing Accuracy:77.7%\r",
      "Progress:0.9% Speed(reviews/sec):2936.% #Correct:8 #Tested:10 Testing Accuracy:80.0%\r",
      "Progress:1.0% Speed(reviews/sec):3034.% #Correct:9 #Tested:11 Testing Accuracy:81.8%\r",
      "Progress:1.1% Speed(reviews/sec):3159.% #Correct:10 #Tested:12 Testing Accuracy:83.3%\r",
      "Progress:1.2% Speed(reviews/sec):3192.% #Correct:10 #Tested:13 Testing Accuracy:76.9%\r",
      "Progress:1.3% Speed(reviews/sec):3282.% #Correct:11 #Tested:14 Testing Accuracy:78.5%\r",
      "Progress:1.4% Speed(reviews/sec):3375.% #Correct:11 #Tested:15 Testing Accuracy:73.3%\r",
      "Progress:1.5% Speed(reviews/sec):3455.% #Correct:12 #Tested:16 Testing Accuracy:75.0%\r",
      "Progress:1.6% Speed(reviews/sec):3365.% #Correct:13 #Tested:17 Testing Accuracy:76.4%\r",
      "Progress:1.7% Speed(reviews/sec):3377.% #Correct:14 #Tested:18 Testing Accuracy:77.7%\r",
      "Progress:1.8% Speed(reviews/sec):3465.% #Correct:15 #Tested:19 Testing Accuracy:78.9%\r",
      "Progress:1.9% Speed(reviews/sec):3425.% #Correct:16 #Tested:20 Testing Accuracy:80.0%\r",
      "Progress:2.0% Speed(reviews/sec):3443.% #Correct:17 #Tested:21 Testing Accuracy:80.9%\r",
      "Progress:2.1% Speed(reviews/sec):3480.% #Correct:18 #Tested:22 Testing Accuracy:81.8%\r",
      "Progress:2.2% Speed(reviews/sec):3515.% #Correct:19 #Tested:23 Testing Accuracy:82.6%\r",
      "Progress:2.3% Speed(reviews/sec):3534.% #Correct:20 #Tested:24 Testing Accuracy:83.3%\r",
      "Progress:2.4% Speed(reviews/sec):3450.% #Correct:21 #Tested:25 Testing Accuracy:84.0%\r",
      "Progress:2.5% Speed(reviews/sec):3527.% #Correct:22 #Tested:26 Testing Accuracy:84.6%\r",
      "Progress:2.6% Speed(reviews/sec):3574.% #Correct:22 #Tested:27 Testing Accuracy:81.4%\r",
      "Progress:2.7% Speed(reviews/sec):3446.% #Correct:23 #Tested:28 Testing Accuracy:82.1%\r",
      "Progress:2.8% Speed(reviews/sec):3456.% #Correct:24 #Tested:29 Testing Accuracy:82.7%\r",
      "Progress:2.9% Speed(reviews/sec):3471.% #Correct:25 #Tested:30 Testing Accuracy:83.3%\r",
      "Progress:3.0% Speed(reviews/sec):3496.% #Correct:25 #Tested:31 Testing Accuracy:80.6%\r",
      "Progress:3.1% Speed(reviews/sec):3532.% #Correct:26 #Tested:32 Testing Accuracy:81.2%\r",
      "Progress:3.2% Speed(reviews/sec):3554.% #Correct:27 #Tested:33 Testing Accuracy:81.8%\r",
      "Progress:3.3% Speed(reviews/sec):3585.% #Correct:28 #Tested:34 Testing Accuracy:82.3%\r",
      "Progress:3.4% Speed(reviews/sec):3591.% #Correct:29 #Tested:35 Testing Accuracy:82.8%\r",
      "Progress:3.5% Speed(reviews/sec):3644.% #Correct:30 #Tested:36 Testing Accuracy:83.3%\r",
      "Progress:3.6% Speed(reviews/sec):3634.% #Correct:31 #Tested:37 Testing Accuracy:83.7%\r",
      "Progress:3.7% Speed(reviews/sec):3676.% #Correct:32 #Tested:38 Testing Accuracy:84.2%\r",
      "Progress:3.8% Speed(reviews/sec):3529.% #Correct:33 #Tested:39 Testing Accuracy:84.6%\r",
      "Progress:3.9% Speed(reviews/sec):3440.% #Correct:33 #Tested:40 Testing Accuracy:82.5%\r",
      "Progress:4.0% Speed(reviews/sec):3445.% #Correct:34 #Tested:41 Testing Accuracy:82.9%\r",
      "Progress:4.1% Speed(reviews/sec):3477.% #Correct:35 #Tested:42 Testing Accuracy:83.3%\r",
      "Progress:4.2% Speed(reviews/sec):3348.% #Correct:36 #Tested:43 Testing Accuracy:83.7%\r",
      "Progress:4.3% Speed(reviews/sec):3313.% #Correct:37 #Tested:44 Testing Accuracy:84.0%\r",
      "Progress:4.4% Speed(reviews/sec):3280.% #Correct:38 #Tested:45 Testing Accuracy:84.4%\r",
      "Progress:4.5% Speed(reviews/sec):3237.% #Correct:39 #Tested:46 Testing Accuracy:84.7%\r",
      "Progress:4.6% Speed(reviews/sec):3196.% #Correct:40 #Tested:47 Testing Accuracy:85.1%\r",
      "Progress:4.7% Speed(reviews/sec):3226.% #Correct:41 #Tested:48 Testing Accuracy:85.4%\r",
      "Progress:4.8% Speed(reviews/sec):3231.% #Correct:42 #Tested:49 Testing Accuracy:85.7%\r",
      "Progress:4.9% Speed(reviews/sec):3256.% #Correct:43 #Tested:50 Testing Accuracy:86.0%\r",
      "Progress:5.0% Speed(reviews/sec):3284.% #Correct:44 #Tested:51 Testing Accuracy:86.2%\r",
      "Progress:5.1% Speed(reviews/sec):3316.% #Correct:45 #Tested:52 Testing Accuracy:86.5%\r",
      "Progress:5.2% Speed(reviews/sec):3299.% #Correct:46 #Tested:53 Testing Accuracy:86.7%\r",
      "Progress:5.3% Speed(reviews/sec):3313.% #Correct:47 #Tested:54 Testing Accuracy:87.0%\r",
      "Progress:5.4% Speed(reviews/sec):3336.% #Correct:48 #Tested:55 Testing Accuracy:87.2%\r",
      "Progress:5.5% Speed(reviews/sec):3367.% #Correct:49 #Tested:56 Testing Accuracy:87.5%\r",
      "Progress:5.6% Speed(reviews/sec):3309.% #Correct:50 #Tested:57 Testing Accuracy:87.7%\r",
      "Progress:5.7% Speed(reviews/sec):3330.% #Correct:51 #Tested:58 Testing Accuracy:87.9%\r",
      "Progress:5.8% Speed(reviews/sec):3357.% #Correct:52 #Tested:59 Testing Accuracy:88.1%\r",
      "Progress:5.9% Speed(reviews/sec):3378.% #Correct:53 #Tested:60 Testing Accuracy:88.3%\r",
      "Progress:6.0% Speed(reviews/sec):3388.% #Correct:53 #Tested:61 Testing Accuracy:86.8%\r",
      "Progress:6.1% Speed(reviews/sec):3393.% #Correct:54 #Tested:62 Testing Accuracy:87.0%\r",
      "Progress:6.2% Speed(reviews/sec):3419.% #Correct:55 #Tested:63 Testing Accuracy:87.3%\r",
      "Progress:6.3% Speed(reviews/sec):3443.% #Correct:55 #Tested:64 Testing Accuracy:85.9%\r",
      "Progress:6.4% Speed(reviews/sec):3443.% #Correct:55 #Tested:65 Testing Accuracy:84.6%\r",
      "Progress:6.5% Speed(reviews/sec):3463.% #Correct:55 #Tested:66 Testing Accuracy:83.3%\r",
      "Progress:6.6% Speed(reviews/sec):3475.% #Correct:56 #Tested:67 Testing Accuracy:83.5%\r",
      "Progress:6.7% Speed(reviews/sec):3493.% #Correct:57 #Tested:68 Testing Accuracy:83.8%\r",
      "Progress:6.8% Speed(reviews/sec):3508.% #Correct:58 #Tested:69 Testing Accuracy:84.0%\r",
      "Progress:6.9% Speed(reviews/sec):3514.% #Correct:59 #Tested:70 Testing Accuracy:84.2%\r",
      "Progress:7.0% Speed(reviews/sec):3518.% #Correct:59 #Tested:71 Testing Accuracy:83.0%\r",
      "Progress:7.1% Speed(reviews/sec):3541.% #Correct:60 #Tested:72 Testing Accuracy:83.3%\r",
      "Progress:7.2% Speed(reviews/sec):3543.% #Correct:61 #Tested:73 Testing Accuracy:83.5%\r",
      "Progress:7.3% Speed(reviews/sec):3562.% #Correct:62 #Tested:74 Testing Accuracy:83.7%\r",
      "Progress:7.4% Speed(reviews/sec):3576.% #Correct:63 #Tested:75 Testing Accuracy:84.0%\r",
      "Progress:7.5% Speed(reviews/sec):3590.% #Correct:64 #Tested:76 Testing Accuracy:84.2%\r",
      "Progress:7.6% Speed(reviews/sec):3601.% #Correct:65 #Tested:77 Testing Accuracy:84.4%\r",
      "Progress:7.7% Speed(reviews/sec):3618.% #Correct:66 #Tested:78 Testing Accuracy:84.6%\r",
      "Progress:7.8% Speed(reviews/sec):3635.% #Correct:67 #Tested:79 Testing Accuracy:84.8%\r",
      "Progress:7.9% Speed(reviews/sec):3649.% #Correct:68 #Tested:80 Testing Accuracy:85.0%\r",
      "Progress:8.0% Speed(reviews/sec):3675.% #Correct:69 #Tested:81 Testing Accuracy:85.1%\r",
      "Progress:8.1% Speed(reviews/sec):3622.% #Correct:69 #Tested:82 Testing Accuracy:84.1%\r",
      "Progress:8.2% Speed(reviews/sec):3622.% #Correct:70 #Tested:83 Testing Accuracy:84.3%\r",
      "Progress:8.3% Speed(reviews/sec):3619.% #Correct:71 #Tested:84 Testing Accuracy:84.5%\r",
      "Progress:8.4% Speed(reviews/sec):3626.% #Correct:72 #Tested:85 Testing Accuracy:84.7%\r",
      "Progress:8.5% Speed(reviews/sec):3648.% #Correct:73 #Tested:86 Testing Accuracy:84.8%\r",
      "Progress:8.6% Speed(reviews/sec):3647.% #Correct:74 #Tested:87 Testing Accuracy:85.0%\r",
      "Progress:8.7% Speed(reviews/sec):3660.% #Correct:74 #Tested:88 Testing Accuracy:84.0%\r",
      "Progress:8.8% Speed(reviews/sec):3676.% #Correct:75 #Tested:89 Testing Accuracy:84.2%\r",
      "Progress:8.9% Speed(reviews/sec):3646.% #Correct:76 #Tested:90 Testing Accuracy:84.4%\r",
      "Progress:9.0% Speed(reviews/sec):3645.% #Correct:77 #Tested:91 Testing Accuracy:84.6%\r",
      "Progress:9.1% Speed(reviews/sec):3648.% #Correct:78 #Tested:92 Testing Accuracy:84.7%\r",
      "Progress:9.2% Speed(reviews/sec):3663.% #Correct:79 #Tested:93 Testing Accuracy:84.9%\r",
      "Progress:9.3% Speed(reviews/sec):3658.% #Correct:80 #Tested:94 Testing Accuracy:85.1%\r",
      "Progress:9.4% Speed(reviews/sec):3667.% #Correct:81 #Tested:95 Testing Accuracy:85.2%\r",
      "Progress:9.5% Speed(reviews/sec):3681.% #Correct:82 #Tested:96 Testing Accuracy:85.4%\r",
      "Progress:9.6% Speed(reviews/sec):3686.% #Correct:83 #Tested:97 Testing Accuracy:85.5%\r",
      "Progress:9.7% Speed(reviews/sec):3686.% #Correct:84 #Tested:98 Testing Accuracy:85.7%\r",
      "Progress:9.8% Speed(reviews/sec):3698.% #Correct:85 #Tested:99 Testing Accuracy:85.8%\r",
      "Progress:9.9% Speed(reviews/sec):3704.% #Correct:86 #Tested:100 Testing Accuracy:86.0%\r",
      "Progress:10.0% Speed(reviews/sec):3723.% #Correct:87 #Tested:101 Testing Accuracy:86.1%\r",
      "Progress:10.1% Speed(reviews/sec):3733.% #Correct:88 #Tested:102 Testing Accuracy:86.2%\r",
      "Progress:10.2% Speed(reviews/sec):3742.% #Correct:89 #Tested:103 Testing Accuracy:86.4%\r",
      "Progress:10.3% Speed(reviews/sec):3732.% #Correct:89 #Tested:104 Testing Accuracy:85.5%\r",
      "Progress:10.4% Speed(reviews/sec):3741.% #Correct:90 #Tested:105 Testing Accuracy:85.7%\r",
      "Progress:10.5% Speed(reviews/sec):3765.% #Correct:91 #Tested:106 Testing Accuracy:85.8%\r",
      "Progress:10.6% Speed(reviews/sec):3767.% #Correct:92 #Tested:107 Testing Accuracy:85.9%\r",
      "Progress:10.7% Speed(reviews/sec):3776.% #Correct:93 #Tested:108 Testing Accuracy:86.1%\r",
      "Progress:10.8% Speed(reviews/sec):3788.% #Correct:94 #Tested:109 Testing Accuracy:86.2%\r",
      "Progress:10.9% Speed(reviews/sec):3799.% #Correct:94 #Tested:110 Testing Accuracy:85.4%\r",
      "Progress:11.0% Speed(reviews/sec):3814.% #Correct:95 #Tested:111 Testing Accuracy:85.5%\r",
      "Progress:11.1% Speed(reviews/sec):3819.% #Correct:96 #Tested:112 Testing Accuracy:85.7%\r",
      "Progress:11.2% Speed(reviews/sec):3825.% #Correct:97 #Tested:113 Testing Accuracy:85.8%\r",
      "Progress:11.3% Speed(reviews/sec):3822.% #Correct:98 #Tested:114 Testing Accuracy:85.9%\r",
      "Progress:11.4% Speed(reviews/sec):3825.% #Correct:99 #Tested:115 Testing Accuracy:86.0%\r",
      "Progress:11.5% Speed(reviews/sec):3842.% #Correct:100 #Tested:116 Testing Accuracy:86.2%\r",
      "Progress:11.6% Speed(reviews/sec):3852.% #Correct:101 #Tested:117 Testing Accuracy:86.3%\r",
      "Progress:11.7% Speed(reviews/sec):3854.% #Correct:101 #Tested:118 Testing Accuracy:85.5%\r",
      "Progress:11.8% Speed(reviews/sec):3865.% #Correct:102 #Tested:119 Testing Accuracy:85.7%\r",
      "Progress:11.9% Speed(reviews/sec):3868.% #Correct:103 #Tested:120 Testing Accuracy:85.8%\r",
      "Progress:12.0% Speed(reviews/sec):3885.% #Correct:103 #Tested:121 Testing Accuracy:85.1%\r",
      "Progress:12.1% Speed(reviews/sec):3892.% #Correct:104 #Tested:122 Testing Accuracy:85.2%\r",
      "Progress:12.2% Speed(reviews/sec):3896.% #Correct:105 #Tested:123 Testing Accuracy:85.3%\r",
      "Progress:12.3% Speed(reviews/sec):3888.% #Correct:106 #Tested:124 Testing Accuracy:85.4%\r",
      "Progress:12.4% Speed(reviews/sec):3886.% #Correct:107 #Tested:125 Testing Accuracy:85.6%\r",
      "Progress:12.5% Speed(reviews/sec):3895.% #Correct:108 #Tested:126 Testing Accuracy:85.7%\r",
      "Progress:12.6% Speed(reviews/sec):3906.% #Correct:109 #Tested:127 Testing Accuracy:85.8%\r",
      "Progress:12.7% Speed(reviews/sec):3898.% #Correct:110 #Tested:128 Testing Accuracy:85.9%\r",
      "Progress:12.8% Speed(reviews/sec):3908.% #Correct:111 #Tested:129 Testing Accuracy:86.0%\r",
      "Progress:12.9% Speed(reviews/sec):3916.% #Correct:112 #Tested:130 Testing Accuracy:86.1%\r",
      "Progress:13.0% Speed(reviews/sec):3931.% #Correct:112 #Tested:131 Testing Accuracy:85.4%\r",
      "Progress:13.1% Speed(reviews/sec):3942.% #Correct:113 #Tested:132 Testing Accuracy:85.6%\r",
      "Progress:13.2% Speed(reviews/sec):3951.% #Correct:114 #Tested:133 Testing Accuracy:85.7%\r",
      "Progress:13.3% Speed(reviews/sec):3956.% #Correct:115 #Tested:134 Testing Accuracy:85.8%\r",
      "Progress:13.4% Speed(reviews/sec):3957.% #Correct:116 #Tested:135 Testing Accuracy:85.9%\r",
      "Progress:13.5% Speed(reviews/sec):3966.% #Correct:116 #Tested:136 Testing Accuracy:85.2%\r",
      "Progress:13.6% Speed(reviews/sec):3974.% #Correct:117 #Tested:137 Testing Accuracy:85.4%\r",
      "Progress:13.7% Speed(reviews/sec):3982.% #Correct:118 #Tested:138 Testing Accuracy:85.5%\r",
      "Progress:13.8% Speed(reviews/sec):3990.% #Correct:119 #Tested:139 Testing Accuracy:85.6%\r",
      "Progress:13.9% Speed(reviews/sec):3978.% #Correct:120 #Tested:140 Testing Accuracy:85.7%\r",
      "Progress:14.0% Speed(reviews/sec):3997.% #Correct:121 #Tested:141 Testing Accuracy:85.8%\r",
      "Progress:14.1% Speed(reviews/sec):4001.% #Correct:122 #Tested:142 Testing Accuracy:85.9%\r",
      "Progress:14.2% Speed(reviews/sec):4010.% #Correct:123 #Tested:143 Testing Accuracy:86.0%\r",
      "Progress:14.3% Speed(reviews/sec):4018.% #Correct:124 #Tested:144 Testing Accuracy:86.1%\r",
      "Progress:14.4% Speed(reviews/sec):4016.% #Correct:125 #Tested:145 Testing Accuracy:86.2%\r",
      "Progress:14.5% Speed(reviews/sec):4023.% #Correct:126 #Tested:146 Testing Accuracy:86.3%\r",
      "Progress:14.6% Speed(reviews/sec):4010.% #Correct:127 #Tested:147 Testing Accuracy:86.3%\r",
      "Progress:14.7% Speed(reviews/sec):4012.% #Correct:128 #Tested:148 Testing Accuracy:86.4%\r",
      "Progress:14.8% Speed(reviews/sec):4020.% #Correct:129 #Tested:149 Testing Accuracy:86.5%\r",
      "Progress:14.9% Speed(reviews/sec):4027.% #Correct:130 #Tested:150 Testing Accuracy:86.6%\r",
      "Progress:15.0% Speed(reviews/sec):4035.% #Correct:131 #Tested:151 Testing Accuracy:86.7%\r",
      "Progress:15.1% Speed(reviews/sec):4043.% #Correct:132 #Tested:152 Testing Accuracy:86.8%\r",
      "Progress:15.2% Speed(reviews/sec):4037.% #Correct:133 #Tested:153 Testing Accuracy:86.9%\r",
      "Progress:15.3% Speed(reviews/sec):4031.% #Correct:134 #Tested:154 Testing Accuracy:87.0%\r",
      "Progress:15.4% Speed(reviews/sec):4035.% #Correct:135 #Tested:155 Testing Accuracy:87.0%\r",
      "Progress:15.5% Speed(reviews/sec):4038.% #Correct:136 #Tested:156 Testing Accuracy:87.1%\r",
      "Progress:15.6% Speed(reviews/sec):4032.% #Correct:137 #Tested:157 Testing Accuracy:87.2%\r",
      "Progress:15.7% Speed(reviews/sec):4031.% #Correct:138 #Tested:158 Testing Accuracy:87.3%\r",
      "Progress:15.8% Speed(reviews/sec):4038.% #Correct:139 #Tested:159 Testing Accuracy:87.4%\r",
      "Progress:15.9% Speed(reviews/sec):4043.% #Correct:140 #Tested:160 Testing Accuracy:87.5%\r",
      "Progress:16.0% Speed(reviews/sec):4044.% #Correct:141 #Tested:161 Testing Accuracy:87.5%\r",
      "Progress:16.1% Speed(reviews/sec):4043.% #Correct:141 #Tested:162 Testing Accuracy:87.0%\r",
      "Progress:16.2% Speed(reviews/sec):4050.% #Correct:142 #Tested:163 Testing Accuracy:87.1%\r",
      "Progress:16.3% Speed(reviews/sec):4057.% #Correct:143 #Tested:164 Testing Accuracy:87.1%\r",
      "Progress:16.4% Speed(reviews/sec):4066.% #Correct:144 #Tested:165 Testing Accuracy:87.2%\r",
      "Progress:16.5% Speed(reviews/sec):4068.% #Correct:145 #Tested:166 Testing Accuracy:87.3%\r",
      "Progress:16.6% Speed(reviews/sec):4067.% #Correct:145 #Tested:167 Testing Accuracy:86.8%\r",
      "Progress:16.7% Speed(reviews/sec):4069.% #Correct:146 #Tested:168 Testing Accuracy:86.9%\r",
      "Progress:16.8% Speed(reviews/sec):4079.% #Correct:147 #Tested:169 Testing Accuracy:86.9%\r",
      "Progress:16.9% Speed(reviews/sec):4086.% #Correct:148 #Tested:170 Testing Accuracy:87.0%\r",
      "Progress:17.0% Speed(reviews/sec):4096.% #Correct:149 #Tested:171 Testing Accuracy:87.1%\r",
      "Progress:17.1% Speed(reviews/sec):4102.% #Correct:150 #Tested:172 Testing Accuracy:87.2%\r",
      "Progress:17.2% Speed(reviews/sec):4091.% #Correct:151 #Tested:173 Testing Accuracy:87.2%\r",
      "Progress:17.3% Speed(reviews/sec):4094.% #Correct:151 #Tested:174 Testing Accuracy:86.7%\r",
      "Progress:17.4% Speed(reviews/sec):4095.% #Correct:152 #Tested:175 Testing Accuracy:86.8%\r",
      "Progress:17.5% Speed(reviews/sec):4107.% #Correct:153 #Tested:176 Testing Accuracy:86.9%\r",
      "Progress:17.6% Speed(reviews/sec):4113.% #Correct:154 #Tested:177 Testing Accuracy:87.0%\r",
      "Progress:17.7% Speed(reviews/sec):4106.% #Correct:155 #Tested:178 Testing Accuracy:87.0%\r",
      "Progress:17.8% Speed(reviews/sec):4113.% #Correct:156 #Tested:179 Testing Accuracy:87.1%\r",
      "Progress:17.9% Speed(reviews/sec):4119.% #Correct:157 #Tested:180 Testing Accuracy:87.2%\r",
      "Progress:18.0% Speed(reviews/sec):4129.% #Correct:158 #Tested:181 Testing Accuracy:87.2%\r",
      "Progress:18.1% Speed(reviews/sec):4134.% #Correct:159 #Tested:182 Testing Accuracy:87.3%\r",
      "Progress:18.2% Speed(reviews/sec):4138.% #Correct:159 #Tested:183 Testing Accuracy:86.8%\r",
      "Progress:18.3% Speed(reviews/sec):4138.% #Correct:160 #Tested:184 Testing Accuracy:86.9%\r",
      "Progress:18.4% Speed(reviews/sec):4129.% #Correct:161 #Tested:185 Testing Accuracy:87.0%\r",
      "Progress:18.5% Speed(reviews/sec):4137.% #Correct:162 #Tested:186 Testing Accuracy:87.0%\r",
      "Progress:18.6% Speed(reviews/sec):4144.% #Correct:162 #Tested:187 Testing Accuracy:86.6%\r",
      "Progress:18.7% Speed(reviews/sec):4143.% #Correct:163 #Tested:188 Testing Accuracy:86.7%\r",
      "Progress:18.8% Speed(reviews/sec):4136.% #Correct:164 #Tested:189 Testing Accuracy:86.7%\r",
      "Progress:18.9% Speed(reviews/sec):4138.% #Correct:165 #Tested:190 Testing Accuracy:86.8%\r",
      "Progress:19.0% Speed(reviews/sec):4151.% #Correct:166 #Tested:191 Testing Accuracy:86.9%\r",
      "Progress:19.1% Speed(reviews/sec):4156.% #Correct:167 #Tested:192 Testing Accuracy:86.9%\r",
      "Progress:19.2% Speed(reviews/sec):4162.% #Correct:168 #Tested:193 Testing Accuracy:87.0%\r",
      "Progress:19.3% Speed(reviews/sec):4155.% #Correct:169 #Tested:194 Testing Accuracy:87.1%\r",
      "Progress:19.4% Speed(reviews/sec):4161.% #Correct:170 #Tested:195 Testing Accuracy:87.1%\r",
      "Progress:19.5% Speed(reviews/sec):4167.% #Correct:170 #Tested:196 Testing Accuracy:86.7%\r",
      "Progress:19.6% Speed(reviews/sec):4165.% #Correct:171 #Tested:197 Testing Accuracy:86.8%\r",
      "Progress:19.7% Speed(reviews/sec):4164.% #Correct:172 #Tested:198 Testing Accuracy:86.8%\r",
      "Progress:19.8% Speed(reviews/sec):4167.% #Correct:173 #Tested:199 Testing Accuracy:86.9%\r",
      "Progress:19.9% Speed(reviews/sec):4166.% #Correct:174 #Tested:200 Testing Accuracy:87.0%\r",
      "Progress:20.0% Speed(reviews/sec):4180.% #Correct:175 #Tested:201 Testing Accuracy:87.0%\r",
      "Progress:20.1% Speed(reviews/sec):4180.% #Correct:176 #Tested:202 Testing Accuracy:87.1%\r",
      "Progress:20.2% Speed(reviews/sec):4186.% #Correct:177 #Tested:203 Testing Accuracy:87.1%\r",
      "Progress:20.3% Speed(reviews/sec):4184.% #Correct:178 #Tested:204 Testing Accuracy:87.2%\r",
      "Progress:20.4% Speed(reviews/sec):4189.% #Correct:179 #Tested:205 Testing Accuracy:87.3%\r",
      "Progress:20.5% Speed(reviews/sec):4194.% #Correct:180 #Tested:206 Testing Accuracy:87.3%\r",
      "Progress:20.6% Speed(reviews/sec):4198.% #Correct:181 #Tested:207 Testing Accuracy:87.4%\r",
      "Progress:20.7% Speed(reviews/sec):4203.% #Correct:182 #Tested:208 Testing Accuracy:87.5%\r",
      "Progress:20.8% Speed(reviews/sec):4209.% #Correct:183 #Tested:209 Testing Accuracy:87.5%\r",
      "Progress:20.9% Speed(reviews/sec):4203.% #Correct:184 #Tested:210 Testing Accuracy:87.6%\r",
      "Progress:21.0% Speed(reviews/sec):4214.% #Correct:184 #Tested:211 Testing Accuracy:87.2%\r",
      "Progress:21.1% Speed(reviews/sec):4218.% #Correct:185 #Tested:212 Testing Accuracy:87.2%\r",
      "Progress:21.2% Speed(reviews/sec):4223.% #Correct:186 #Tested:213 Testing Accuracy:87.3%\r",
      "Progress:21.3% Speed(reviews/sec):4209.% #Correct:187 #Tested:214 Testing Accuracy:87.3%\r",
      "Progress:21.4% Speed(reviews/sec):4214.% #Correct:188 #Tested:215 Testing Accuracy:87.4%\r",
      "Progress:21.5% Speed(reviews/sec):4214.% #Correct:189 #Tested:216 Testing Accuracy:87.5%\r",
      "Progress:21.6% Speed(reviews/sec):4218.% #Correct:190 #Tested:217 Testing Accuracy:87.5%\r",
      "Progress:21.7% Speed(reviews/sec):4217.% #Correct:190 #Tested:218 Testing Accuracy:87.1%\r",
      "Progress:21.8% Speed(reviews/sec):4215.% #Correct:191 #Tested:219 Testing Accuracy:87.2%\r",
      "Progress:21.9% Speed(reviews/sec):4223.% #Correct:192 #Tested:220 Testing Accuracy:87.2%\r",
      "Progress:22.0% Speed(reviews/sec):4222.% #Correct:193 #Tested:221 Testing Accuracy:87.3%\r",
      "Progress:22.1% Speed(reviews/sec):4224.% #Correct:194 #Tested:222 Testing Accuracy:87.3%\r",
      "Progress:22.2% Speed(reviews/sec):4225.% #Correct:195 #Tested:223 Testing Accuracy:87.4%\r",
      "Progress:22.3% Speed(reviews/sec):4227.% #Correct:196 #Tested:224 Testing Accuracy:87.5%\r",
      "Progress:22.4% Speed(reviews/sec):4213.% #Correct:197 #Tested:225 Testing Accuracy:87.5%\r",
      "Progress:22.5% Speed(reviews/sec):4218.% #Correct:198 #Tested:226 Testing Accuracy:87.6%\r",
      "Progress:22.6% Speed(reviews/sec):4203.% #Correct:199 #Tested:227 Testing Accuracy:87.6%\r",
      "Progress:22.7% Speed(reviews/sec):4205.% #Correct:200 #Tested:228 Testing Accuracy:87.7%\r",
      "Progress:22.8% Speed(reviews/sec):4207.% #Correct:201 #Tested:229 Testing Accuracy:87.7%\r",
      "Progress:22.9% Speed(reviews/sec):4208.% #Correct:202 #Tested:230 Testing Accuracy:87.8%\r",
      "Progress:23.0% Speed(reviews/sec):4208.% #Correct:203 #Tested:231 Testing Accuracy:87.8%\r",
      "Progress:23.1% Speed(reviews/sec):4207.% #Correct:204 #Tested:232 Testing Accuracy:87.9%\r",
      "Progress:23.2% Speed(reviews/sec):4214.% #Correct:205 #Tested:233 Testing Accuracy:87.9%\r",
      "Progress:23.3% Speed(reviews/sec):4218.% #Correct:206 #Tested:234 Testing Accuracy:88.0%\r",
      "Progress:23.4% Speed(reviews/sec):4205.% #Correct:207 #Tested:235 Testing Accuracy:88.0%\r",
      "Progress:23.5% Speed(reviews/sec):4213.% #Correct:208 #Tested:236 Testing Accuracy:88.1%\r",
      "Progress:23.6% Speed(reviews/sec):4203.% #Correct:208 #Tested:237 Testing Accuracy:87.7%\r",
      "Progress:23.7% Speed(reviews/sec):4203.% #Correct:209 #Tested:238 Testing Accuracy:87.8%\r",
      "Progress:23.8% Speed(reviews/sec):4207.% #Correct:210 #Tested:239 Testing Accuracy:87.8%\r",
      "Progress:23.9% Speed(reviews/sec):4209.% #Correct:211 #Tested:240 Testing Accuracy:87.9%\r",
      "Progress:24.0% Speed(reviews/sec):4210.% #Correct:212 #Tested:241 Testing Accuracy:87.9%\r",
      "Progress:24.1% Speed(reviews/sec):4210.% #Correct:212 #Tested:242 Testing Accuracy:87.6%\r",
      "Progress:24.2% Speed(reviews/sec):4210.% #Correct:213 #Tested:243 Testing Accuracy:87.6%\r",
      "Progress:24.3% Speed(reviews/sec):4204.% #Correct:214 #Tested:244 Testing Accuracy:87.7%\r",
      "Progress:24.4% Speed(reviews/sec):4203.% #Correct:215 #Tested:245 Testing Accuracy:87.7%\r",
      "Progress:24.5% Speed(reviews/sec):4211.% #Correct:216 #Tested:246 Testing Accuracy:87.8%\r",
      "Progress:24.6% Speed(reviews/sec):4211.% #Correct:217 #Tested:247 Testing Accuracy:87.8%\r",
      "Progress:24.7% Speed(reviews/sec):4210.% #Correct:218 #Tested:248 Testing Accuracy:87.9%\r",
      "Progress:24.8% Speed(reviews/sec):4219.% #Correct:219 #Tested:249 Testing Accuracy:87.9%\r",
      "Progress:24.9% Speed(reviews/sec):4223.% #Correct:220 #Tested:250 Testing Accuracy:88.0%\r",
      "Progress:25.0% Speed(reviews/sec):4232.% #Correct:221 #Tested:251 Testing Accuracy:88.0%\r",
      "Progress:25.1% Speed(reviews/sec):4237.% #Correct:222 #Tested:252 Testing Accuracy:88.0%\r",
      "Progress:25.2% Speed(reviews/sec):4239.% #Correct:223 #Tested:253 Testing Accuracy:88.1%\r",
      "Progress:25.3% Speed(reviews/sec):4242.% #Correct:224 #Tested:254 Testing Accuracy:88.1%\r",
      "Progress:25.4% Speed(reviews/sec):4247.% #Correct:225 #Tested:255 Testing Accuracy:88.2%\r",
      "Progress:25.5% Speed(reviews/sec):4256.% #Correct:226 #Tested:256 Testing Accuracy:88.2%\r",
      "Progress:25.6% Speed(reviews/sec):4263.% #Correct:227 #Tested:257 Testing Accuracy:88.3%\r",
      "Progress:25.7% Speed(reviews/sec):4268.% #Correct:228 #Tested:258 Testing Accuracy:88.3%\r",
      "Progress:25.8% Speed(reviews/sec):4274.% #Correct:229 #Tested:259 Testing Accuracy:88.4%\r",
      "Progress:25.9% Speed(reviews/sec):4277.% #Correct:229 #Tested:260 Testing Accuracy:88.0%\r",
      "Progress:26.0% Speed(reviews/sec):4287.% #Correct:230 #Tested:261 Testing Accuracy:88.1%\r",
      "Progress:26.1% Speed(reviews/sec):4293.% #Correct:231 #Tested:262 Testing Accuracy:88.1%\r",
      "Progress:26.2% Speed(reviews/sec):4295.% #Correct:232 #Tested:263 Testing Accuracy:88.2%\r",
      "Progress:26.3% Speed(reviews/sec):4291.% #Correct:233 #Tested:264 Testing Accuracy:88.2%\r",
      "Progress:26.4% Speed(reviews/sec):4294.% #Correct:234 #Tested:265 Testing Accuracy:88.3%\r",
      "Progress:26.5% Speed(reviews/sec):4284.% #Correct:234 #Tested:266 Testing Accuracy:87.9%\r",
      "Progress:26.6% Speed(reviews/sec):4285.% #Correct:235 #Tested:267 Testing Accuracy:88.0%\r",
      "Progress:26.7% Speed(reviews/sec):4287.% #Correct:235 #Tested:268 Testing Accuracy:87.6%\r",
      "Progress:26.8% Speed(reviews/sec):4291.% #Correct:236 #Tested:269 Testing Accuracy:87.7%\r",
      "Progress:26.9% Speed(reviews/sec):4296.% #Correct:236 #Tested:270 Testing Accuracy:87.4%\r",
      "Progress:27.0% Speed(reviews/sec):4296.% #Correct:236 #Tested:271 Testing Accuracy:87.0%\r",
      "Progress:27.1% Speed(reviews/sec):4298.% #Correct:237 #Tested:272 Testing Accuracy:87.1%\r",
      "Progress:27.2% Speed(reviews/sec):4294.% #Correct:238 #Tested:273 Testing Accuracy:87.1%\r",
      "Progress:27.3% Speed(reviews/sec):4299.% #Correct:239 #Tested:274 Testing Accuracy:87.2%\r",
      "Progress:27.4% Speed(reviews/sec):4297.% #Correct:240 #Tested:275 Testing Accuracy:87.2%\r",
      "Progress:27.5% Speed(reviews/sec):4287.% #Correct:241 #Tested:276 Testing Accuracy:87.3%\r",
      "Progress:27.6% Speed(reviews/sec):4289.% #Correct:242 #Tested:277 Testing Accuracy:87.3%\r",
      "Progress:27.7% Speed(reviews/sec):4293.% #Correct:243 #Tested:278 Testing Accuracy:87.4%\r",
      "Progress:27.8% Speed(reviews/sec):4298.% #Correct:244 #Tested:279 Testing Accuracy:87.4%\r",
      "Progress:27.9% Speed(reviews/sec):4304.% #Correct:245 #Tested:280 Testing Accuracy:87.5%\r",
      "Progress:28.0% Speed(reviews/sec):4308.% #Correct:246 #Tested:281 Testing Accuracy:87.5%\r",
      "Progress:28.1% Speed(reviews/sec):4313.% #Correct:247 #Tested:282 Testing Accuracy:87.5%\r",
      "Progress:28.2% Speed(reviews/sec):4320.% #Correct:248 #Tested:283 Testing Accuracy:87.6%\r",
      "Progress:28.3% Speed(reviews/sec):4325.% #Correct:249 #Tested:284 Testing Accuracy:87.6%\r",
      "Progress:28.4% Speed(reviews/sec):4307.% #Correct:250 #Tested:285 Testing Accuracy:87.7%\r",
      "Progress:28.5% Speed(reviews/sec):4308.% #Correct:251 #Tested:286 Testing Accuracy:87.7%\r",
      "Progress:28.6% Speed(reviews/sec):4314.% #Correct:252 #Tested:287 Testing Accuracy:87.8%\r",
      "Progress:28.7% Speed(reviews/sec):4320.% #Correct:253 #Tested:288 Testing Accuracy:87.8%\r",
      "Progress:28.8% Speed(reviews/sec):4325.% #Correct:254 #Tested:289 Testing Accuracy:87.8%\r",
      "Progress:28.9% Speed(reviews/sec):4330.% #Correct:255 #Tested:290 Testing Accuracy:87.9%\r",
      "Progress:29.0% Speed(reviews/sec):4337.% #Correct:256 #Tested:291 Testing Accuracy:87.9%\r",
      "Progress:29.1% Speed(reviews/sec):4341.% #Correct:257 #Tested:292 Testing Accuracy:88.0%\r",
      "Progress:29.2% Speed(reviews/sec):4344.% #Correct:258 #Tested:293 Testing Accuracy:88.0%\r",
      "Progress:29.3% Speed(reviews/sec):4349.% #Correct:259 #Tested:294 Testing Accuracy:88.0%\r",
      "Progress:29.4% Speed(reviews/sec):4354.% #Correct:260 #Tested:295 Testing Accuracy:88.1%\r",
      "Progress:29.5% Speed(reviews/sec):4363.% #Correct:261 #Tested:296 Testing Accuracy:88.1%\r",
      "Progress:29.6% Speed(reviews/sec):4369.% #Correct:262 #Tested:297 Testing Accuracy:88.2%\r",
      "Progress:29.7% Speed(reviews/sec):4367.% #Correct:263 #Tested:298 Testing Accuracy:88.2%\r",
      "Progress:29.8% Speed(reviews/sec):4368.% #Correct:264 #Tested:299 Testing Accuracy:88.2%\r",
      "Progress:29.9% Speed(reviews/sec):4366.% #Correct:265 #Tested:300 Testing Accuracy:88.3%\r",
      "Progress:30.0% Speed(reviews/sec):4371.% #Correct:266 #Tested:301 Testing Accuracy:88.3%\r",
      "Progress:30.1% Speed(reviews/sec):4364.% #Correct:266 #Tested:302 Testing Accuracy:88.0%\r",
      "Progress:30.2% Speed(reviews/sec):4345.% #Correct:267 #Tested:303 Testing Accuracy:88.1%\r",
      "Progress:30.3% Speed(reviews/sec):4335.% #Correct:268 #Tested:304 Testing Accuracy:88.1%\r",
      "Progress:30.4% Speed(reviews/sec):4339.% #Correct:269 #Tested:305 Testing Accuracy:88.1%\r",
      "Progress:30.5% Speed(reviews/sec):4347.% #Correct:269 #Tested:306 Testing Accuracy:87.9%\r",
      "Progress:30.6% Speed(reviews/sec):4331.% #Correct:270 #Tested:307 Testing Accuracy:87.9%\r",
      "Progress:30.7% Speed(reviews/sec):4333.% #Correct:270 #Tested:308 Testing Accuracy:87.6%\r",
      "Progress:30.8% Speed(reviews/sec):4333.% #Correct:271 #Tested:309 Testing Accuracy:87.7%\r",
      "Progress:30.9% Speed(reviews/sec):4323.% #Correct:272 #Tested:310 Testing Accuracy:87.7%\r",
      "Progress:31.0% Speed(reviews/sec):4332.% #Correct:273 #Tested:311 Testing Accuracy:87.7%\r",
      "Progress:31.1% Speed(reviews/sec):4331.% #Correct:274 #Tested:312 Testing Accuracy:87.8%\r",
      "Progress:31.2% Speed(reviews/sec):4333.% #Correct:275 #Tested:313 Testing Accuracy:87.8%\r",
      "Progress:31.3% Speed(reviews/sec):4333.% #Correct:276 #Tested:314 Testing Accuracy:87.8%\r",
      "Progress:31.4% Speed(reviews/sec):4337.% #Correct:277 #Tested:315 Testing Accuracy:87.9%\r",
      "Progress:31.5% Speed(reviews/sec):4341.% #Correct:278 #Tested:316 Testing Accuracy:87.9%\r",
      "Progress:31.6% Speed(reviews/sec):4345.% #Correct:279 #Tested:317 Testing Accuracy:88.0%\r",
      "Progress:31.7% Speed(reviews/sec):4345.% #Correct:279 #Tested:318 Testing Accuracy:87.7%\r",
      "Progress:31.8% Speed(reviews/sec):4345.% #Correct:280 #Tested:319 Testing Accuracy:87.7%\r",
      "Progress:31.9% Speed(reviews/sec):4348.% #Correct:281 #Tested:320 Testing Accuracy:87.8%\r",
      "Progress:32.0% Speed(reviews/sec):4356.% #Correct:282 #Tested:321 Testing Accuracy:87.8%\r",
      "Progress:32.1% Speed(reviews/sec):4360.% #Correct:282 #Tested:322 Testing Accuracy:87.5%\r",
      "Progress:32.2% Speed(reviews/sec):4365.% #Correct:283 #Tested:323 Testing Accuracy:87.6%\r",
      "Progress:32.3% Speed(reviews/sec):4366.% #Correct:284 #Tested:324 Testing Accuracy:87.6%\r",
      "Progress:32.4% Speed(reviews/sec):4363.% #Correct:285 #Tested:325 Testing Accuracy:87.6%\r",
      "Progress:32.5% Speed(reviews/sec):4365.% #Correct:286 #Tested:326 Testing Accuracy:87.7%\r",
      "Progress:32.6% Speed(reviews/sec):4368.% #Correct:287 #Tested:327 Testing Accuracy:87.7%\r",
      "Progress:32.7% Speed(reviews/sec):4365.% #Correct:287 #Tested:328 Testing Accuracy:87.5%\r",
      "Progress:32.8% Speed(reviews/sec):4364.% #Correct:288 #Tested:329 Testing Accuracy:87.5%\r",
      "Progress:32.9% Speed(reviews/sec):4367.% #Correct:289 #Tested:330 Testing Accuracy:87.5%\r",
      "Progress:33.0% Speed(reviews/sec):4369.% #Correct:290 #Tested:331 Testing Accuracy:87.6%\r",
      "Progress:33.1% Speed(reviews/sec):4372.% #Correct:291 #Tested:332 Testing Accuracy:87.6%\r",
      "Progress:33.2% Speed(reviews/sec):4371.% #Correct:292 #Tested:333 Testing Accuracy:87.6%\r",
      "Progress:33.3% Speed(reviews/sec):4374.% #Correct:293 #Tested:334 Testing Accuracy:87.7%\r",
      "Progress:33.4% Speed(reviews/sec):4365.% #Correct:294 #Tested:335 Testing Accuracy:87.7%\r",
      "Progress:33.5% Speed(reviews/sec):4368.% #Correct:295 #Tested:336 Testing Accuracy:87.7%\r",
      "Progress:33.6% Speed(reviews/sec):4370.% #Correct:296 #Tested:337 Testing Accuracy:87.8%\r",
      "Progress:33.7% Speed(reviews/sec):4374.% #Correct:297 #Tested:338 Testing Accuracy:87.8%\r",
      "Progress:33.8% Speed(reviews/sec):4377.% #Correct:297 #Tested:339 Testing Accuracy:87.6%\r",
      "Progress:33.9% Speed(reviews/sec):4380.% #Correct:298 #Tested:340 Testing Accuracy:87.6%\r",
      "Progress:34.0% Speed(reviews/sec):4381.% #Correct:298 #Tested:341 Testing Accuracy:87.3%\r",
      "Progress:34.1% Speed(reviews/sec):4381.% #Correct:299 #Tested:342 Testing Accuracy:87.4%\r",
      "Progress:34.2% Speed(reviews/sec):4367.% #Correct:300 #Tested:343 Testing Accuracy:87.4%\r",
      "Progress:34.3% Speed(reviews/sec):4370.% #Correct:301 #Tested:344 Testing Accuracy:87.5%\r",
      "Progress:34.4% Speed(reviews/sec):4367.% #Correct:302 #Tested:345 Testing Accuracy:87.5%\r",
      "Progress:34.5% Speed(reviews/sec):4370.% #Correct:303 #Tested:346 Testing Accuracy:87.5%\r",
      "Progress:34.6% Speed(reviews/sec):4374.% #Correct:303 #Tested:347 Testing Accuracy:87.3%\r",
      "Progress:34.7% Speed(reviews/sec):4376.% #Correct:304 #Tested:348 Testing Accuracy:87.3%\r",
      "Progress:34.8% Speed(reviews/sec):4377.% #Correct:305 #Tested:349 Testing Accuracy:87.3%\r",
      "Progress:34.9% Speed(reviews/sec):4379.% #Correct:306 #Tested:350 Testing Accuracy:87.4%\r",
      "Progress:35.0% Speed(reviews/sec):4386.% #Correct:307 #Tested:351 Testing Accuracy:87.4%\r",
      "Progress:35.1% Speed(reviews/sec):4387.% #Correct:308 #Tested:352 Testing Accuracy:87.5%\r",
      "Progress:35.2% Speed(reviews/sec):4387.% #Correct:309 #Tested:353 Testing Accuracy:87.5%\r",
      "Progress:35.3% Speed(reviews/sec):4389.% #Correct:309 #Tested:354 Testing Accuracy:87.2%\r",
      "Progress:35.4% Speed(reviews/sec):4393.% #Correct:310 #Tested:355 Testing Accuracy:87.3%\r",
      "Progress:35.5% Speed(reviews/sec):4390.% #Correct:311 #Tested:356 Testing Accuracy:87.3%\r",
      "Progress:35.6% Speed(reviews/sec):4390.% #Correct:311 #Tested:357 Testing Accuracy:87.1%\r",
      "Progress:35.7% Speed(reviews/sec):4389.% #Correct:311 #Tested:358 Testing Accuracy:86.8%\r",
      "Progress:35.8% Speed(reviews/sec):4392.% #Correct:312 #Tested:359 Testing Accuracy:86.9%\r",
      "Progress:35.9% Speed(reviews/sec):4395.% #Correct:313 #Tested:360 Testing Accuracy:86.9%\r",
      "Progress:36.0% Speed(reviews/sec):4399.% #Correct:314 #Tested:361 Testing Accuracy:86.9%\r",
      "Progress:36.1% Speed(reviews/sec):4401.% #Correct:315 #Tested:362 Testing Accuracy:87.0%\r",
      "Progress:36.2% Speed(reviews/sec):4393.% #Correct:316 #Tested:363 Testing Accuracy:87.0%\r",
      "Progress:36.3% Speed(reviews/sec):4396.% #Correct:317 #Tested:364 Testing Accuracy:87.0%\r",
      "Progress:36.4% Speed(reviews/sec):4400.% #Correct:317 #Tested:365 Testing Accuracy:86.8%\r",
      "Progress:36.5% Speed(reviews/sec):4404.% #Correct:318 #Tested:366 Testing Accuracy:86.8%\r",
      "Progress:36.6% Speed(reviews/sec):4407.% #Correct:319 #Tested:367 Testing Accuracy:86.9%\r",
      "Progress:36.7% Speed(reviews/sec):4405.% #Correct:320 #Tested:368 Testing Accuracy:86.9%\r",
      "Progress:36.8% Speed(reviews/sec):4406.% #Correct:320 #Tested:369 Testing Accuracy:86.7%\r",
      "Progress:36.9% Speed(reviews/sec):4406.% #Correct:320 #Tested:370 Testing Accuracy:86.4%\r",
      "Progress:37.0% Speed(reviews/sec):4410.% #Correct:321 #Tested:371 Testing Accuracy:86.5%\r",
      "Progress:37.1% Speed(reviews/sec):4399.% #Correct:322 #Tested:372 Testing Accuracy:86.5%\r",
      "Progress:37.2% Speed(reviews/sec):4394.% #Correct:322 #Tested:373 Testing Accuracy:86.3%\r",
      "Progress:37.3% Speed(reviews/sec):4397.% #Correct:322 #Tested:374 Testing Accuracy:86.0%\r",
      "Progress:37.4% Speed(reviews/sec):4389.% #Correct:323 #Tested:375 Testing Accuracy:86.1%\r",
      "Progress:37.5% Speed(reviews/sec):4386.% #Correct:324 #Tested:376 Testing Accuracy:86.1%\r",
      "Progress:37.6% Speed(reviews/sec):4382.% #Correct:325 #Tested:377 Testing Accuracy:86.2%\r",
      "Progress:37.7% Speed(reviews/sec):4383.% #Correct:326 #Tested:378 Testing Accuracy:86.2%\r",
      "Progress:37.8% Speed(reviews/sec):4385.% #Correct:326 #Tested:379 Testing Accuracy:86.0%\r",
      "Progress:37.9% Speed(reviews/sec):4390.% #Correct:327 #Tested:380 Testing Accuracy:86.0%\r",
      "Progress:38.0% Speed(reviews/sec):4384.% #Correct:328 #Tested:381 Testing Accuracy:86.0%\r",
      "Progress:38.1% Speed(reviews/sec):4388.% #Correct:329 #Tested:382 Testing Accuracy:86.1%\r",
      "Progress:38.2% Speed(reviews/sec):4387.% #Correct:330 #Tested:383 Testing Accuracy:86.1%\r",
      "Progress:38.3% Speed(reviews/sec):4389.% #Correct:331 #Tested:384 Testing Accuracy:86.1%\r",
      "Progress:38.4% Speed(reviews/sec):4392.% #Correct:332 #Tested:385 Testing Accuracy:86.2%\r",
      "Progress:38.5% Speed(reviews/sec):4398.% #Correct:333 #Tested:386 Testing Accuracy:86.2%\r",
      "Progress:38.6% Speed(reviews/sec):4397.% #Correct:334 #Tested:387 Testing Accuracy:86.3%\r",
      "Progress:38.7% Speed(reviews/sec):4399.% #Correct:335 #Tested:388 Testing Accuracy:86.3%\r",
      "Progress:38.8% Speed(reviews/sec):4402.% #Correct:335 #Tested:389 Testing Accuracy:86.1%\r",
      "Progress:38.9% Speed(reviews/sec):4405.% #Correct:336 #Tested:390 Testing Accuracy:86.1%\r",
      "Progress:39.0% Speed(reviews/sec):4408.% #Correct:336 #Tested:391 Testing Accuracy:85.9%\r",
      "Progress:39.1% Speed(reviews/sec):4406.% #Correct:337 #Tested:392 Testing Accuracy:85.9%\r",
      "Progress:39.2% Speed(reviews/sec):4408.% #Correct:337 #Tested:393 Testing Accuracy:85.7%\r",
      "Progress:39.3% Speed(reviews/sec):4404.% #Correct:338 #Tested:394 Testing Accuracy:85.7%\r",
      "Progress:39.4% Speed(reviews/sec):4403.% #Correct:338 #Tested:395 Testing Accuracy:85.5%\r",
      "Progress:39.5% Speed(reviews/sec):4408.% #Correct:339 #Tested:396 Testing Accuracy:85.6%\r",
      "Progress:39.6% Speed(reviews/sec):4410.% #Correct:340 #Tested:397 Testing Accuracy:85.6%\r",
      "Progress:39.7% Speed(reviews/sec):4413.% #Correct:341 #Tested:398 Testing Accuracy:85.6%\r",
      "Progress:39.8% Speed(reviews/sec):4411.% #Correct:341 #Tested:399 Testing Accuracy:85.4%\r",
      "Progress:39.9% Speed(reviews/sec):4411.% #Correct:342 #Tested:400 Testing Accuracy:85.5%\r",
      "Progress:40.0% Speed(reviews/sec):4410.% #Correct:343 #Tested:401 Testing Accuracy:85.5%\r",
      "Progress:40.1% Speed(reviews/sec):4414.% #Correct:344 #Tested:402 Testing Accuracy:85.5%\r",
      "Progress:40.2% Speed(reviews/sec):4415.% #Correct:345 #Tested:403 Testing Accuracy:85.6%\r",
      "Progress:40.3% Speed(reviews/sec):4419.% #Correct:345 #Tested:404 Testing Accuracy:85.3%\r",
      "Progress:40.4% Speed(reviews/sec):4419.% #Correct:346 #Tested:405 Testing Accuracy:85.4%\r",
      "Progress:40.5% Speed(reviews/sec):4420.% #Correct:347 #Tested:406 Testing Accuracy:85.4%\r",
      "Progress:40.6% Speed(reviews/sec):4421.% #Correct:348 #Tested:407 Testing Accuracy:85.5%\r",
      "Progress:40.7% Speed(reviews/sec):4418.% #Correct:349 #Tested:408 Testing Accuracy:85.5%\r",
      "Progress:40.8% Speed(reviews/sec):4412.% #Correct:350 #Tested:409 Testing Accuracy:85.5%\r",
      "Progress:40.9% Speed(reviews/sec):4411.% #Correct:351 #Tested:410 Testing Accuracy:85.6%\r",
      "Progress:41.0% Speed(reviews/sec):4415.% #Correct:352 #Tested:411 Testing Accuracy:85.6%\r",
      "Progress:41.1% Speed(reviews/sec):4413.% #Correct:353 #Tested:412 Testing Accuracy:85.6%\r",
      "Progress:41.2% Speed(reviews/sec):4419.% #Correct:354 #Tested:413 Testing Accuracy:85.7%\r",
      "Progress:41.3% Speed(reviews/sec):4419.% #Correct:355 #Tested:414 Testing Accuracy:85.7%\r",
      "Progress:41.4% Speed(reviews/sec):4425.% #Correct:356 #Tested:415 Testing Accuracy:85.7%\r",
      "Progress:41.5% Speed(reviews/sec):4429.% #Correct:357 #Tested:416 Testing Accuracy:85.8%\r",
      "Progress:41.6% Speed(reviews/sec):4435.% #Correct:358 #Tested:417 Testing Accuracy:85.8%\r",
      "Progress:41.7% Speed(reviews/sec):4439.% #Correct:359 #Tested:418 Testing Accuracy:85.8%\r",
      "Progress:41.8% Speed(reviews/sec):4444.% #Correct:360 #Tested:419 Testing Accuracy:85.9%\r",
      "Progress:41.9% Speed(reviews/sec):4451.% #Correct:360 #Tested:420 Testing Accuracy:85.7%\r",
      "Progress:42.0% Speed(reviews/sec):4450.% #Correct:361 #Tested:421 Testing Accuracy:85.7%\r",
      "Progress:42.1% Speed(reviews/sec):4455.% #Correct:362 #Tested:422 Testing Accuracy:85.7%\r",
      "Progress:42.2% Speed(reviews/sec):4461.% #Correct:363 #Tested:423 Testing Accuracy:85.8%\r",
      "Progress:42.3% Speed(reviews/sec):4465.% #Correct:364 #Tested:424 Testing Accuracy:85.8%\r",
      "Progress:42.4% Speed(reviews/sec):4466.% #Correct:365 #Tested:425 Testing Accuracy:85.8%\r",
      "Progress:42.5% Speed(reviews/sec):4472.% #Correct:366 #Tested:426 Testing Accuracy:85.9%\r",
      "Progress:42.6% Speed(reviews/sec):4461.% #Correct:367 #Tested:427 Testing Accuracy:85.9%\r",
      "Progress:42.7% Speed(reviews/sec):4459.% #Correct:368 #Tested:428 Testing Accuracy:85.9%\r",
      "Progress:42.8% Speed(reviews/sec):4459.% #Correct:369 #Tested:429 Testing Accuracy:86.0%\r",
      "Progress:42.9% Speed(reviews/sec):4461.% #Correct:370 #Tested:430 Testing Accuracy:86.0%\r",
      "Progress:43.0% Speed(reviews/sec):4465.% #Correct:371 #Tested:431 Testing Accuracy:86.0%\r",
      "Progress:43.1% Speed(reviews/sec):4467.% #Correct:372 #Tested:432 Testing Accuracy:86.1%\r",
      "Progress:43.2% Speed(reviews/sec):4467.% #Correct:372 #Tested:433 Testing Accuracy:85.9%\r",
      "Progress:43.3% Speed(reviews/sec):4471.% #Correct:373 #Tested:434 Testing Accuracy:85.9%\r",
      "Progress:43.4% Speed(reviews/sec):4468.% #Correct:374 #Tested:435 Testing Accuracy:85.9%\r",
      "Progress:43.5% Speed(reviews/sec):4469.% #Correct:375 #Tested:436 Testing Accuracy:86.0%\r",
      "Progress:43.6% Speed(reviews/sec):4474.% #Correct:376 #Tested:437 Testing Accuracy:86.0%\r",
      "Progress:43.7% Speed(reviews/sec):4472.% #Correct:377 #Tested:438 Testing Accuracy:86.0%\r",
      "Progress:43.8% Speed(reviews/sec):4476.% #Correct:378 #Tested:439 Testing Accuracy:86.1%\r",
      "Progress:43.9% Speed(reviews/sec):4470.% #Correct:379 #Tested:440 Testing Accuracy:86.1%\r",
      "Progress:44.0% Speed(reviews/sec):4467.% #Correct:380 #Tested:441 Testing Accuracy:86.1%\r",
      "Progress:44.1% Speed(reviews/sec):4471.% #Correct:381 #Tested:442 Testing Accuracy:86.1%\r",
      "Progress:44.2% Speed(reviews/sec):4471.% #Correct:382 #Tested:443 Testing Accuracy:86.2%\r",
      "Progress:44.3% Speed(reviews/sec):4472.% #Correct:383 #Tested:444 Testing Accuracy:86.2%\r",
      "Progress:44.4% Speed(reviews/sec):4453.% #Correct:384 #Tested:445 Testing Accuracy:86.2%\r",
      "Progress:44.5% Speed(reviews/sec):4450.% #Correct:385 #Tested:446 Testing Accuracy:86.3%\r",
      "Progress:44.6% Speed(reviews/sec):4447.% #Correct:386 #Tested:447 Testing Accuracy:86.3%\r",
      "Progress:44.7% Speed(reviews/sec):4437.% #Correct:387 #Tested:448 Testing Accuracy:86.3%\r",
      "Progress:44.8% Speed(reviews/sec):4439.% #Correct:388 #Tested:449 Testing Accuracy:86.4%\r",
      "Progress:44.9% Speed(reviews/sec):4437.% #Correct:388 #Tested:450 Testing Accuracy:86.2%\r",
      "Progress:45.0% Speed(reviews/sec):4443.% #Correct:389 #Tested:451 Testing Accuracy:86.2%\r",
      "Progress:45.1% Speed(reviews/sec):4434.% #Correct:389 #Tested:452 Testing Accuracy:86.0%\r",
      "Progress:45.2% Speed(reviews/sec):4433.% #Correct:390 #Tested:453 Testing Accuracy:86.0%\r",
      "Progress:45.3% Speed(reviews/sec):4435.% #Correct:391 #Tested:454 Testing Accuracy:86.1%\r",
      "Progress:45.4% Speed(reviews/sec):4441.% #Correct:392 #Tested:455 Testing Accuracy:86.1%\r",
      "Progress:45.5% Speed(reviews/sec):4446.% #Correct:393 #Tested:456 Testing Accuracy:86.1%\r",
      "Progress:45.6% Speed(reviews/sec):4452.% #Correct:394 #Tested:457 Testing Accuracy:86.2%\r",
      "Progress:45.7% Speed(reviews/sec):4456.% #Correct:395 #Tested:458 Testing Accuracy:86.2%\r",
      "Progress:45.8% Speed(reviews/sec):4460.% #Correct:396 #Tested:459 Testing Accuracy:86.2%\r",
      "Progress:45.9% Speed(reviews/sec):4459.% #Correct:397 #Tested:460 Testing Accuracy:86.3%\r",
      "Progress:46.0% Speed(reviews/sec):4463.% #Correct:398 #Tested:461 Testing Accuracy:86.3%\r",
      "Progress:46.1% Speed(reviews/sec):4464.% #Correct:398 #Tested:462 Testing Accuracy:86.1%\r",
      "Progress:46.2% Speed(reviews/sec):4456.% #Correct:399 #Tested:463 Testing Accuracy:86.1%\r",
      "Progress:46.3% Speed(reviews/sec):4460.% #Correct:400 #Tested:464 Testing Accuracy:86.2%\r",
      "Progress:46.4% Speed(reviews/sec):4465.% #Correct:401 #Tested:465 Testing Accuracy:86.2%\r",
      "Progress:46.5% Speed(reviews/sec):4470.% #Correct:402 #Tested:466 Testing Accuracy:86.2%\r",
      "Progress:46.6% Speed(reviews/sec):4473.% #Correct:403 #Tested:467 Testing Accuracy:86.2%\r",
      "Progress:46.7% Speed(reviews/sec):4471.% #Correct:404 #Tested:468 Testing Accuracy:86.3%\r",
      "Progress:46.8% Speed(reviews/sec):4471.% #Correct:405 #Tested:469 Testing Accuracy:86.3%\r",
      "Progress:46.9% Speed(reviews/sec):4475.% #Correct:405 #Tested:470 Testing Accuracy:86.1%\r",
      "Progress:47.0% Speed(reviews/sec):4481.% #Correct:406 #Tested:471 Testing Accuracy:86.1%\r",
      "Progress:47.1% Speed(reviews/sec):4485.% #Correct:406 #Tested:472 Testing Accuracy:86.0%\r",
      "Progress:47.2% Speed(reviews/sec):4490.% #Correct:407 #Tested:473 Testing Accuracy:86.0%\r",
      "Progress:47.3% Speed(reviews/sec):4489.% #Correct:408 #Tested:474 Testing Accuracy:86.0%\r",
      "Progress:47.4% Speed(reviews/sec):4493.% #Correct:409 #Tested:475 Testing Accuracy:86.1%\r",
      "Progress:47.5% Speed(reviews/sec):4494.% #Correct:410 #Tested:476 Testing Accuracy:86.1%\r",
      "Progress:47.6% Speed(reviews/sec):4489.% #Correct:411 #Tested:477 Testing Accuracy:86.1%\r",
      "Progress:47.7% Speed(reviews/sec):4490.% #Correct:411 #Tested:478 Testing Accuracy:85.9%\r",
      "Progress:47.8% Speed(reviews/sec):4487.% #Correct:412 #Tested:479 Testing Accuracy:86.0%\r",
      "Progress:47.9% Speed(reviews/sec):4491.% #Correct:413 #Tested:480 Testing Accuracy:86.0%\r",
      "Progress:48.0% Speed(reviews/sec):4496.% #Correct:414 #Tested:481 Testing Accuracy:86.0%\r",
      "Progress:48.1% Speed(reviews/sec):4487.% #Correct:415 #Tested:482 Testing Accuracy:86.0%\r",
      "Progress:48.2% Speed(reviews/sec):4492.% #Correct:416 #Tested:483 Testing Accuracy:86.1%\r",
      "Progress:48.3% Speed(reviews/sec):4494.% #Correct:417 #Tested:484 Testing Accuracy:86.1%\r",
      "Progress:48.4% Speed(reviews/sec):4497.% #Correct:418 #Tested:485 Testing Accuracy:86.1%\r",
      "Progress:48.5% Speed(reviews/sec):4499.% #Correct:419 #Tested:486 Testing Accuracy:86.2%\r",
      "Progress:48.6% Speed(reviews/sec):4503.% #Correct:420 #Tested:487 Testing Accuracy:86.2%\r",
      "Progress:48.7% Speed(reviews/sec):4508.% #Correct:420 #Tested:488 Testing Accuracy:86.0%\r",
      "Progress:48.8% Speed(reviews/sec):4511.% #Correct:421 #Tested:489 Testing Accuracy:86.0%\r",
      "Progress:48.9% Speed(reviews/sec):4506.% #Correct:421 #Tested:490 Testing Accuracy:85.9%\r",
      "Progress:49.0% Speed(reviews/sec):4509.% #Correct:422 #Tested:491 Testing Accuracy:85.9%\r",
      "Progress:49.1% Speed(reviews/sec):4513.% #Correct:423 #Tested:492 Testing Accuracy:85.9%\r",
      "Progress:49.2% Speed(reviews/sec):4515.% #Correct:424 #Tested:493 Testing Accuracy:86.0%\r",
      "Progress:49.3% Speed(reviews/sec):4516.% #Correct:425 #Tested:494 Testing Accuracy:86.0%\r",
      "Progress:49.4% Speed(reviews/sec):4521.% #Correct:426 #Tested:495 Testing Accuracy:86.0%\r",
      "Progress:49.5% Speed(reviews/sec):4523.% #Correct:427 #Tested:496 Testing Accuracy:86.0%\r",
      "Progress:49.6% Speed(reviews/sec):4527.% #Correct:428 #Tested:497 Testing Accuracy:86.1%\r",
      "Progress:49.7% Speed(reviews/sec):4530.% #Correct:428 #Tested:498 Testing Accuracy:85.9%\r",
      "Progress:49.8% Speed(reviews/sec):4528.% #Correct:429 #Tested:499 Testing Accuracy:85.9%\r",
      "Progress:49.9% Speed(reviews/sec):4529.% #Correct:430 #Tested:500 Testing Accuracy:86.0%\r",
      "Progress:50.0% Speed(reviews/sec):4535.% #Correct:431 #Tested:501 Testing Accuracy:86.0%\r",
      "Progress:50.1% Speed(reviews/sec):4532.% #Correct:432 #Tested:502 Testing Accuracy:86.0%\r",
      "Progress:50.2% Speed(reviews/sec):4534.% #Correct:433 #Tested:503 Testing Accuracy:86.0%\r",
      "Progress:50.3% Speed(reviews/sec):4535.% #Correct:434 #Tested:504 Testing Accuracy:86.1%\r",
      "Progress:50.4% Speed(reviews/sec):4537.% #Correct:434 #Tested:505 Testing Accuracy:85.9%\r",
      "Progress:50.5% Speed(reviews/sec):4542.% #Correct:435 #Tested:506 Testing Accuracy:85.9%\r",
      "Progress:50.6% Speed(reviews/sec):4537.% #Correct:436 #Tested:507 Testing Accuracy:85.9%\r",
      "Progress:50.7% Speed(reviews/sec):4525.% #Correct:437 #Tested:508 Testing Accuracy:86.0%\r",
      "Progress:50.8% Speed(reviews/sec):4528.% #Correct:438 #Tested:509 Testing Accuracy:86.0%\r",
      "Progress:50.9% Speed(reviews/sec):4532.% #Correct:439 #Tested:510 Testing Accuracy:86.0%\r",
      "Progress:51.0% Speed(reviews/sec):4529.% #Correct:440 #Tested:511 Testing Accuracy:86.1%\r",
      "Progress:51.1% Speed(reviews/sec):4533.% #Correct:441 #Tested:512 Testing Accuracy:86.1%\r",
      "Progress:51.2% Speed(reviews/sec):4534.% #Correct:442 #Tested:513 Testing Accuracy:86.1%\r",
      "Progress:51.3% Speed(reviews/sec):4538.% #Correct:443 #Tested:514 Testing Accuracy:86.1%\r",
      "Progress:51.4% Speed(reviews/sec):4540.% #Correct:444 #Tested:515 Testing Accuracy:86.2%\r",
      "Progress:51.5% Speed(reviews/sec):4541.% #Correct:445 #Tested:516 Testing Accuracy:86.2%\r",
      "Progress:51.6% Speed(reviews/sec):4540.% #Correct:446 #Tested:517 Testing Accuracy:86.2%\r",
      "Progress:51.7% Speed(reviews/sec):4543.% #Correct:447 #Tested:518 Testing Accuracy:86.2%\r",
      "Progress:51.8% Speed(reviews/sec):4546.% #Correct:447 #Tested:519 Testing Accuracy:86.1%\r",
      "Progress:51.9% Speed(reviews/sec):4549.% #Correct:448 #Tested:520 Testing Accuracy:86.1%\r",
      "Progress:52.0% Speed(reviews/sec):4555.% #Correct:449 #Tested:521 Testing Accuracy:86.1%\r",
      "Progress:52.1% Speed(reviews/sec):4557.% #Correct:450 #Tested:522 Testing Accuracy:86.2%\r",
      "Progress:52.2% Speed(reviews/sec):4559.% #Correct:451 #Tested:523 Testing Accuracy:86.2%\r",
      "Progress:52.3% Speed(reviews/sec):4561.% #Correct:452 #Tested:524 Testing Accuracy:86.2%\r",
      "Progress:52.4% Speed(reviews/sec):4565.% #Correct:453 #Tested:525 Testing Accuracy:86.2%\r",
      "Progress:52.5% Speed(reviews/sec):4570.% #Correct:454 #Tested:526 Testing Accuracy:86.3%\r",
      "Progress:52.6% Speed(reviews/sec):4574.% #Correct:455 #Tested:527 Testing Accuracy:86.3%\r",
      "Progress:52.7% Speed(reviews/sec):4578.% #Correct:455 #Tested:528 Testing Accuracy:86.1%\r",
      "Progress:52.8% Speed(reviews/sec):4578.% #Correct:455 #Tested:529 Testing Accuracy:86.0%\r",
      "Progress:52.9% Speed(reviews/sec):4580.% #Correct:456 #Tested:530 Testing Accuracy:86.0%\r",
      "Progress:53.0% Speed(reviews/sec):4580.% #Correct:457 #Tested:531 Testing Accuracy:86.0%\r",
      "Progress:53.1% Speed(reviews/sec):4584.% #Correct:457 #Tested:532 Testing Accuracy:85.9%\r",
      "Progress:53.2% Speed(reviews/sec):4588.% #Correct:458 #Tested:533 Testing Accuracy:85.9%\r",
      "Progress:53.3% Speed(reviews/sec):4590.% #Correct:459 #Tested:534 Testing Accuracy:85.9%\r",
      "Progress:53.4% Speed(reviews/sec):4594.% #Correct:460 #Tested:535 Testing Accuracy:85.9%\r",
      "Progress:53.5% Speed(reviews/sec):4599.% #Correct:461 #Tested:536 Testing Accuracy:86.0%\r",
      "Progress:53.6% Speed(reviews/sec):4603.% #Correct:461 #Tested:537 Testing Accuracy:85.8%\r",
      "Progress:53.7% Speed(reviews/sec):4607.% #Correct:462 #Tested:538 Testing Accuracy:85.8%\r",
      "Progress:53.8% Speed(reviews/sec):4609.% #Correct:463 #Tested:539 Testing Accuracy:85.8%\r",
      "Progress:53.9% Speed(reviews/sec):4613.% #Correct:464 #Tested:540 Testing Accuracy:85.9%\r",
      "Progress:54.0% Speed(reviews/sec):4615.% #Correct:465 #Tested:541 Testing Accuracy:85.9%\r",
      "Progress:54.1% Speed(reviews/sec):4618.% #Correct:466 #Tested:542 Testing Accuracy:85.9%\r",
      "Progress:54.2% Speed(reviews/sec):4618.% #Correct:467 #Tested:543 Testing Accuracy:86.0%\r",
      "Progress:54.3% Speed(reviews/sec):4621.% #Correct:468 #Tested:544 Testing Accuracy:86.0%\r",
      "Progress:54.4% Speed(reviews/sec):4621.% #Correct:468 #Tested:545 Testing Accuracy:85.8%\r",
      "Progress:54.5% Speed(reviews/sec):4622.% #Correct:469 #Tested:546 Testing Accuracy:85.8%\r",
      "Progress:54.6% Speed(reviews/sec):4620.% #Correct:469 #Tested:547 Testing Accuracy:85.7%\r",
      "Progress:54.7% Speed(reviews/sec):4622.% #Correct:470 #Tested:548 Testing Accuracy:85.7%\r",
      "Progress:54.8% Speed(reviews/sec):4626.% #Correct:471 #Tested:549 Testing Accuracy:85.7%\r",
      "Progress:54.9% Speed(reviews/sec):4630.% #Correct:472 #Tested:550 Testing Accuracy:85.8%\r",
      "Progress:55.0% Speed(reviews/sec):4635.% #Correct:473 #Tested:551 Testing Accuracy:85.8%\r",
      "Progress:55.1% Speed(reviews/sec):4636.% #Correct:474 #Tested:552 Testing Accuracy:85.8%\r",
      "Progress:55.2% Speed(reviews/sec):4639.% #Correct:475 #Tested:553 Testing Accuracy:85.8%\r",
      "Progress:55.3% Speed(reviews/sec):4643.% #Correct:476 #Tested:554 Testing Accuracy:85.9%\r",
      "Progress:55.4% Speed(reviews/sec):4640.% #Correct:477 #Tested:555 Testing Accuracy:85.9%\r",
      "Progress:55.5% Speed(reviews/sec):4644.% #Correct:478 #Tested:556 Testing Accuracy:85.9%\r",
      "Progress:55.6% Speed(reviews/sec):4645.% #Correct:479 #Tested:557 Testing Accuracy:85.9%\r",
      "Progress:55.7% Speed(reviews/sec):4646.% #Correct:480 #Tested:558 Testing Accuracy:86.0%\r",
      "Progress:55.8% Speed(reviews/sec):4644.% #Correct:480 #Tested:559 Testing Accuracy:85.8%\r",
      "Progress:55.9% Speed(reviews/sec):4647.% #Correct:481 #Tested:560 Testing Accuracy:85.8%\r",
      "Progress:56.0% Speed(reviews/sec):4652.% #Correct:482 #Tested:561 Testing Accuracy:85.9%\r",
      "Progress:56.1% Speed(reviews/sec):4655.% #Correct:483 #Tested:562 Testing Accuracy:85.9%\r",
      "Progress:56.2% Speed(reviews/sec):4656.% #Correct:484 #Tested:563 Testing Accuracy:85.9%\r",
      "Progress:56.3% Speed(reviews/sec):4659.% #Correct:485 #Tested:564 Testing Accuracy:85.9%\r",
      "Progress:56.4% Speed(reviews/sec):4660.% #Correct:486 #Tested:565 Testing Accuracy:86.0%\r",
      "Progress:56.5% Speed(reviews/sec):4664.% #Correct:487 #Tested:566 Testing Accuracy:86.0%\r",
      "Progress:56.6% Speed(reviews/sec):4666.% #Correct:488 #Tested:567 Testing Accuracy:86.0%\r",
      "Progress:56.7% Speed(reviews/sec):4669.% #Correct:489 #Tested:568 Testing Accuracy:86.0%\r",
      "Progress:56.8% Speed(reviews/sec):4672.% #Correct:490 #Tested:569 Testing Accuracy:86.1%\r",
      "Progress:56.9% Speed(reviews/sec):4674.% #Correct:491 #Tested:570 Testing Accuracy:86.1%\r",
      "Progress:57.0% Speed(reviews/sec):4669.% #Correct:492 #Tested:571 Testing Accuracy:86.1%\r",
      "Progress:57.1% Speed(reviews/sec):4669.% #Correct:493 #Tested:572 Testing Accuracy:86.1%\r",
      "Progress:57.2% Speed(reviews/sec):4669.% #Correct:493 #Tested:573 Testing Accuracy:86.0%\r",
      "Progress:57.3% Speed(reviews/sec):4672.% #Correct:493 #Tested:574 Testing Accuracy:85.8%\r",
      "Progress:57.4% Speed(reviews/sec):4672.% #Correct:494 #Tested:575 Testing Accuracy:85.9%\r",
      "Progress:57.5% Speed(reviews/sec):4676.% #Correct:495 #Tested:576 Testing Accuracy:85.9%\r",
      "Progress:57.6% Speed(reviews/sec):4680.% #Correct:496 #Tested:577 Testing Accuracy:85.9%\r",
      "Progress:57.7% Speed(reviews/sec):4683.% #Correct:497 #Tested:578 Testing Accuracy:85.9%\r",
      "Progress:57.8% Speed(reviews/sec):4681.% #Correct:498 #Tested:579 Testing Accuracy:86.0%\r",
      "Progress:57.9% Speed(reviews/sec):4685.% #Correct:499 #Tested:580 Testing Accuracy:86.0%\r",
      "Progress:58.0% Speed(reviews/sec):4686.% #Correct:500 #Tested:581 Testing Accuracy:86.0%\r",
      "Progress:58.1% Speed(reviews/sec):4690.% #Correct:501 #Tested:582 Testing Accuracy:86.0%\r",
      "Progress:58.2% Speed(reviews/sec):4693.% #Correct:502 #Tested:583 Testing Accuracy:86.1%\r",
      "Progress:58.3% Speed(reviews/sec):4696.% #Correct:503 #Tested:584 Testing Accuracy:86.1%\r",
      "Progress:58.4% Speed(reviews/sec):4699.% #Correct:504 #Tested:585 Testing Accuracy:86.1%\r",
      "Progress:58.5% Speed(reviews/sec):4702.% #Correct:505 #Tested:586 Testing Accuracy:86.1%\r",
      "Progress:58.6% Speed(reviews/sec):4706.% #Correct:506 #Tested:587 Testing Accuracy:86.2%\r",
      "Progress:58.7% Speed(reviews/sec):4709.% #Correct:507 #Tested:588 Testing Accuracy:86.2%\r",
      "Progress:58.8% Speed(reviews/sec):4713.% #Correct:508 #Tested:589 Testing Accuracy:86.2%\r",
      "Progress:58.9% Speed(reviews/sec):4716.% #Correct:509 #Tested:590 Testing Accuracy:86.2%\r",
      "Progress:59.0% Speed(reviews/sec):4721.% #Correct:510 #Tested:591 Testing Accuracy:86.2%\r",
      "Progress:59.1% Speed(reviews/sec):4724.% #Correct:511 #Tested:592 Testing Accuracy:86.3%\r",
      "Progress:59.2% Speed(reviews/sec):4722.% #Correct:511 #Tested:593 Testing Accuracy:86.1%\r",
      "Progress:59.3% Speed(reviews/sec):4725.% #Correct:512 #Tested:594 Testing Accuracy:86.1%\r",
      "Progress:59.4% Speed(reviews/sec):4726.% #Correct:513 #Tested:595 Testing Accuracy:86.2%\r",
      "Progress:59.5% Speed(reviews/sec):4730.% #Correct:514 #Tested:596 Testing Accuracy:86.2%\r",
      "Progress:59.6% Speed(reviews/sec):4734.% #Correct:515 #Tested:597 Testing Accuracy:86.2%\r",
      "Progress:59.7% Speed(reviews/sec):4735.% #Correct:516 #Tested:598 Testing Accuracy:86.2%\r",
      "Progress:59.8% Speed(reviews/sec):4737.% #Correct:516 #Tested:599 Testing Accuracy:86.1%\r",
      "Progress:59.9% Speed(reviews/sec):4740.% #Correct:517 #Tested:600 Testing Accuracy:86.1%\r",
      "Progress:60.0% Speed(reviews/sec):4742.% #Correct:517 #Tested:601 Testing Accuracy:86.0%\r",
      "Progress:60.1% Speed(reviews/sec):4744.% #Correct:518 #Tested:602 Testing Accuracy:86.0%\r",
      "Progress:60.2% Speed(reviews/sec):4747.% #Correct:519 #Tested:603 Testing Accuracy:86.0%\r",
      "Progress:60.3% Speed(reviews/sec):4751.% #Correct:520 #Tested:604 Testing Accuracy:86.0%\r",
      "Progress:60.4% Speed(reviews/sec):4754.% #Correct:521 #Tested:605 Testing Accuracy:86.1%\r",
      "Progress:60.5% Speed(reviews/sec):4750.% #Correct:522 #Tested:606 Testing Accuracy:86.1%\r",
      "Progress:60.6% Speed(reviews/sec):4753.% #Correct:522 #Tested:607 Testing Accuracy:85.9%\r",
      "Progress:60.7% Speed(reviews/sec):4756.% #Correct:523 #Tested:608 Testing Accuracy:86.0%\r",
      "Progress:60.8% Speed(reviews/sec):4758.% #Correct:524 #Tested:609 Testing Accuracy:86.0%\r",
      "Progress:60.9% Speed(reviews/sec):4763.% #Correct:525 #Tested:610 Testing Accuracy:86.0%\r",
      "Progress:61.0% Speed(reviews/sec):4764.% #Correct:525 #Tested:611 Testing Accuracy:85.9%\r",
      "Progress:61.1% Speed(reviews/sec):4767.% #Correct:526 #Tested:612 Testing Accuracy:85.9%\r",
      "Progress:61.2% Speed(reviews/sec):4771.% #Correct:527 #Tested:613 Testing Accuracy:85.9%\r",
      "Progress:61.3% Speed(reviews/sec):4774.% #Correct:528 #Tested:614 Testing Accuracy:85.9%\r",
      "Progress:61.4% Speed(reviews/sec):4778.% #Correct:528 #Tested:615 Testing Accuracy:85.8%\r",
      "Progress:61.5% Speed(reviews/sec):4781.% #Correct:528 #Tested:616 Testing Accuracy:85.7%\r",
      "Progress:61.6% Speed(reviews/sec):4783.% #Correct:529 #Tested:617 Testing Accuracy:85.7%\r",
      "Progress:61.7% Speed(reviews/sec):4785.% #Correct:530 #Tested:618 Testing Accuracy:85.7%\r",
      "Progress:61.8% Speed(reviews/sec):4788.% #Correct:531 #Tested:619 Testing Accuracy:85.7%\r",
      "Progress:61.9% Speed(reviews/sec):4791.% #Correct:531 #Tested:620 Testing Accuracy:85.6%\r",
      "Progress:62.0% Speed(reviews/sec):4792.% #Correct:531 #Tested:621 Testing Accuracy:85.5%\r",
      "Progress:62.1% Speed(reviews/sec):4795.% #Correct:532 #Tested:622 Testing Accuracy:85.5%\r",
      "Progress:62.2% Speed(reviews/sec):4797.% #Correct:532 #Tested:623 Testing Accuracy:85.3%\r",
      "Progress:62.3% Speed(reviews/sec):4800.% #Correct:533 #Tested:624 Testing Accuracy:85.4%\r",
      "Progress:62.4% Speed(reviews/sec):4803.% #Correct:533 #Tested:625 Testing Accuracy:85.2%\r",
      "Progress:62.5% Speed(reviews/sec):4796.% #Correct:533 #Tested:626 Testing Accuracy:85.1%\r",
      "Progress:62.6% Speed(reviews/sec):4797.% #Correct:533 #Tested:627 Testing Accuracy:85.0%\r",
      "Progress:62.7% Speed(reviews/sec):4799.% #Correct:533 #Tested:628 Testing Accuracy:84.8%\r",
      "Progress:62.8% Speed(reviews/sec):4803.% #Correct:533 #Tested:629 Testing Accuracy:84.7%\r",
      "Progress:62.9% Speed(reviews/sec):4803.% #Correct:534 #Tested:630 Testing Accuracy:84.7%\r",
      "Progress:63.0% Speed(reviews/sec):4804.% #Correct:534 #Tested:631 Testing Accuracy:84.6%\r",
      "Progress:63.1% Speed(reviews/sec):4800.% #Correct:535 #Tested:632 Testing Accuracy:84.6%\r",
      "Progress:63.2% Speed(reviews/sec):4803.% #Correct:535 #Tested:633 Testing Accuracy:84.5%\r",
      "Progress:63.3% Speed(reviews/sec):4804.% #Correct:536 #Tested:634 Testing Accuracy:84.5%\r",
      "Progress:63.4% Speed(reviews/sec):4801.% #Correct:536 #Tested:635 Testing Accuracy:84.4%\r",
      "Progress:63.5% Speed(reviews/sec):4801.% #Correct:537 #Tested:636 Testing Accuracy:84.4%\r",
      "Progress:63.6% Speed(reviews/sec):4804.% #Correct:537 #Tested:637 Testing Accuracy:84.3%\r",
      "Progress:63.7% Speed(reviews/sec):4805.% #Correct:538 #Tested:638 Testing Accuracy:84.3%\r",
      "Progress:63.8% Speed(reviews/sec):4808.% #Correct:539 #Tested:639 Testing Accuracy:84.3%\r",
      "Progress:63.9% Speed(reviews/sec):4812.% #Correct:540 #Tested:640 Testing Accuracy:84.3%\r",
      "Progress:64.0% Speed(reviews/sec):4817.% #Correct:540 #Tested:641 Testing Accuracy:84.2%\r",
      "Progress:64.1% Speed(reviews/sec):4817.% #Correct:540 #Tested:642 Testing Accuracy:84.1%\r",
      "Progress:64.2% Speed(reviews/sec):4817.% #Correct:541 #Tested:643 Testing Accuracy:84.1%\r",
      "Progress:64.3% Speed(reviews/sec):4820.% #Correct:542 #Tested:644 Testing Accuracy:84.1%\r",
      "Progress:64.4% Speed(reviews/sec):4821.% #Correct:543 #Tested:645 Testing Accuracy:84.1%\r",
      "Progress:64.5% Speed(reviews/sec):4822.% #Correct:543 #Tested:646 Testing Accuracy:84.0%\r",
      "Progress:64.6% Speed(reviews/sec):4820.% #Correct:544 #Tested:647 Testing Accuracy:84.0%\r",
      "Progress:64.7% Speed(reviews/sec):4823.% #Correct:545 #Tested:648 Testing Accuracy:84.1%\r",
      "Progress:64.8% Speed(reviews/sec):4825.% #Correct:546 #Tested:649 Testing Accuracy:84.1%\r",
      "Progress:64.9% Speed(reviews/sec):4827.% #Correct:547 #Tested:650 Testing Accuracy:84.1%\r",
      "Progress:65.0% Speed(reviews/sec):4832.% #Correct:547 #Tested:651 Testing Accuracy:84.0%\r",
      "Progress:65.1% Speed(reviews/sec):4835.% #Correct:548 #Tested:652 Testing Accuracy:84.0%\r",
      "Progress:65.2% Speed(reviews/sec):4838.% #Correct:549 #Tested:653 Testing Accuracy:84.0%\r",
      "Progress:65.3% Speed(reviews/sec):4841.% #Correct:550 #Tested:654 Testing Accuracy:84.0%\r",
      "Progress:65.4% Speed(reviews/sec):4843.% #Correct:550 #Tested:655 Testing Accuracy:83.9%\r",
      "Progress:65.5% Speed(reviews/sec):4847.% #Correct:551 #Tested:656 Testing Accuracy:83.9%\r",
      "Progress:65.6% Speed(reviews/sec):4851.% #Correct:551 #Tested:657 Testing Accuracy:83.8%\r",
      "Progress:65.7% Speed(reviews/sec):4850.% #Correct:552 #Tested:658 Testing Accuracy:83.8%\r",
      "Progress:65.8% Speed(reviews/sec):4854.% #Correct:553 #Tested:659 Testing Accuracy:83.9%\r",
      "Progress:65.9% Speed(reviews/sec):4855.% #Correct:554 #Tested:660 Testing Accuracy:83.9%\r",
      "Progress:66.0% Speed(reviews/sec):4860.% #Correct:555 #Tested:661 Testing Accuracy:83.9%\r",
      "Progress:66.1% Speed(reviews/sec):4862.% #Correct:556 #Tested:662 Testing Accuracy:83.9%\r",
      "Progress:66.2% Speed(reviews/sec):4864.% #Correct:557 #Tested:663 Testing Accuracy:84.0%\r",
      "Progress:66.3% Speed(reviews/sec):4866.% #Correct:557 #Tested:664 Testing Accuracy:83.8%\r",
      "Progress:66.4% Speed(reviews/sec):4869.% #Correct:558 #Tested:665 Testing Accuracy:83.9%\r",
      "Progress:66.5% Speed(reviews/sec):4872.% #Correct:559 #Tested:666 Testing Accuracy:83.9%\r",
      "Progress:66.6% Speed(reviews/sec):4876.% #Correct:560 #Tested:667 Testing Accuracy:83.9%\r",
      "Progress:66.7% Speed(reviews/sec):4878.% #Correct:561 #Tested:668 Testing Accuracy:83.9%\r",
      "Progress:66.8% Speed(reviews/sec):4880.% #Correct:562 #Tested:669 Testing Accuracy:84.0%\r",
      "Progress:66.9% Speed(reviews/sec):4883.% #Correct:562 #Tested:670 Testing Accuracy:83.8%\r",
      "Progress:67.0% Speed(reviews/sec):4888.% #Correct:563 #Tested:671 Testing Accuracy:83.9%\r",
      "Progress:67.1% Speed(reviews/sec):4891.% #Correct:564 #Tested:672 Testing Accuracy:83.9%\r",
      "Progress:67.2% Speed(reviews/sec):4895.% #Correct:565 #Tested:673 Testing Accuracy:83.9%\r",
      "Progress:67.3% Speed(reviews/sec):4896.% #Correct:566 #Tested:674 Testing Accuracy:83.9%\r",
      "Progress:67.4% Speed(reviews/sec):4899.% #Correct:567 #Tested:675 Testing Accuracy:84.0%\r",
      "Progress:67.5% Speed(reviews/sec):4902.% #Correct:568 #Tested:676 Testing Accuracy:84.0%\r",
      "Progress:67.6% Speed(reviews/sec):4905.% #Correct:568 #Tested:677 Testing Accuracy:83.8%\r",
      "Progress:67.7% Speed(reviews/sec):4907.% #Correct:568 #Tested:678 Testing Accuracy:83.7%\r",
      "Progress:67.8% Speed(reviews/sec):4911.% #Correct:569 #Tested:679 Testing Accuracy:83.7%\r",
      "Progress:67.9% Speed(reviews/sec):4913.% #Correct:570 #Tested:680 Testing Accuracy:83.8%\r",
      "Progress:68.0% Speed(reviews/sec):4917.% #Correct:570 #Tested:681 Testing Accuracy:83.7%\r",
      "Progress:68.1% Speed(reviews/sec):4919.% #Correct:571 #Tested:682 Testing Accuracy:83.7%\r",
      "Progress:68.2% Speed(reviews/sec):4922.% #Correct:572 #Tested:683 Testing Accuracy:83.7%\r",
      "Progress:68.3% Speed(reviews/sec):4923.% #Correct:573 #Tested:684 Testing Accuracy:83.7%\r",
      "Progress:68.4% Speed(reviews/sec):4925.% #Correct:574 #Tested:685 Testing Accuracy:83.7%\r",
      "Progress:68.5% Speed(reviews/sec):4929.% #Correct:575 #Tested:686 Testing Accuracy:83.8%\r",
      "Progress:68.6% Speed(reviews/sec):4932.% #Correct:575 #Tested:687 Testing Accuracy:83.6%\r",
      "Progress:68.7% Speed(reviews/sec):4935.% #Correct:576 #Tested:688 Testing Accuracy:83.7%\r",
      "Progress:68.8% Speed(reviews/sec):4932.% #Correct:577 #Tested:689 Testing Accuracy:83.7%\r",
      "Progress:68.9% Speed(reviews/sec):4934.% #Correct:578 #Tested:690 Testing Accuracy:83.7%\r",
      "Progress:69.0% Speed(reviews/sec):4937.% #Correct:579 #Tested:691 Testing Accuracy:83.7%\r",
      "Progress:69.1% Speed(reviews/sec):4938.% #Correct:580 #Tested:692 Testing Accuracy:83.8%\r",
      "Progress:69.2% Speed(reviews/sec):4940.% #Correct:581 #Tested:693 Testing Accuracy:83.8%\r",
      "Progress:69.3% Speed(reviews/sec):4942.% #Correct:582 #Tested:694 Testing Accuracy:83.8%\r",
      "Progress:69.4% Speed(reviews/sec):4942.% #Correct:582 #Tested:695 Testing Accuracy:83.7%\r",
      "Progress:69.5% Speed(reviews/sec):4943.% #Correct:583 #Tested:696 Testing Accuracy:83.7%\r",
      "Progress:69.6% Speed(reviews/sec):4946.% #Correct:584 #Tested:697 Testing Accuracy:83.7%\r",
      "Progress:69.7% Speed(reviews/sec):4948.% #Correct:585 #Tested:698 Testing Accuracy:83.8%\r",
      "Progress:69.8% Speed(reviews/sec):4950.% #Correct:586 #Tested:699 Testing Accuracy:83.8%\r",
      "Progress:69.9% Speed(reviews/sec):4952.% #Correct:587 #Tested:700 Testing Accuracy:83.8%\r",
      "Progress:70.0% Speed(reviews/sec):4954.% #Correct:588 #Tested:701 Testing Accuracy:83.8%\r",
      "Progress:70.1% Speed(reviews/sec):4956.% #Correct:589 #Tested:702 Testing Accuracy:83.9%\r",
      "Progress:70.2% Speed(reviews/sec):4957.% #Correct:590 #Tested:703 Testing Accuracy:83.9%\r",
      "Progress:70.3% Speed(reviews/sec):4958.% #Correct:591 #Tested:704 Testing Accuracy:83.9%\r",
      "Progress:70.4% Speed(reviews/sec):4959.% #Correct:592 #Tested:705 Testing Accuracy:83.9%\r",
      "Progress:70.5% Speed(reviews/sec):4961.% #Correct:593 #Tested:706 Testing Accuracy:83.9%\r",
      "Progress:70.6% Speed(reviews/sec):4963.% #Correct:594 #Tested:707 Testing Accuracy:84.0%\r",
      "Progress:70.7% Speed(reviews/sec):4966.% #Correct:595 #Tested:708 Testing Accuracy:84.0%\r",
      "Progress:70.8% Speed(reviews/sec):4966.% #Correct:596 #Tested:709 Testing Accuracy:84.0%\r",
      "Progress:70.9% Speed(reviews/sec):4968.% #Correct:597 #Tested:710 Testing Accuracy:84.0%\r",
      "Progress:71.0% Speed(reviews/sec):4972.% #Correct:598 #Tested:711 Testing Accuracy:84.1%\r",
      "Progress:71.1% Speed(reviews/sec):4974.% #Correct:599 #Tested:712 Testing Accuracy:84.1%\r",
      "Progress:71.2% Speed(reviews/sec):4978.% #Correct:599 #Tested:713 Testing Accuracy:84.0%\r",
      "Progress:71.3% Speed(reviews/sec):4978.% #Correct:600 #Tested:714 Testing Accuracy:84.0%\r",
      "Progress:71.4% Speed(reviews/sec):4979.% #Correct:601 #Tested:715 Testing Accuracy:84.0%\r",
      "Progress:71.5% Speed(reviews/sec):4983.% #Correct:602 #Tested:716 Testing Accuracy:84.0%\r",
      "Progress:71.6% Speed(reviews/sec):4986.% #Correct:603 #Tested:717 Testing Accuracy:84.1%\r",
      "Progress:71.7% Speed(reviews/sec):4989.% #Correct:604 #Tested:718 Testing Accuracy:84.1%\r",
      "Progress:71.8% Speed(reviews/sec):4989.% #Correct:605 #Tested:719 Testing Accuracy:84.1%\r",
      "Progress:71.9% Speed(reviews/sec):4991.% #Correct:606 #Tested:720 Testing Accuracy:84.1%\r",
      "Progress:72.0% Speed(reviews/sec):4995.% #Correct:606 #Tested:721 Testing Accuracy:84.0%\r",
      "Progress:72.1% Speed(reviews/sec):4996.% #Correct:607 #Tested:722 Testing Accuracy:84.0%\r",
      "Progress:72.2% Speed(reviews/sec):4998.% #Correct:608 #Tested:723 Testing Accuracy:84.0%\r",
      "Progress:72.3% Speed(reviews/sec):5000.% #Correct:609 #Tested:724 Testing Accuracy:84.1%\r",
      "Progress:72.4% Speed(reviews/sec):5003.% #Correct:609 #Tested:725 Testing Accuracy:84.0%\r",
      "Progress:72.5% Speed(reviews/sec):5005.% #Correct:610 #Tested:726 Testing Accuracy:84.0%\r",
      "Progress:72.6% Speed(reviews/sec):5004.% #Correct:611 #Tested:727 Testing Accuracy:84.0%\r",
      "Progress:72.7% Speed(reviews/sec):5002.% #Correct:612 #Tested:728 Testing Accuracy:84.0%\r",
      "Progress:72.8% Speed(reviews/sec):5005.% #Correct:613 #Tested:729 Testing Accuracy:84.0%\r",
      "Progress:72.9% Speed(reviews/sec):5002.% #Correct:614 #Tested:730 Testing Accuracy:84.1%\r",
      "Progress:73.0% Speed(reviews/sec):5005.% #Correct:615 #Tested:731 Testing Accuracy:84.1%\r",
      "Progress:73.1% Speed(reviews/sec):5008.% #Correct:616 #Tested:732 Testing Accuracy:84.1%\r",
      "Progress:73.2% Speed(reviews/sec):5008.% #Correct:617 #Tested:733 Testing Accuracy:84.1%\r",
      "Progress:73.3% Speed(reviews/sec):5008.% #Correct:618 #Tested:734 Testing Accuracy:84.1%\r",
      "Progress:73.4% Speed(reviews/sec):5007.% #Correct:619 #Tested:735 Testing Accuracy:84.2%\r",
      "Progress:73.5% Speed(reviews/sec):5008.% #Correct:620 #Tested:736 Testing Accuracy:84.2%\r",
      "Progress:73.6% Speed(reviews/sec):5010.% #Correct:621 #Tested:737 Testing Accuracy:84.2%\r",
      "Progress:73.7% Speed(reviews/sec):5012.% #Correct:621 #Tested:738 Testing Accuracy:84.1%\r",
      "Progress:73.8% Speed(reviews/sec):5013.% #Correct:622 #Tested:739 Testing Accuracy:84.1%\r",
      "Progress:73.9% Speed(reviews/sec):5016.% #Correct:623 #Tested:740 Testing Accuracy:84.1%\r",
      "Progress:74.0% Speed(reviews/sec):5020.% #Correct:624 #Tested:741 Testing Accuracy:84.2%\r",
      "Progress:74.1% Speed(reviews/sec):5023.% #Correct:625 #Tested:742 Testing Accuracy:84.2%\r",
      "Progress:74.2% Speed(reviews/sec):5025.% #Correct:626 #Tested:743 Testing Accuracy:84.2%\r",
      "Progress:74.3% Speed(reviews/sec):5025.% #Correct:626 #Tested:744 Testing Accuracy:84.1%\r",
      "Progress:74.4% Speed(reviews/sec):5027.% #Correct:627 #Tested:745 Testing Accuracy:84.1%\r",
      "Progress:74.5% Speed(reviews/sec):5025.% #Correct:627 #Tested:746 Testing Accuracy:84.0%\r",
      "Progress:74.6% Speed(reviews/sec):5026.% #Correct:628 #Tested:747 Testing Accuracy:84.0%\r",
      "Progress:74.7% Speed(reviews/sec):5023.% #Correct:628 #Tested:748 Testing Accuracy:83.9%\r",
      "Progress:74.8% Speed(reviews/sec):5023.% #Correct:629 #Tested:749 Testing Accuracy:83.9%\r",
      "Progress:74.9% Speed(reviews/sec):5023.% #Correct:630 #Tested:750 Testing Accuracy:84.0%\r",
      "Progress:75.0% Speed(reviews/sec):5027.% #Correct:631 #Tested:751 Testing Accuracy:84.0%\r",
      "Progress:75.1% Speed(reviews/sec):5030.% #Correct:632 #Tested:752 Testing Accuracy:84.0%\r",
      "Progress:75.2% Speed(reviews/sec):5031.% #Correct:633 #Tested:753 Testing Accuracy:84.0%\r",
      "Progress:75.3% Speed(reviews/sec):5034.% #Correct:634 #Tested:754 Testing Accuracy:84.0%\r",
      "Progress:75.4% Speed(reviews/sec):5032.% #Correct:635 #Tested:755 Testing Accuracy:84.1%\r",
      "Progress:75.5% Speed(reviews/sec):5035.% #Correct:635 #Tested:756 Testing Accuracy:83.9%\r",
      "Progress:75.6% Speed(reviews/sec):5037.% #Correct:635 #Tested:757 Testing Accuracy:83.8%\r",
      "Progress:75.7% Speed(reviews/sec):5040.% #Correct:636 #Tested:758 Testing Accuracy:83.9%\r",
      "Progress:75.8% Speed(reviews/sec):5041.% #Correct:636 #Tested:759 Testing Accuracy:83.7%\r",
      "Progress:75.9% Speed(reviews/sec):5043.% #Correct:637 #Tested:760 Testing Accuracy:83.8%\r",
      "Progress:76.0% Speed(reviews/sec):5045.% #Correct:637 #Tested:761 Testing Accuracy:83.7%\r",
      "Progress:76.1% Speed(reviews/sec):5046.% #Correct:638 #Tested:762 Testing Accuracy:83.7%\r",
      "Progress:76.2% Speed(reviews/sec):5045.% #Correct:638 #Tested:763 Testing Accuracy:83.6%\r",
      "Progress:76.3% Speed(reviews/sec):5047.% #Correct:639 #Tested:764 Testing Accuracy:83.6%\r",
      "Progress:76.4% Speed(reviews/sec):5048.% #Correct:639 #Tested:765 Testing Accuracy:83.5%\r",
      "Progress:76.5% Speed(reviews/sec):5049.% #Correct:639 #Tested:766 Testing Accuracy:83.4%\r",
      "Progress:76.6% Speed(reviews/sec):5051.% #Correct:639 #Tested:767 Testing Accuracy:83.3%\r",
      "Progress:76.7% Speed(reviews/sec):5053.% #Correct:639 #Tested:768 Testing Accuracy:83.2%\r",
      "Progress:76.8% Speed(reviews/sec):5055.% #Correct:639 #Tested:769 Testing Accuracy:83.0%\r",
      "Progress:76.9% Speed(reviews/sec):5057.% #Correct:640 #Tested:770 Testing Accuracy:83.1%\r",
      "Progress:77.0% Speed(reviews/sec):5056.% #Correct:640 #Tested:771 Testing Accuracy:83.0%\r",
      "Progress:77.1% Speed(reviews/sec):5057.% #Correct:641 #Tested:772 Testing Accuracy:83.0%\r",
      "Progress:77.2% Speed(reviews/sec):5060.% #Correct:642 #Tested:773 Testing Accuracy:83.0%\r",
      "Progress:77.3% Speed(reviews/sec):5060.% #Correct:643 #Tested:774 Testing Accuracy:83.0%\r",
      "Progress:77.4% Speed(reviews/sec):5063.% #Correct:644 #Tested:775 Testing Accuracy:83.0%\r",
      "Progress:77.5% Speed(reviews/sec):5063.% #Correct:645 #Tested:776 Testing Accuracy:83.1%\r",
      "Progress:77.6% Speed(reviews/sec):5064.% #Correct:645 #Tested:777 Testing Accuracy:83.0%\r",
      "Progress:77.7% Speed(reviews/sec):5064.% #Correct:645 #Tested:778 Testing Accuracy:82.9%\r",
      "Progress:77.8% Speed(reviews/sec):5059.% #Correct:646 #Tested:779 Testing Accuracy:82.9%\r",
      "Progress:77.9% Speed(reviews/sec):5061.% #Correct:647 #Tested:780 Testing Accuracy:82.9%\r",
      "Progress:78.0% Speed(reviews/sec):5055.% #Correct:647 #Tested:781 Testing Accuracy:82.8%\r",
      "Progress:78.1% Speed(reviews/sec):5059.% #Correct:648 #Tested:782 Testing Accuracy:82.8%\r",
      "Progress:78.2% Speed(reviews/sec):5058.% #Correct:648 #Tested:783 Testing Accuracy:82.7%\r",
      "Progress:78.3% Speed(reviews/sec):5060.% #Correct:649 #Tested:784 Testing Accuracy:82.7%\r",
      "Progress:78.4% Speed(reviews/sec):5060.% #Correct:649 #Tested:785 Testing Accuracy:82.6%\r",
      "Progress:78.5% Speed(reviews/sec):5063.% #Correct:650 #Tested:786 Testing Accuracy:82.6%\r",
      "Progress:78.6% Speed(reviews/sec):5064.% #Correct:650 #Tested:787 Testing Accuracy:82.5%\r",
      "Progress:78.7% Speed(reviews/sec):5063.% #Correct:651 #Tested:788 Testing Accuracy:82.6%\r",
      "Progress:78.8% Speed(reviews/sec):5066.% #Correct:651 #Tested:789 Testing Accuracy:82.5%\r",
      "Progress:78.9% Speed(reviews/sec):5064.% #Correct:652 #Tested:790 Testing Accuracy:82.5%\r",
      "Progress:79.0% Speed(reviews/sec):5063.% #Correct:652 #Tested:791 Testing Accuracy:82.4%\r",
      "Progress:79.1% Speed(reviews/sec):5062.% #Correct:653 #Tested:792 Testing Accuracy:82.4%\r",
      "Progress:79.2% Speed(reviews/sec):5060.% #Correct:653 #Tested:793 Testing Accuracy:82.3%\r",
      "Progress:79.3% Speed(reviews/sec):5062.% #Correct:653 #Tested:794 Testing Accuracy:82.2%\r",
      "Progress:79.4% Speed(reviews/sec):5063.% #Correct:654 #Tested:795 Testing Accuracy:82.2%\r",
      "Progress:79.5% Speed(reviews/sec):5067.% #Correct:655 #Tested:796 Testing Accuracy:82.2%\r",
      "Progress:79.6% Speed(reviews/sec):5068.% #Correct:656 #Tested:797 Testing Accuracy:82.3%\r",
      "Progress:79.7% Speed(reviews/sec):5070.% #Correct:657 #Tested:798 Testing Accuracy:82.3%\r",
      "Progress:79.8% Speed(reviews/sec):5074.% #Correct:658 #Tested:799 Testing Accuracy:82.3%\r",
      "Progress:79.9% Speed(reviews/sec):5076.% #Correct:659 #Tested:800 Testing Accuracy:82.3%\r",
      "Progress:80.0% Speed(reviews/sec):5081.% #Correct:660 #Tested:801 Testing Accuracy:82.3%\r",
      "Progress:80.1% Speed(reviews/sec):5084.% #Correct:661 #Tested:802 Testing Accuracy:82.4%\r",
      "Progress:80.2% Speed(reviews/sec):5087.% #Correct:662 #Tested:803 Testing Accuracy:82.4%\r",
      "Progress:80.3% Speed(reviews/sec):5089.% #Correct:663 #Tested:804 Testing Accuracy:82.4%\r",
      "Progress:80.4% Speed(reviews/sec):5092.% #Correct:664 #Tested:805 Testing Accuracy:82.4%\r",
      "Progress:80.5% Speed(reviews/sec):5096.% #Correct:664 #Tested:806 Testing Accuracy:82.3%\r",
      "Progress:80.6% Speed(reviews/sec):5097.% #Correct:665 #Tested:807 Testing Accuracy:82.4%\r",
      "Progress:80.7% Speed(reviews/sec):5097.% #Correct:666 #Tested:808 Testing Accuracy:82.4%\r",
      "Progress:80.8% Speed(reviews/sec):5099.% #Correct:667 #Tested:809 Testing Accuracy:82.4%\r",
      "Progress:80.9% Speed(reviews/sec):5098.% #Correct:668 #Tested:810 Testing Accuracy:82.4%\r",
      "Progress:81.0% Speed(reviews/sec):5098.% #Correct:669 #Tested:811 Testing Accuracy:82.4%\r",
      "Progress:81.1% Speed(reviews/sec):5099.% #Correct:670 #Tested:812 Testing Accuracy:82.5%\r",
      "Progress:81.2% Speed(reviews/sec):5100.% #Correct:671 #Tested:813 Testing Accuracy:82.5%\r",
      "Progress:81.3% Speed(reviews/sec):5102.% #Correct:672 #Tested:814 Testing Accuracy:82.5%\r",
      "Progress:81.4% Speed(reviews/sec):5100.% #Correct:673 #Tested:815 Testing Accuracy:82.5%\r",
      "Progress:81.5% Speed(reviews/sec):5102.% #Correct:674 #Tested:816 Testing Accuracy:82.5%\r",
      "Progress:81.6% Speed(reviews/sec):5105.% #Correct:675 #Tested:817 Testing Accuracy:82.6%\r",
      "Progress:81.7% Speed(reviews/sec):5106.% #Correct:676 #Tested:818 Testing Accuracy:82.6%\r",
      "Progress:81.8% Speed(reviews/sec):5106.% #Correct:677 #Tested:819 Testing Accuracy:82.6%\r",
      "Progress:81.9% Speed(reviews/sec):5107.% #Correct:677 #Tested:820 Testing Accuracy:82.5%\r",
      "Progress:82.0% Speed(reviews/sec):5104.% #Correct:678 #Tested:821 Testing Accuracy:82.5%\r",
      "Progress:82.1% Speed(reviews/sec):5104.% #Correct:678 #Tested:822 Testing Accuracy:82.4%\r",
      "Progress:82.2% Speed(reviews/sec):5106.% #Correct:678 #Tested:823 Testing Accuracy:82.3%\r",
      "Progress:82.3% Speed(reviews/sec):5108.% #Correct:679 #Tested:824 Testing Accuracy:82.4%\r",
      "Progress:82.4% Speed(reviews/sec):5110.% #Correct:680 #Tested:825 Testing Accuracy:82.4%\r",
      "Progress:82.5% Speed(reviews/sec):5111.% #Correct:681 #Tested:826 Testing Accuracy:82.4%\r",
      "Progress:82.6% Speed(reviews/sec):5103.% #Correct:682 #Tested:827 Testing Accuracy:82.4%\r",
      "Progress:82.7% Speed(reviews/sec):5105.% #Correct:683 #Tested:828 Testing Accuracy:82.4%\r",
      "Progress:82.8% Speed(reviews/sec):5105.% #Correct:684 #Tested:829 Testing Accuracy:82.5%\r",
      "Progress:82.9% Speed(reviews/sec):5106.% #Correct:685 #Tested:830 Testing Accuracy:82.5%\r",
      "Progress:83.0% Speed(reviews/sec):5109.% #Correct:686 #Tested:831 Testing Accuracy:82.5%\r",
      "Progress:83.1% Speed(reviews/sec):5110.% #Correct:687 #Tested:832 Testing Accuracy:82.5%\r",
      "Progress:83.2% Speed(reviews/sec):5111.% #Correct:688 #Tested:833 Testing Accuracy:82.5%\r",
      "Progress:83.3% Speed(reviews/sec):5113.% #Correct:688 #Tested:834 Testing Accuracy:82.4%\r",
      "Progress:83.4% Speed(reviews/sec):5113.% #Correct:689 #Tested:835 Testing Accuracy:82.5%\r",
      "Progress:83.5% Speed(reviews/sec):5116.% #Correct:690 #Tested:836 Testing Accuracy:82.5%\r",
      "Progress:83.6% Speed(reviews/sec):5114.% #Correct:691 #Tested:837 Testing Accuracy:82.5%\r",
      "Progress:83.7% Speed(reviews/sec):5107.% #Correct:692 #Tested:838 Testing Accuracy:82.5%\r",
      "Progress:83.8% Speed(reviews/sec):5107.% #Correct:692 #Tested:839 Testing Accuracy:82.4%\r",
      "Progress:83.9% Speed(reviews/sec):5110.% #Correct:693 #Tested:840 Testing Accuracy:82.5%\r",
      "Progress:84.0% Speed(reviews/sec):5114.% #Correct:694 #Tested:841 Testing Accuracy:82.5%\r",
      "Progress:84.1% Speed(reviews/sec):5116.% #Correct:695 #Tested:842 Testing Accuracy:82.5%\r",
      "Progress:84.2% Speed(reviews/sec):5117.% #Correct:696 #Tested:843 Testing Accuracy:82.5%\r",
      "Progress:84.3% Speed(reviews/sec):5119.% #Correct:697 #Tested:844 Testing Accuracy:82.5%\r",
      "Progress:84.4% Speed(reviews/sec):5121.% #Correct:698 #Tested:845 Testing Accuracy:82.6%\r",
      "Progress:84.5% Speed(reviews/sec):5124.% #Correct:699 #Tested:846 Testing Accuracy:82.6%\r",
      "Progress:84.6% Speed(reviews/sec):5124.% #Correct:699 #Tested:847 Testing Accuracy:82.5%\r",
      "Progress:84.7% Speed(reviews/sec):5126.% #Correct:699 #Tested:848 Testing Accuracy:82.4%\r",
      "Progress:84.8% Speed(reviews/sec):5128.% #Correct:700 #Tested:849 Testing Accuracy:82.4%\r",
      "Progress:84.9% Speed(reviews/sec):5124.% #Correct:701 #Tested:850 Testing Accuracy:82.4%\r",
      "Progress:85.0% Speed(reviews/sec):5123.% #Correct:702 #Tested:851 Testing Accuracy:82.4%\r",
      "Progress:85.1% Speed(reviews/sec):5125.% #Correct:703 #Tested:852 Testing Accuracy:82.5%\r",
      "Progress:85.2% Speed(reviews/sec):5124.% #Correct:703 #Tested:853 Testing Accuracy:82.4%\r",
      "Progress:85.3% Speed(reviews/sec):5123.% #Correct:704 #Tested:854 Testing Accuracy:82.4%\r",
      "Progress:85.4% Speed(reviews/sec):5126.% #Correct:705 #Tested:855 Testing Accuracy:82.4%\r",
      "Progress:85.5% Speed(reviews/sec):5129.% #Correct:706 #Tested:856 Testing Accuracy:82.4%\r",
      "Progress:85.6% Speed(reviews/sec):5130.% #Correct:707 #Tested:857 Testing Accuracy:82.4%\r",
      "Progress:85.7% Speed(reviews/sec):5130.% #Correct:708 #Tested:858 Testing Accuracy:82.5%\r",
      "Progress:85.8% Speed(reviews/sec):5131.% #Correct:709 #Tested:859 Testing Accuracy:82.5%\r",
      "Progress:85.9% Speed(reviews/sec):5132.% #Correct:710 #Tested:860 Testing Accuracy:82.5%\r",
      "Progress:86.0% Speed(reviews/sec):5134.% #Correct:711 #Tested:861 Testing Accuracy:82.5%\r",
      "Progress:86.1% Speed(reviews/sec):5135.% #Correct:712 #Tested:862 Testing Accuracy:82.5%\r",
      "Progress:86.2% Speed(reviews/sec):5137.% #Correct:712 #Tested:863 Testing Accuracy:82.5%\r",
      "Progress:86.3% Speed(reviews/sec):5130.% #Correct:713 #Tested:864 Testing Accuracy:82.5%\r",
      "Progress:86.4% Speed(reviews/sec):5132.% #Correct:713 #Tested:865 Testing Accuracy:82.4%\r",
      "Progress:86.5% Speed(reviews/sec):5134.% #Correct:714 #Tested:866 Testing Accuracy:82.4%\r",
      "Progress:86.6% Speed(reviews/sec):5135.% #Correct:714 #Tested:867 Testing Accuracy:82.3%\r",
      "Progress:86.7% Speed(reviews/sec):5138.% #Correct:714 #Tested:868 Testing Accuracy:82.2%\r",
      "Progress:86.8% Speed(reviews/sec):5141.% #Correct:715 #Tested:869 Testing Accuracy:82.2%\r",
      "Progress:86.9% Speed(reviews/sec):5143.% #Correct:716 #Tested:870 Testing Accuracy:82.2%\r",
      "Progress:87.0% Speed(reviews/sec):5146.% #Correct:717 #Tested:871 Testing Accuracy:82.3%\r",
      "Progress:87.1% Speed(reviews/sec):5147.% #Correct:718 #Tested:872 Testing Accuracy:82.3%\r",
      "Progress:87.2% Speed(reviews/sec):5149.% #Correct:719 #Tested:873 Testing Accuracy:82.3%\r",
      "Progress:87.3% Speed(reviews/sec):5152.% #Correct:720 #Tested:874 Testing Accuracy:82.3%\r",
      "Progress:87.4% Speed(reviews/sec):5155.% #Correct:721 #Tested:875 Testing Accuracy:82.4%\r",
      "Progress:87.5% Speed(reviews/sec):5157.% #Correct:722 #Tested:876 Testing Accuracy:82.4%\r",
      "Progress:87.6% Speed(reviews/sec):5160.% #Correct:722 #Tested:877 Testing Accuracy:82.3%\r",
      "Progress:87.7% Speed(reviews/sec):5152.% #Correct:723 #Tested:878 Testing Accuracy:82.3%\r",
      "Progress:87.8% Speed(reviews/sec):5155.% #Correct:724 #Tested:879 Testing Accuracy:82.3%\r",
      "Progress:87.9% Speed(reviews/sec):5157.% #Correct:725 #Tested:880 Testing Accuracy:82.3%\r",
      "Progress:88.0% Speed(reviews/sec):5159.% #Correct:726 #Tested:881 Testing Accuracy:82.4%\r",
      "Progress:88.1% Speed(reviews/sec):5161.% #Correct:727 #Tested:882 Testing Accuracy:82.4%\r",
      "Progress:88.2% Speed(reviews/sec):5163.% #Correct:728 #Tested:883 Testing Accuracy:82.4%\r",
      "Progress:88.3% Speed(reviews/sec):5165.% #Correct:729 #Tested:884 Testing Accuracy:82.4%\r",
      "Progress:88.4% Speed(reviews/sec):5167.% #Correct:730 #Tested:885 Testing Accuracy:82.4%\r",
      "Progress:88.5% Speed(reviews/sec):5171.% #Correct:731 #Tested:886 Testing Accuracy:82.5%\r",
      "Progress:88.6% Speed(reviews/sec):5174.% #Correct:731 #Tested:887 Testing Accuracy:82.4%\r",
      "Progress:88.7% Speed(reviews/sec):5175.% #Correct:732 #Tested:888 Testing Accuracy:82.4%\r",
      "Progress:88.8% Speed(reviews/sec):5177.% #Correct:732 #Tested:889 Testing Accuracy:82.3%\r",
      "Progress:88.9% Speed(reviews/sec):5177.% #Correct:733 #Tested:890 Testing Accuracy:82.3%\r",
      "Progress:89.0% Speed(reviews/sec):5178.% #Correct:734 #Tested:891 Testing Accuracy:82.3%\r",
      "Progress:89.1% Speed(reviews/sec):5178.% #Correct:735 #Tested:892 Testing Accuracy:82.3%\r",
      "Progress:89.2% Speed(reviews/sec):5181.% #Correct:735 #Tested:893 Testing Accuracy:82.3%\r",
      "Progress:89.3% Speed(reviews/sec):5182.% #Correct:736 #Tested:894 Testing Accuracy:82.3%\r",
      "Progress:89.4% Speed(reviews/sec):5185.% #Correct:737 #Tested:895 Testing Accuracy:82.3%\r",
      "Progress:89.5% Speed(reviews/sec):5188.% #Correct:738 #Tested:896 Testing Accuracy:82.3%\r",
      "Progress:89.6% Speed(reviews/sec):5190.% #Correct:739 #Tested:897 Testing Accuracy:82.3%\r",
      "Progress:89.7% Speed(reviews/sec):5192.% #Correct:740 #Tested:898 Testing Accuracy:82.4%\r",
      "Progress:89.8% Speed(reviews/sec):5187.% #Correct:741 #Tested:899 Testing Accuracy:82.4%\r",
      "Progress:89.9% Speed(reviews/sec):5189.% #Correct:742 #Tested:900 Testing Accuracy:82.4%\r",
      "Progress:90.0% Speed(reviews/sec):5191.% #Correct:743 #Tested:901 Testing Accuracy:82.4%\r",
      "Progress:90.1% Speed(reviews/sec):5188.% #Correct:744 #Tested:902 Testing Accuracy:82.4%\r",
      "Progress:90.2% Speed(reviews/sec):5189.% #Correct:745 #Tested:903 Testing Accuracy:82.5%\r",
      "Progress:90.3% Speed(reviews/sec):5190.% #Correct:746 #Tested:904 Testing Accuracy:82.5%\r",
      "Progress:90.4% Speed(reviews/sec):5192.% #Correct:747 #Tested:905 Testing Accuracy:82.5%\r",
      "Progress:90.5% Speed(reviews/sec):5195.% #Correct:748 #Tested:906 Testing Accuracy:82.5%\r",
      "Progress:90.6% Speed(reviews/sec):5198.% #Correct:748 #Tested:907 Testing Accuracy:82.4%\r",
      "Progress:90.7% Speed(reviews/sec):5199.% #Correct:749 #Tested:908 Testing Accuracy:82.4%\r",
      "Progress:90.8% Speed(reviews/sec):5200.% #Correct:749 #Tested:909 Testing Accuracy:82.3%\r",
      "Progress:90.9% Speed(reviews/sec):5202.% #Correct:749 #Tested:910 Testing Accuracy:82.3%\r",
      "Progress:91.0% Speed(reviews/sec):5204.% #Correct:750 #Tested:911 Testing Accuracy:82.3%\r",
      "Progress:91.1% Speed(reviews/sec):5205.% #Correct:750 #Tested:912 Testing Accuracy:82.2%\r",
      "Progress:91.2% Speed(reviews/sec):5206.% #Correct:751 #Tested:913 Testing Accuracy:82.2%\r",
      "Progress:91.3% Speed(reviews/sec):5204.% #Correct:751 #Tested:914 Testing Accuracy:82.1%\r",
      "Progress:91.4% Speed(reviews/sec):5206.% #Correct:752 #Tested:915 Testing Accuracy:82.1%\r",
      "Progress:91.5% Speed(reviews/sec):5208.% #Correct:752 #Tested:916 Testing Accuracy:82.0%\r",
      "Progress:91.6% Speed(reviews/sec):5207.% #Correct:752 #Tested:917 Testing Accuracy:82.0%\r",
      "Progress:91.7% Speed(reviews/sec):5208.% #Correct:752 #Tested:918 Testing Accuracy:81.9%\r",
      "Progress:91.8% Speed(reviews/sec):5209.% #Correct:753 #Tested:919 Testing Accuracy:81.9%\r",
      "Progress:91.9% Speed(reviews/sec):5210.% #Correct:754 #Tested:920 Testing Accuracy:81.9%\r",
      "Progress:92.0% Speed(reviews/sec):5212.% #Correct:754 #Tested:921 Testing Accuracy:81.8%\r",
      "Progress:92.1% Speed(reviews/sec):5214.% #Correct:755 #Tested:922 Testing Accuracy:81.8%\r",
      "Progress:92.2% Speed(reviews/sec):5215.% #Correct:756 #Tested:923 Testing Accuracy:81.9%\r",
      "Progress:92.3% Speed(reviews/sec):5217.% #Correct:757 #Tested:924 Testing Accuracy:81.9%\r",
      "Progress:92.4% Speed(reviews/sec):5219.% #Correct:758 #Tested:925 Testing Accuracy:81.9%\r",
      "Progress:92.5% Speed(reviews/sec):5222.% #Correct:759 #Tested:926 Testing Accuracy:81.9%\r",
      "Progress:92.6% Speed(reviews/sec):5222.% #Correct:760 #Tested:927 Testing Accuracy:81.9%\r",
      "Progress:92.7% Speed(reviews/sec):5225.% #Correct:761 #Tested:928 Testing Accuracy:82.0%\r",
      "Progress:92.8% Speed(reviews/sec):5227.% #Correct:761 #Tested:929 Testing Accuracy:81.9%\r",
      "Progress:92.9% Speed(reviews/sec):5228.% #Correct:762 #Tested:930 Testing Accuracy:81.9%\r",
      "Progress:93.0% Speed(reviews/sec):5231.% #Correct:763 #Tested:931 Testing Accuracy:81.9%\r",
      "Progress:93.1% Speed(reviews/sec):5229.% #Correct:764 #Tested:932 Testing Accuracy:81.9%\r",
      "Progress:93.2% Speed(reviews/sec):5231.% #Correct:765 #Tested:933 Testing Accuracy:81.9%\r",
      "Progress:93.3% Speed(reviews/sec):5230.% #Correct:766 #Tested:934 Testing Accuracy:82.0%\r",
      "Progress:93.4% Speed(reviews/sec):5231.% #Correct:767 #Tested:935 Testing Accuracy:82.0%\r",
      "Progress:93.5% Speed(reviews/sec):5234.% #Correct:768 #Tested:936 Testing Accuracy:82.0%\r",
      "Progress:93.6% Speed(reviews/sec):5236.% #Correct:768 #Tested:937 Testing Accuracy:81.9%\r",
      "Progress:93.7% Speed(reviews/sec):5238.% #Correct:769 #Tested:938 Testing Accuracy:81.9%\r",
      "Progress:93.8% Speed(reviews/sec):5240.% #Correct:769 #Tested:939 Testing Accuracy:81.8%\r",
      "Progress:93.9% Speed(reviews/sec):5243.% #Correct:770 #Tested:940 Testing Accuracy:81.9%\r",
      "Progress:94.0% Speed(reviews/sec):5247.% #Correct:771 #Tested:941 Testing Accuracy:81.9%\r",
      "Progress:94.1% Speed(reviews/sec):5248.% #Correct:771 #Tested:942 Testing Accuracy:81.8%\r",
      "Progress:94.2% Speed(reviews/sec):5249.% #Correct:771 #Tested:943 Testing Accuracy:81.7%\r",
      "Progress:94.3% Speed(reviews/sec):5251.% #Correct:772 #Tested:944 Testing Accuracy:81.7%\r",
      "Progress:94.4% Speed(reviews/sec):5248.% #Correct:773 #Tested:945 Testing Accuracy:81.7%\r",
      "Progress:94.5% Speed(reviews/sec):5250.% #Correct:774 #Tested:946 Testing Accuracy:81.8%\r",
      "Progress:94.6% Speed(reviews/sec):5252.% #Correct:775 #Tested:947 Testing Accuracy:81.8%\r",
      "Progress:94.7% Speed(reviews/sec):5253.% #Correct:776 #Tested:948 Testing Accuracy:81.8%\r",
      "Progress:94.8% Speed(reviews/sec):5254.% #Correct:777 #Tested:949 Testing Accuracy:81.8%\r",
      "Progress:94.9% Speed(reviews/sec):5257.% #Correct:778 #Tested:950 Testing Accuracy:81.8%\r",
      "Progress:95.0% Speed(reviews/sec):5260.% #Correct:779 #Tested:951 Testing Accuracy:81.9%\r",
      "Progress:95.1% Speed(reviews/sec):5257.% #Correct:779 #Tested:952 Testing Accuracy:81.8%\r",
      "Progress:95.2% Speed(reviews/sec):5258.% #Correct:779 #Tested:953 Testing Accuracy:81.7%\r",
      "Progress:95.3% Speed(reviews/sec):5260.% #Correct:780 #Tested:954 Testing Accuracy:81.7%\r",
      "Progress:95.4% Speed(reviews/sec):5256.% #Correct:781 #Tested:955 Testing Accuracy:81.7%\r",
      "Progress:95.5% Speed(reviews/sec):5259.% #Correct:782 #Tested:956 Testing Accuracy:81.7%\r",
      "Progress:95.6% Speed(reviews/sec):5260.% #Correct:783 #Tested:957 Testing Accuracy:81.8%\r",
      "Progress:95.7% Speed(reviews/sec):5263.% #Correct:784 #Tested:958 Testing Accuracy:81.8%\r",
      "Progress:95.8% Speed(reviews/sec):5265.% #Correct:785 #Tested:959 Testing Accuracy:81.8%\r",
      "Progress:95.9% Speed(reviews/sec):5267.% #Correct:786 #Tested:960 Testing Accuracy:81.8%\r",
      "Progress:96.0% Speed(reviews/sec):5267.% #Correct:787 #Tested:961 Testing Accuracy:81.8%\r",
      "Progress:96.1% Speed(reviews/sec):5270.% #Correct:788 #Tested:962 Testing Accuracy:81.9%\r",
      "Progress:96.2% Speed(reviews/sec):5272.% #Correct:789 #Tested:963 Testing Accuracy:81.9%\r",
      "Progress:96.3% Speed(reviews/sec):5274.% #Correct:790 #Tested:964 Testing Accuracy:81.9%\r",
      "Progress:96.4% Speed(reviews/sec):5275.% #Correct:791 #Tested:965 Testing Accuracy:81.9%\r",
      "Progress:96.5% Speed(reviews/sec):5278.% #Correct:792 #Tested:966 Testing Accuracy:81.9%\r",
      "Progress:96.6% Speed(reviews/sec):5280.% #Correct:793 #Tested:967 Testing Accuracy:82.0%\r",
      "Progress:96.7% Speed(reviews/sec):5283.% #Correct:794 #Tested:968 Testing Accuracy:82.0%\r",
      "Progress:96.8% Speed(reviews/sec):5285.% #Correct:795 #Tested:969 Testing Accuracy:82.0%\r",
      "Progress:96.9% Speed(reviews/sec):5287.% #Correct:796 #Tested:970 Testing Accuracy:82.0%\r",
      "Progress:97.0% Speed(reviews/sec):5288.% #Correct:797 #Tested:971 Testing Accuracy:82.0%\r",
      "Progress:97.1% Speed(reviews/sec):5289.% #Correct:798 #Tested:972 Testing Accuracy:82.0%\r",
      "Progress:97.2% Speed(reviews/sec):5291.% #Correct:798 #Tested:973 Testing Accuracy:82.0%\r",
      "Progress:97.3% Speed(reviews/sec):5290.% #Correct:799 #Tested:974 Testing Accuracy:82.0%\r",
      "Progress:97.4% Speed(reviews/sec):5290.% #Correct:800 #Tested:975 Testing Accuracy:82.0%\r",
      "Progress:97.5% Speed(reviews/sec):5292.% #Correct:801 #Tested:976 Testing Accuracy:82.0%\r",
      "Progress:97.6% Speed(reviews/sec):5292.% #Correct:802 #Tested:977 Testing Accuracy:82.0%\r",
      "Progress:97.7% Speed(reviews/sec):5289.% #Correct:803 #Tested:978 Testing Accuracy:82.1%\r",
      "Progress:97.8% Speed(reviews/sec):5289.% #Correct:804 #Tested:979 Testing Accuracy:82.1%\r",
      "Progress:97.9% Speed(reviews/sec):5288.% #Correct:805 #Tested:980 Testing Accuracy:82.1%\r",
      "Progress:98.0% Speed(reviews/sec):5291.% #Correct:806 #Tested:981 Testing Accuracy:82.1%\r",
      "Progress:98.1% Speed(reviews/sec):5285.% #Correct:807 #Tested:982 Testing Accuracy:82.1%\r",
      "Progress:98.2% Speed(reviews/sec):5285.% #Correct:808 #Tested:983 Testing Accuracy:82.1%\r",
      "Progress:98.3% Speed(reviews/sec):5279.% #Correct:809 #Tested:984 Testing Accuracy:82.2%\r",
      "Progress:98.4% Speed(reviews/sec):5282.% #Correct:809 #Tested:985 Testing Accuracy:82.1%\r",
      "Progress:98.5% Speed(reviews/sec):5285.% #Correct:810 #Tested:986 Testing Accuracy:82.1%\r",
      "Progress:98.6% Speed(reviews/sec):5287.% #Correct:811 #Tested:987 Testing Accuracy:82.1%\r",
      "Progress:98.7% Speed(reviews/sec):5288.% #Correct:812 #Tested:988 Testing Accuracy:82.1%\r",
      "Progress:98.8% Speed(reviews/sec):5289.% #Correct:813 #Tested:989 Testing Accuracy:82.2%\r",
      "Progress:98.9% Speed(reviews/sec):5289.% #Correct:814 #Tested:990 Testing Accuracy:82.2%\r",
      "Progress:99.0% Speed(reviews/sec):5291.% #Correct:815 #Tested:991 Testing Accuracy:82.2%\r",
      "Progress:99.1% Speed(reviews/sec):5292.% #Correct:816 #Tested:992 Testing Accuracy:82.2%\r",
      "Progress:99.2% Speed(reviews/sec):5294.% #Correct:817 #Tested:993 Testing Accuracy:82.2%\r",
      "Progress:99.3% Speed(reviews/sec):5296.% #Correct:818 #Tested:994 Testing Accuracy:82.2%\r",
      "Progress:99.4% Speed(reviews/sec):5294.% #Correct:818 #Tested:995 Testing Accuracy:82.2%\r",
      "Progress:99.5% Speed(reviews/sec):5295.% #Correct:819 #Tested:996 Testing Accuracy:82.2%\r",
      "Progress:99.6% Speed(reviews/sec):5296.% #Correct:820 #Tested:997 Testing Accuracy:82.2%\r",
      "Progress:99.7% Speed(reviews/sec):5296.% #Correct:821 #Tested:998 Testing Accuracy:82.2%\r",
      "Progress:99.8% Speed(reviews/sec):5297.% #Correct:821 #Tested:999 Testing Accuracy:82.1%\r",
      "Progress:99.9% Speed(reviews/sec):5299.% #Correct:822 #Tested:1000 Testing Accuracy:82.2%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we got an increase in speed from 2236 w/s to 6251 w/s however 3% of the accuracy was traded off as a result. There will almost always be a trade-off between speed and accuracy excluding noise reduction which normally helps both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Whats going on with the weights?\n",
    "\n",
    "Here we will visualise what is realling going on under the hood of the network and how the weights work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_full = SentimentNetwork(reviews[:-1000], labels[:-1000], min_count=0, polarity_cutoff=0, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):1680. #Correct:20335 #Trained:24000 Training Accuracy:84.7%"
     ]
    }
   ],
   "source": [
    "mlp_full.train(reviews[:-1000], labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_similar_words(focus = \"horrible\"):\n",
    "    most_similar = Counter()\n",
    "\n",
    "    for word in mlp_full.word2index.keys():\n",
    "        most_similar[word] = np.dot(mlp_full.weights_0_1[mlp_full.word2index[word]],mlp_full.weights_0_1[mlp_full.word2index[focus]])\n",
    "    \n",
    "    return most_similar.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excellent', 0.13672950757352476),\n",
       " ('perfect', 0.12548286087225946),\n",
       " ('amazing', 0.091827633925999713),\n",
       " ('today', 0.090223662694414217),\n",
       " ('wonderful', 0.089355976962214589),\n",
       " ('fun', 0.087504466674206888),\n",
       " ('great', 0.087141758882292031),\n",
       " ('best', 0.085810885617880639),\n",
       " ('liked', 0.077697629123843426),\n",
       " ('definitely', 0.076628781406966023),\n",
       " ('brilliant', 0.073423858769279066),\n",
       " ('loved', 0.073285428928122162),\n",
       " ('favorite', 0.072781136036160765),\n",
       " ('superb', 0.071736207178505054),\n",
       " ('fantastic', 0.070922191916266183),\n",
       " ('job', 0.06916061720763407),\n",
       " ('incredible', 0.066424077952614416),\n",
       " ('enjoyable', 0.065632560502888793),\n",
       " ('rare', 0.064819212662615089),\n",
       " ('highly', 0.063889453350970515),\n",
       " ('enjoyed', 0.062127546101812946),\n",
       " ('wonderfully', 0.062055178604090169),\n",
       " ('perfectly', 0.061093208811887387),\n",
       " ('fascinating', 0.060663547937493886),\n",
       " ('bit', 0.059655427045653048),\n",
       " ('gem', 0.059510859296156786),\n",
       " ('outstanding', 0.058860808147083027),\n",
       " ('beautiful', 0.058613934703162077),\n",
       " ('surprised', 0.058273314482562975),\n",
       " ('worth', 0.057657484236471226),\n",
       " ('especially', 0.057422020781760778),\n",
       " ('refreshing', 0.057310532092265762),\n",
       " ('entertaining', 0.056612033835629204),\n",
       " ('hilarious', 0.056168541032286676),\n",
       " ('masterpiece', 0.054993988649431599),\n",
       " ('simple', 0.054484083134924095),\n",
       " ('subtle', 0.054368883033508633),\n",
       " ('funniest', 0.05345716487130267),\n",
       " ('solid', 0.052903564743620658),\n",
       " ('awesome', 0.052489194202770428),\n",
       " ('always', 0.05226032852534529),\n",
       " ('noir', 0.051530194726406908),\n",
       " ('guys', 0.051109413645642698),\n",
       " ('sweet', 0.050818930317526004),\n",
       " ('unique', 0.05067016226358919),\n",
       " ('very', 0.050132994948528478),\n",
       " ('heart', 0.04994805849824361),\n",
       " ('moving', 0.049424601164379134),\n",
       " ('atmosphere', 0.048842500895912855),\n",
       " ('strong', 0.048570880631759218)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similar_words('excellent')[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these words are supposed to give a similar output the network sees them as similar and therefore have similar weights. We can visualise these clusters buy plotting them on a graph using T-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "words_to_visualize = list()\n",
    "for word, ratio in pos_neg_ratios.most_common(500):\n",
    "    if(word in mlp_full.word2index.keys()):\n",
    "        words_to_visualize.append(word)\n",
    "    \n",
    "for word, ratio in list(reversed(pos_neg_ratios.most_common()))[0:500]:\n",
    "    if(word in mlp_full.word2index.keys()):\n",
    "        words_to_visualize.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "\n",
    "colors_list = list()\n",
    "vectors_list = list()\n",
    "for word in words_to_visualize:\n",
    "    if word in pos_neg_ratios.keys():\n",
    "        vectors_list.append(mlp_full.weights_0_1[mlp_full.word2index[word]])\n",
    "        if(pos_neg_ratios[word] > 0):\n",
    "            pos+=1\n",
    "            colors_list.append(\"#00ff00\")\n",
    "        else:\n",
    "            neg+=1\n",
    "            colors_list.append(\"#000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_top_ted_tsne = tsne.fit_transform(vectors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda/lib/python3.6/site-packages/bokeh/util/deprecation.py:34: BokehDeprecationWarning: \n",
      "Supplying a user-defined data source AND iterable values to glyph methods is deprecated.\n",
      "\n",
      "See https://github.com/bokeh/bokeh/issues/2056 for more information.\n",
      "\n",
      "  warn(message)\n",
      "/Users/max/anaconda/lib/python3.6/site-packages/bokeh/util/deprecation.py:34: BokehDeprecationWarning: \n",
      "Supplying a user-defined data source AND iterable values to glyph methods is deprecated.\n",
      "\n",
      "See https://github.com/bokeh/bokeh/issues/2056 for more information.\n",
      "\n",
      "  warn(message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"bk-plotdiv\" id=\"6560c3a1-1ec8-495d-8646-7a057ab9f859\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = false;\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        document.getElementById(\"6560c3a1-1ec8-495d-8646-7a057ab9f859\").textContent = \"BokehJS successfully loaded.\";\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"6560c3a1-1ec8-495d-8646-7a057ab9f859\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6560c3a1-1ec8-495d-8646-7a057ab9f859' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        (function() {\n",
       "          var fn = function() {\n",
       "            var docs_json = {\"52e46e61-76e7-43c5-9317-dd7d7972bf1c\":{\"roots\":{\"references\":[{\"attributes\":{\"callback\":null},\"id\":\"3ad67f9d-2091-4a45-aa77-046d01af7804\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"084a0c76-b9db-4a5b-8bfa-58887a26e7ec\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"084a0c76-b9db-4a5b-8bfa-58887a26e7ec\",\"type\":\"BasicTicker\"}},\"id\":\"205f7037-b3de-476d-bebd-8b8ddfc2ac94\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"d3bfbc7a-8dd4-4f0f-8e20-df198f5c1f5a\",\"type\":\"ToolEvents\"},{\"attributes\":{\"formatter\":{\"id\":\"7295e16c-787b-4bd3-8991-346b8dde7452\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"98df958a-5f71-4a8e-878d-a3b0ba6e68e5\",\"type\":\"BasicTicker\"}},\"id\":\"b2fa9637-804a-461e-be09-448deba04661\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"98df958a-5f71-4a8e-878d-a3b0ba6e68e5\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"e60bac9e-0f4c-433c-833c-8d794caf374e\",\"type\":\"PanTool\"},{\"id\":\"8b706d88-fc25-4a53-b0e4-8616204dae2b\",\"type\":\"WheelZoomTool\"},{\"id\":\"c1b7674f-3972-40c6-9200-6fa8886ada2a\",\"type\":\"ResetTool\"},{\"id\":\"e054e5f7-8cf3-4637-b27f-291ae9a3e961\",\"type\":\"SaveTool\"}]},\"id\":\"d3e61b7e-18a7-44e4-a073-72bbdbc05d3d\",\"type\":\"Toolbar\"},{\"attributes\":{\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"007a2142-3ba5-477b-8af0-19f57ceec26e\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"190e01a2-bca7-4005-9a8d-cb1e7210c2e7\",\"type\":\"LabelSet\"},{\"attributes\":{\"fill_color\":{\"field\":\"fill_color\"},\"line_color\":{\"field\":\"line_color\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"c1c2b998-dc64-47c6-ae5e-702d487b3c14\",\"type\":\"Circle\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"98df958a-5f71-4a8e-878d-a3b0ba6e68e5\",\"type\":\"BasicTicker\"}},\"id\":\"fbc7011e-aac6-4bef-8bef-de7dc84ac6ce\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"3eafffa5-de1d-47de-997b-b866a1c13951\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"7295e16c-787b-4bd3-8991-346b8dde7452\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"e60bac9e-0f4c-433c-833c-8d794caf374e\",\"type\":\"PanTool\"},{\"attributes\":{\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"8b706d88-fc25-4a53-b0e4-8616204dae2b\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"c1b7674f-3972-40c6-9200-6fa8886ada2a\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"e054e5f7-8cf3-4637-b27f-291ae9a3e961\",\"type\":\"SaveTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"8a2ed9bd-c0b4-4851-b1c6-ba7747f49a5e\",\"type\":\"Circle\"},{\"attributes\":{\"data_source\":{\"id\":\"007a2142-3ba5-477b-8af0-19f57ceec26e\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"c1c2b998-dc64-47c6-ae5e-702d487b3c14\",\"type\":\"Circle\"},\"hover_glyph\":null,\"nonselection_glyph\":{\"id\":\"8a2ed9bd-c0b4-4851-b1c6-ba7747f49a5e\",\"type\":\"Circle\"},\"selection_glyph\":null},\"id\":\"ddae3d87-fc85-41af-a2fa-10a4846cc835\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":null,\"text\":\"vector T-SNE for most polarized words\"},\"id\":\"75ae49c4-0222-4fd6-89b3-c68d369b28e6\",\"type\":\"Title\"},{\"attributes\":{\"below\":[{\"id\":\"97c9d0af-26fa-4864-957b-1e9f2bfe7225\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"b2fa9637-804a-461e-be09-448deba04661\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"97c9d0af-26fa-4864-957b-1e9f2bfe7225\",\"type\":\"LinearAxis\"},{\"id\":\"205f7037-b3de-476d-bebd-8b8ddfc2ac94\",\"type\":\"Grid\"},{\"id\":\"b2fa9637-804a-461e-be09-448deba04661\",\"type\":\"LinearAxis\"},{\"id\":\"fbc7011e-aac6-4bef-8bef-de7dc84ac6ce\",\"type\":\"Grid\"},{\"id\":\"ddae3d87-fc85-41af-a2fa-10a4846cc835\",\"type\":\"GlyphRenderer\"},{\"id\":\"190e01a2-bca7-4005-9a8d-cb1e7210c2e7\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"75ae49c4-0222-4fd6-89b3-c68d369b28e6\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"d3bfbc7a-8dd4-4f0f-8e20-df198f5c1f5a\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"d3e61b7e-18a7-44e4-a073-72bbdbc05d3d\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"3ad67f9d-2091-4a45-aa77-046d01af7804\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"eab3ecb6-7afd-4ba5-a3ef-29664a29af7f\",\"type\":\"DataRange1d\"}},\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x1\",\"x2\",\"names\",\"fill_color\",\"line_color\"],\"data\":{\"fill_color\":[\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\"],\"line_color\":[\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\"],\"names\":[\"edie\",\"paulie\",\"felix\",\"polanski\",\"matthau\",\"victoria\",\"mildred\",\"gandhi\",\"flawless\",\"superbly\",\"perfection\",\"astaire\",\"captures\",\"voight\",\"wonderfully\",\"powell\",\"brosnan\",\"lily\",\"bakshi\",\"lincoln\",\"refreshing\",\"breathtaking\",\"bourne\",\"lemmon\",\"delightful\",\"flynn\",\"andrews\",\"homer\",\"beautifully\",\"soccer\",\"elvira\",\"underrated\",\"gripping\",\"superb\",\"delight\",\"welles\",\"sadness\",\"sinatra\",\"touching\",\"timeless\",\"macy\",\"unforgettable\",\"favorites\",\"stewart\",\"sullivan\",\"extraordinary\",\"hartley\",\"brilliantly\",\"friendship\",\"wonderful\",\"palma\",\"magnificent\",\"finest\",\"jackie\",\"ritter\",\"tremendous\",\"freedom\",\"fantastic\",\"terrific\",\"noir\",\"sidney\",\"outstanding\",\"pleasantly\",\"mann\",\"nancy\",\"marie\",\"marvelous\",\"excellent\",\"ruth\",\"stanwyck\",\"widmark\",\"splendid\",\"chan\",\"exceptional\",\"tender\",\"gentle\",\"poignant\",\"gem\",\"amazing\",\"chilling\",\"fisher\",\"davies\",\"captivating\",\"darker\",\"april\",\"kelly\",\"blake\",\"overlooked\",\"ralph\",\"bette\",\"hoffman\",\"cole\",\"shines\",\"powerful\",\"notch\",\"remarkable\",\"pitt\",\"winters\",\"vivid\",\"gritty\",\"giallo\",\"portrait\",\"innocence\",\"psychiatrist\",\"favorite\",\"ensemble\",\"stunning\",\"burns\",\"garbo\",\"barbara\",\"philip\",\"panic\",\"holly\",\"carol\",\"perfect\",\"appreciated\",\"favourite\",\"journey\",\"rural\",\"bond\",\"builds\",\"brilliant\",\"brooklyn\",\"von\",\"recommended\",\"unfolds\",\"daniel\",\"perfectly\",\"crafted\",\"prince\",\"troubled\",\"consequences\",\"haunting\",\"cinderella\",\"alexander\",\"emotions\",\"boxing\",\"subtle\",\"curtis\",\"rare\",\"loved\",\"daughters\",\"courage\",\"dentist\",\"highly\",\"nominated\",\"tony\",\"draws\",\"everyday\",\"contrast\",\"cried\",\"fabulous\",\"ned\",\"fay\",\"emma\",\"sensitive\",\"smooth\",\"dramas\",\"today\",\"helps\",\"inspiring\",\"jimmy\",\"awesome\",\"unique\",\"tragic\",\"intense\",\"stellar\",\"rival\",\"provides\",\"depression\",\"shy\",\"carrie\",\"blend\",\"hank\",\"diana\",\"adorable\",\"unexpected\",\"achievement\",\"bettie\",\"happiness\",\"glorious\",\"davis\",\"terrifying\",\"beauty\",\"ideal\",\"fears\",\"hong\",\"seasons\",\"fascinating\",\"carries\",\"satisfying\",\"definite\",\"touched\",\"greatest\",\"creates\",\"aunt\",\"walter\",\"spectacular\",\"portrayal\",\"ann\",\"enterprise\",\"musicals\",\"deeply\",\"incredible\",\"mature\",\"triumph\",\"margaret\",\"navy\",\"harry\",\"lucas\",\"sweet\",\"joey\",\"oscar\",\"balance\",\"warm\",\"ages\",\"guilt\",\"glover\",\"carrey\",\"learns\",\"unusual\",\"sons\",\"complex\",\"essence\",\"brazil\",\"widow\",\"solid\",\"beautiful\",\"holmes\",\"awe\",\"vhs\",\"eerie\",\"lonely\",\"grim\",\"sport\",\"debut\",\"destiny\",\"thrillers\",\"tears\",\"rose\",\"feelings\",\"ginger\",\"winning\",\"stanley\",\"cox\",\"paris\",\"heart\",\"hooked\",\"comfortable\",\"mgm\",\"masterpiece\",\"themes\",\"danny\",\"anime\",\"perry\",\"joy\",\"lovable\",\"mysteries\",\"hal\",\"louis\",\"charming\",\"urban\",\"allows\",\"impact\",\"italy\",\"gradually\",\"lifestyle\",\"spy\",\"treat\",\"subsequent\",\"kennedy\",\"loving\",\"surprising\",\"quiet\",\"winter\",\"reveals\",\"raw\",\"funniest\",\"pleased\",\"norman\",\"thief\",\"season\",\"secrets\",\"colorful\",\"highest\",\"compelling\",\"danes\",\"castle\",\"kudos\",\"great\",\"baseball\",\"subtitles\",\"bleak\",\"winner\",\"tragedy\",\"todd\",\"nicely\",\"arthur\",\"essential\",\"gorgeous\",\"fonda\",\"eastwood\",\"focuses\",\"enjoyed\",\"natural\",\"intensity\",\"witty\",\"rob\",\"worlds\",\"health\",\"magical\",\"deeper\",\"lucy\",\"moving\",\"lovely\",\"purple\",\"memorable\",\"sings\",\"craig\",\"modesty\",\"relate\",\"episodes\",\"strong\",\"smith\",\"tear\",\"apartment\",\"princess\",\"disagree\",\"kung\",\"adventure\",\"columbo\",\"jake\",\"adds\",\"hart\",\"strength\",\"realizes\",\"dave\",\"childhood\",\"forbidden\",\"tight\",\"surreal\",\"manager\",\"dancer\",\"studios\",\"con\",\"miike\",\"realistic\",\"explicit\",\"kurt\",\"traditional\",\"deals\",\"holds\",\"carl\",\"touches\",\"gene\",\"albert\",\"abc\",\"cry\",\"sides\",\"develops\",\"eyre\",\"dances\",\"oscars\",\"legendary\",\"hearted\",\"importance\",\"portraying\",\"impressed\",\"waters\",\"empire\",\"edge\",\"jean\",\"environment\",\"sentimental\",\"captured\",\"styles\",\"daring\",\"frank\",\"tense\",\"backgrounds\",\"matches\",\"gothic\",\"sharp\",\"achieved\",\"court\",\"steals\",\"rules\",\"colors\",\"reunion\",\"covers\",\"tale\",\"rain\",\"denzel\",\"stays\",\"blob\",\"maria\",\"conventional\",\"fresh\",\"midnight\",\"landscape\",\"animated\",\"titanic\",\"sunday\",\"spring\",\"cagney\",\"enjoyable\",\"immensely\",\"sir\",\"nevertheless\",\"driven\",\"performances\",\"memories\",\"nowadays\",\"simple\",\"golden\",\"leslie\",\"lovers\",\"relationship\",\"supporting\",\"che\",\"packed\",\"trek\",\"provoking\",\"strikes\",\"depiction\",\"emotional\",\"secretary\",\"influenced\",\"florida\",\"germany\",\"brings\",\"lewis\",\"elderly\",\"owner\",\"streets\",\"henry\",\"portrays\",\"bears\",\"china\",\"anger\",\"society\",\"available\",\"best\",\"bugs\",\"magic\",\"delivers\",\"verhoeven\",\"jim\",\"donald\",\"endearing\",\"relationships\",\"greatly\",\"charlie\",\"brad\",\"simon\",\"effectively\",\"march\",\"atmosphere\",\"influence\",\"genius\",\"emotionally\",\"ken\",\"identity\",\"sophisticated\",\"dan\",\"andrew\",\"india\",\"roy\",\"surprisingly\",\"sky\",\"romantic\",\"match\",\"meets\",\"cowboy\",\"wave\",\"bitter\",\"patient\",\"stylish\",\"britain\",\"affected\",\"beatty\",\"love\",\"paul\",\"andy\",\"performance\",\"patrick\",\"unlike\",\"brooks\",\"refuses\",\"award\",\"complaint\",\"ride\",\"dawson\",\"luke\",\"wells\",\"france\",\"sports\",\"handsome\",\"directs\",\"rebel\",\"boll\",\"uwe\",\"seagal\",\"unwatchable\",\"stinker\",\"mst\",\"incoherent\",\"unfunny\",\"waste\",\"blah\",\"horrid\",\"pointless\",\"atrocious\",\"redeeming\",\"prom\",\"drivel\",\"lousy\",\"worst\",\"laughable\",\"awful\",\"poorly\",\"wasting\",\"remotely\",\"existent\",\"boredom\",\"miserably\",\"sucks\",\"uninspired\",\"lame\",\"insult\",\"godzilla\",\"uninteresting\",\"gadget\",\"appalling\",\"unconvincing\",\"unintentional\",\"horrible\",\"amateurish\",\"pathetic\",\"idiotic\",\"stupidity\",\"cardboard\",\"wasted\",\"crap\",\"insulting\",\"tedious\",\"dreadful\",\"dire\",\"badly\",\"suck\",\"worse\",\"terrible\",\"embarrassing\",\"mess\",\"garbage\",\"pile\",\"stupid\",\"ashamed\",\"vampires\",\"worthless\",\"dull\",\"inept\",\"avoid\",\"wooden\",\"forgettable\",\"fulci\",\"crappy\",\"bat\",\"unbelievably\",\"whatsoever\",\"excuse\",\"rubbish\",\"ridiculous\",\"junk\",\"flop\",\"boring\",\"turkey\",\"shark\",\"topless\",\"ridiculously\",\"useless\",\"seed\",\"ripped\",\"embarrassed\",\"rambo\",\"costs\",\"hideous\",\"horrendous\",\"bother\",\"dumb\",\"disjointed\",\"plastic\",\"horribly\",\"fest\",\"ludicrous\",\"unintentionally\",\"obnoxious\",\"mildly\",\"bland\",\"mummy\",\"annoying\",\"amateur\",\"bad\",\"dinosaurs\",\"unless\",\"fails\",\"mediocre\",\"awake\",\"clichd\",\"clich\",\"meaningless\",\"disappointment\",\"zombies\",\"asleep\",\"miscast\",\"irritating\",\"utter\",\"disappointing\",\"screaming\",\"supposed\",\"kidding\",\"poor\",\"apes\",\"unbelievable\",\"fake\",\"dude\",\"dracula\",\"joke\",\"clumsy\",\"random\",\"cheap\",\"idiots\",\"devoid\",\"trite\",\"wannabe\",\"unbearable\",\"alright\",\"pretentious\",\"scooby\",\"sucked\",\"senseless\",\"bo\",\"bin\",\"coherent\",\"idiot\",\"toilet\",\"doo\",\"werewolf\",\"cabin\",\"generous\",\"offensive\",\"monkey\",\"painfully\",\"renting\",\"lazy\",\"disgusting\",\"blame\",\"walked\",\"seconds\",\"generic\",\"cheese\",\"sloppy\",\"huh\",\"retarded\",\"trash\",\"shelf\",\"ugly\",\"oh\",\"slightest\",\"explanation\",\"failed\",\"cringe\",\"blatant\",\"clue\",\"bored\",\"cgi\",\"sat\",\"paid\",\"warn\",\"painful\",\"nowhere\",\"bore\",\"absurd\",\"flies\",\"paint\",\"porn\",\"paper\",\"predictable\",\"pseudo\",\"repetitive\",\"outer\",\"brain\",\"sorry\",\"vampire\",\"motivation\",\"unrealistic\",\"wrestling\",\"overrated\",\"aliens\",\"halfway\",\"save\",\"santa\",\"security\",\"contrived\",\"lacks\",\"whale\",\"gore\",\"bunch\",\"hype\",\"flat\",\"noise\",\"below\",\"plain\",\"spending\",\"bothered\",\"annoyed\",\"sounded\",\"honestly\",\"minutes\",\"wreck\",\"lesbian\",\"chick\",\"dollar\",\"f\",\"secondly\",\"wanna\",\"rat\",\"errors\",\"shallow\",\"synopsis\",\"breasts\",\"gray\",\"yeah\",\"nonsense\",\"unnecessary\",\"swear\",\"grave\",\"ruined\",\"somebody\",\"elvis\",\"mindless\",\"terribly\",\"continuity\",\"hoping\",\"ha\",\"nudity\",\"endless\",\"decent\",\"torture\",\"rented\",\"disaster\",\"downright\",\"ok\",\"fat\",\"unpleasant\",\"figured\",\"rip\",\"throwing\",\"attempt\",\"weak\",\"slap\",\"jesus\",\"christian\",\"barely\",\"apparently\",\"implausible\",\"nothing\",\"clichs\",\"credibility\",\"bible\",\"explained\",\"presumably\",\"celluloid\",\"couldn\",\"money\",\"snake\",\"hollow\",\"load\",\"sake\",\"total\",\"priest\",\"supposedly\",\"consists\",\"zombie\",\"bomb\",\"ape\",\"bottom\",\"christ\",\"unfortunately\",\"bullets\",\"grade\",\"drags\",\"freak\",\"wolf\",\"fx\",\"offended\",\"script\",\"raped\",\"producers\",\"okay\",\"confusing\",\"stomach\",\"monster\",\"seriously\",\"alas\",\"promising\",\"knife\",\"substance\",\"premise\",\"threw\",\"k\",\"dear\",\"z\",\"write\",\"rental\",\"warned\",\"zero\",\"semi\",\"guess\",\"scientist\",\"logic\",\"vague\",\"slasher\",\"throw\",\"accents\",\"alien\",\"silly\",\"clown\",\"skip\",\"instead\",\"blank\",\"throat\",\"lab\",\"par\",\"gag\",\"execution\",\"nose\",\"hated\",\"effort\",\"shoot\",\"fill\",\"gratuitous\",\"burn\",\"none\",\"cameras\",\"assume\",\"stick\",\"reasonable\",\"failure\",\"pie\",\"rent\",\"dubbing\",\"weren\",\"truck\",\"stock\",\"thin\",\"daddy\",\"holy\",\"exercise\",\"pg\",\"arm\",\"tried\",\"suppose\",\"advice\",\"gonna\",\"disbelief\",\"derek\",\"mean\",\"merit\",\"looked\",\"channel\",\"gross\",\"stereotypical\",\"hoped\",\"lacking\",\"spent\",\"stiff\",\"overdone\",\"low\",\"romero\",\"hour\",\"blair\",\"saved\",\"damage\",\"reason\",\"intentions\",\"sentence\",\"hardcore\",\"makeup\",\"lack\",\"makers\",\"empty\",\"holes\",\"wouldn\",\"proof\",\"demon\",\"toys\",\"doll\",\"utterly\",\"originality\",\"bush\",\"saying\",\"cover\",\"meat\",\"forest\",\"deserve\",\"sum\",\"bucks\",\"hills\",\"watchable\",\"lacked\",\"handed\",\"mistake\",\"please\",\"whoever\",\"sadistic\",\"monsters\",\"screenwriter\",\"neither\",\"nuclear\",\"sequels\",\"flesh\",\"lying\",\"creature\",\"annie\",\"propaganda\",\"leonard\",\"thats\",\"racist\",\"convince\",\"asian\",\"why\",\"rex\",\"satan\",\"remake\",\"fail\",\"ah\",\"loser\",\"favor\",\"except\",\"flick\",\"freddy\",\"relies\",\"spare\",\"dialog\",\"lou\",\"dragged\",\"guy\",\"problem\",\"melting\",\"flash\",\"im\",\"least\",\"mouth\",\"sole\",\"hell\",\"jerk\",\"drink\",\"intent\",\"shower\",\"fifteen\",\"wasn\",\"thugs\",\"corpse\",\"virus\",\"idea\",\"budget\",\"minimal\",\"reasonably\",\"naked\",\"rick\",\"category\",\"cheesy\",\"judging\",\"half\",\"pregnant\",\"no\",\"millions\",\"stereotypes\",\"juvenile\",\"weekend\",\"convoluted\",\"laurel\",\"killings\",\"sequel\",\"hire\",\"somewhere\",\"frankly\",\"paying\",\"someone\",\"cant\",\"cash\",\"research\",\"dimensional\",\"walk\",\"editing\",\"conceived\",\"scare\",\"positive\",\"anything\"],\"x1\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[1000]},\"x2\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[1000]}}},\"id\":\"007a2142-3ba5-477b-8af0-19f57ceec26e\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"formatter\":{\"id\":\"3eafffa5-de1d-47de-997b-b866a1c13951\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"6b183971-acfe-423c-8013-73aed6781778\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"084a0c76-b9db-4a5b-8bfa-58887a26e7ec\",\"type\":\"BasicTicker\"}},\"id\":\"97c9d0af-26fa-4864-957b-1e9f2bfe7225\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null},\"id\":\"eab3ecb6-7afd-4ba5-a3ef-29664a29af7f\",\"type\":\"DataRange1d\"}],\"root_ids\":[\"6b183971-acfe-423c-8013-73aed6781778\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.4\"}};\n",
       "            var render_items = [{\"docid\":\"52e46e61-76e7-43c5-9317-dd7d7972bf1c\",\"elementid\":\"6560c3a1-1ec8-495d-8646-7a057ab9f859\",\"modelid\":\"6b183971-acfe-423c-8013-73aed6781778\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "          };\n",
       "          if (document.readyState != \"loading\") fn();\n",
       "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "        })();\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === true) {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (force !== true) {\n",
       "        var cell = $(document.getElementById(\"6560c3a1-1ec8-495d-8646-7a057ab9f859\")).parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"vector T-SNE for most polarized words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
    "                                    x2=words_top_ted_tsne[:,1],\n",
    "                                    names=words_to_visualize))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source,color=colors_list)\n",
    "\n",
    "word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(word_labels)\n",
    "\n",
    "show(p)\n",
    "\n",
    "# green indicates positive words, black indicates negative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After curating the dataset and training we were able to achieve a speed of a couple of hundred words per second with a very low accuracy. However after doing the first instance of noise reduction we were able to get the accuracy upwards of 80%. After optimising inefficiencys the network managed to achieve the same accuracy and a couple of thousand words per second. Finally a second set of noise reduction removed the useless data from the set such as names and punctuation. This acieved an even higher accuracy. After this step the network now has the ability to trade of accuracy for speed by cutting more words out of the vocabulary. This can be helpful for training over a much larger dataset. It also marginally increased speed by removing some of the data.\n",
    "\n",
    "After visualising the data it can clearly be seen that the network has successfully grouped the input words by sentiment. With a few agnostic variables normally consisting of names that slipped through. This could be imporoved by increading the cutoff."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
